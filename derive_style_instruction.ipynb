{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e655229",
   "metadata": {},
   "source": [
    "# Multi-Analyst Text Analysis Pipeline\n",
    "\n",
    "In this notebook we demonstrate the full pipeline for analyzing text through multiple specialist lenses (rhetorician, syntactician, lexicologist, etc.) and synthesizing their observations into \n",
    "* a unified writing style analysis from the text samples,\n",
    "* an instruction of how to write in the analyzed style.\n",
    "\n",
    "The workflow is *agentic* in that it involves several distinct agents built on Large Language Models (LLMs), however, the order and relation between each agent is set, not dynamically derived.\n",
    "\n",
    "The analysis and its details are described in this blog post: **INSERT LINK**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83322bf",
   "metadata": {},
   "source": [
    "## Installations and Preparations\n",
    "External libraries are installed and tested to be in working order.\n",
    "\n",
    "Key dependencies:\n",
    "* LiteLLM (model router such that different LLM APIs can be readily employed)\n",
    "* Jinja (create prompts with variables and conditional logic)\n",
    "* Pydantic (create prompts from variables with validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950024fd",
   "metadata": {},
   "source": [
    "**Install requirements.** Only needed if running in fresh kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61f80951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:02:22.033495Z",
     "start_time": "2025-11-19T18:02:20.240014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm==1.79.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.79.3)\n",
      "Requirement already satisfied: pydantic==2.7.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.7.4)\n",
      "Requirement already satisfied: jinja2>=3.1.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: aiohttp>=3.10 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (3.13.2)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (8.3.1)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: httpx>=0.23.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (8.7.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (4.25.1)\n",
      "Requirement already satisfied: openai>=1.99.5 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.22.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in ./venv/lib/python3.11/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./venv/lib/python3.11/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2>=3.1.0->-r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.22.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in ./venv/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.29.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./venv/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in ./venv/lib/python3.11/site-packages (from tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (1.1.4)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (6.0.3)\n",
      "Requirement already satisfied: shellingham in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (0.20.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97424ad1",
   "metadata": {},
   "source": [
    "Check that LiteLLM was installed correctly. List the providers available via LiteLLM router."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79a25bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providers\n",
      "=========\n",
      "* openai\n",
      "* openai_like\n",
      "* bytez\n",
      "* xai\n",
      "* custom_openai\n",
      "* text-completion-openai\n",
      "* cohere\n",
      "* cohere_chat\n",
      "* clarifai\n",
      "* anthropic\n",
      "* anthropic_text\n",
      "* replicate\n",
      "* huggingface\n",
      "* together_ai\n",
      "* datarobot\n",
      "* openrouter\n",
      "* cometapi\n",
      "* vertex_ai\n",
      "* vertex_ai_beta\n",
      "* gemini\n",
      "* ai21\n",
      "* baseten\n",
      "* azure\n",
      "* azure_text\n",
      "* azure_ai\n",
      "* sagemaker\n",
      "* sagemaker_chat\n",
      "* bedrock\n",
      "* vllm\n",
      "* nlp_cloud\n",
      "* petals\n",
      "* oobabooga\n",
      "* ollama\n",
      "* ollama_chat\n",
      "* deepinfra\n",
      "* perplexity\n",
      "* mistral\n",
      "* groq\n",
      "* nvidia_nim\n",
      "* cerebras\n",
      "* baseten\n",
      "* ai21_chat\n",
      "* volcengine\n",
      "* codestral\n",
      "* text-completion-codestral\n",
      "* deepseek\n",
      "* sambanova\n",
      "* maritalk\n",
      "* cloudflare\n",
      "* fireworks_ai\n",
      "* friendliai\n",
      "* watsonx\n",
      "* watsonx_text\n",
      "* triton\n",
      "* predibase\n",
      "* databricks\n",
      "* empower\n",
      "* github\n",
      "* custom\n",
      "* litellm_proxy\n",
      "* hosted_vllm\n",
      "* llamafile\n",
      "* lm_studio\n",
      "* galadriel\n",
      "* gradient_ai\n",
      "* github_copilot\n",
      "* novita\n",
      "* meta_llama\n",
      "* featherless_ai\n",
      "* nscale\n",
      "* nebius\n",
      "* dashscope\n",
      "* moonshot\n",
      "* v0\n",
      "* heroku\n",
      "* oci\n",
      "* morph\n",
      "* lambda_ai\n",
      "* vercel_ai_gateway\n",
      "* wandb\n",
      "* ovhcloud\n",
      "* lemonade\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import litellm\n",
    "    print('Providers\\n=========')\n",
    "    print('* ' + '\\n* '.join(litellm.LITELLM_CHAT_PROVIDERS))\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Cannot import litellm: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7691417",
   "metadata": {},
   "source": [
    "## Initialize Base Objects\n",
    "The base objects part of the current project library (`belletrist`) are initialized. They are:\n",
    "* `LLM`: the LLM object.\n",
    "* `LLMConfig`: the configuration of the LLM object, such as what model to use.\n",
    "* `PromptMaker`: generates prompts from templates and variables\n",
    "* `DataSampler`: retrieves and samples text at a source directory\n",
    "* `ResultStore`: simple database object to save intermediate and final outputs\n",
    "\n",
    "The LLM to use is set by the `model_string`, which is constructed as `<provider>/<model>`, the providers defined by the `litellm` package, see in particular `litellm.LITELLM_CHAT_PROVIDERS`. The API key to the provider should be stored in an environment variable with name defined in `model_provider_api_key_env_var`. You need to create that yourself for the provider of interest. \n",
    "\n",
    "Do **not** store the API key as a string variable directly in the notebook, you're at risk of exposing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ecdc5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_string = 'anthropic/claude-sonnet-4-5-20250929'\n",
    "#model_provider_api_key_env_var = 'ANTHROPIC_API_KEY'\n",
    "model_string = 'mistral/mistral-large-2411'\n",
    "model_provider_api_key_env_var = 'MISTRAL_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bbaea56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:02:29.927627Z",
     "start_time": "2025-11-19T18:02:29.858316Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from belletrist import LLM, LLMConfig, PromptMaker, DataSampler, ResultStore\n",
    "\n",
    "llm = LLM(LLMConfig(\n",
    "    model=model_string,\n",
    "    api_key=os.environ.get(model_provider_api_key_env_var)\n",
    "))\n",
    "prompt_maker = PromptMaker()\n",
    "sampler = DataSampler(\n",
    "    data_path=(Path(os.getcwd()) / \"data\" / \"russell\").resolve()\n",
    ")\n",
    "store = ResultStore(Path(f\"{os.getcwd()}/belletrist_storage_mistral_1127.db\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90249f6c",
   "metadata": {},
   "source": [
    "In case a clean run is wanted, the old contents of the database are discarded with a result store reset. Do **not** run this reset if content should be preserved from previous runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee267fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da595a7f",
   "metadata": {},
   "source": [
    "## Generate and Store Text Samples to be Analyzed\n",
    "\n",
    "The `DataSampler` retrieves paragraphs from the corpus of text. The retrieval can be a random sample of consecutive paragraphs (via the method `sample_segment`) or a specific file and paragraph range (via the method `get_paragraph_chunk`).\n",
    "\n",
    "As illustration of the process, a random four-paragraph long segment is sampled below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc079d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text source: /Users/andersohrn/PycharmProjects/russell_writes/data/russell/education_and_the_good_life.txt\n",
      "Paragraph range: 80 - 85\n",
      "\n",
      "I think that in the life of a man whose circumstances and talents are\n",
      "not very exceptional there should be a large sphere where what is\n",
      "vaguely termed “herd instinct” dominates, and a small sphere into which\n",
      "it does not penetrate. The small sphere should contain the region of\n",
      "his special competence. We think ill of a man who cannot admire a woman\n",
      "unless everybody else also admires her: we think that, in the choice\n",
      "of a wife, a man should be guided by his own independent feelings, not\n",
      "by a reflection of the feelings of his society. It is no matter if his\n",
      "judgments of people in general agree with those of his neighbours, but\n",
      "when he falls in love he ought to be guided by his own independent\n",
      "feelings. Much the same thing applies in other directions. A farmer\n",
      "should follow his own judgment as to the capacities of the fields\n",
      "which he cultivates himself, though his judgment should be formed\n",
      "after acquiring a knowledge of scientific agriculture. An economist\n",
      "should form an independent judgment on currency questions, but an\n",
      "ordinary mortal had better follow authority. Wherever there is special\n",
      "competence, there should be independence. But a man should not make\n",
      "himself into a kind of hedgehog, all bristles to keep the world at a\n",
      "distance. The bulk of our ordinary activities must be co-operative,\n",
      "and co-operation must have an instinctive basis. Nevertheless, we\n",
      "should all learn to be able to think for ourselves about matters that\n",
      "are particularly well known to us, and we ought all to have acquired\n",
      "the courage to proclaim unpopular opinions when we believe them to be\n",
      "important. The application of these broad principles in special cases\n",
      "may, of course, be difficult. But it will be less difficult than it\n",
      "is at present in a world where men commonly have the virtues we have\n",
      "been considering in this chapter. The persecuted saint, for instance,\n",
      "would not exist in such a world. The good man would have no occasion\n",
      "to bristle and become self-conscious; his goodness would result\n",
      "from following his impulses, and would be combined with instinctive\n",
      "happiness. His neighbours would not hate him, because they would not\n",
      "fear him: the hatred of pioneers is due to the terror they inspire, and\n",
      "this terror would not exist among men who had acquired courage. Only a\n",
      "man dominated by fear would join the Ku Klux Klan or the Fascisti. In\n",
      "a world of brave men, such persecuting organizations could not exist,\n",
      "and the good life would involve far less resistance to instinct than\n",
      "it does at present. The good world can only be created and sustained\n",
      "by fearless men, but the more they succeed in their task the fewer\n",
      "occasions there will be for the exercise of their courage.\n",
      "\n",
      "A community of men and women possessing vitality, courage,\n",
      "sensitiveness, and intelligence, in the highest degree that education\n",
      "can produce, would be very different from anything that has hitherto\n",
      "existed. Very few people would be unhappy. The main causes of\n",
      "unhappiness at present are: ill-health, poverty, and an unsatisfactory\n",
      "sex-life. All of these would become very rare. Good health could\n",
      "be almost universal, and even old age could be postponed. Poverty,\n",
      "since the industrial revolution, is only due to collective stupidity.\n",
      "Sensitiveness would make people wish to abolish it, intelligence would\n",
      "show them the way, and courage would lead them to adopt it. (A timid\n",
      "person would rather remain miserable than do anything unusual.) Most\n",
      "people’s sex-life, at present, is more or less unsatisfactory. This is\n",
      "partly due to bad education, partly to persecution by the authorities\n",
      "and Mrs. Grundy. A generation of women brought up without irrational\n",
      "sex fears would soon make an end of this. Fear has been thought the\n",
      "only way to make women “virtuous”, and they have been deliberately\n",
      "taught to be cowards, both physically and mentally. Women in whom love\n",
      "is cramped encourage brutality and hypocrisy in their husbands, and\n",
      "distort the instincts of their children. One generation of fearless\n",
      "women could transform the world, by bringing into it a generation of\n",
      "fearless children, not contorted into unnatural shapes, but straight\n",
      "and candid, generous, affectionate, and free. Their ardour would\n",
      "sweep away the cruelty and pain which we endure because we are lazy,\n",
      "cowardly, hard-hearted and stupid. It is education that gives us these\n",
      "bad qualities, and education that must give us the opposite virtues.\n",
      "Education is the key to the new world.\n",
      "\n",
      "But it is time to have done with generalities and come to the concrete\n",
      "detail in which our ideals are to be embodied.\n",
      "\n",
      "PART II\n",
      "\n",
      "EDUCATION OF CHARACTER\n"
     ]
    }
   ],
   "source": [
    "text_sample = sampler.sample_segment(p_length=5)\n",
    "print(f'Text source: {text_sample.file_path}')\n",
    "print(f'Paragraph range: {text_sample.paragraph_start} - {text_sample.paragraph_end}')\n",
    "print(f'\\n{text_sample.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef790cd6",
   "metadata": {},
   "source": [
    "A number of text samples are retrieved (**set `n_sample` to the desired number**) and each sample comprises a set number of paragraphs (**set `m_paragraphs_per_sample` to the desired number**). These text samples are stored in the project result stored with keys like `sample_001`, `sample_002` and so on; these keys are henceforth referring to specific text samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "436cea45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus it becomes evident that the real table, if there is one, is not the\n",
      "same as what we immediately experience by sight or touch or hearing. The\n",
      "real table, if there is one, is not _immediately_ known to us at all,\n",
      "but must be an inference from what is immediately known. Hence, two very\n",
      "difficult questions at once arise; namely, (1) Is there a real table at\n",
      "all? (2) If so, what sort of object can it be?\n",
      "\n",
      "It will help us in considering these questions to have a few simple\n",
      "terms of which the meaning is definite and clear. Let us give the name\n",
      "of 'sense-data' to the things that are immediately known in sensation:\n",
      "such things as colours, sounds, smells, hardnesses, roughnesses, and\n",
      "so on. We shall give the name 'sensation' to the experience of being\n",
      "immediately aware of these things. Thus, whenever we see a colour,\n",
      "we have a sensation _of_ the colour, but the colour itself is a\n",
      "sense-datum, not a sensation. The colour is that _of_ which we are\n",
      "immediately aware, and the awareness itself is the sensation. It is\n",
      "plain that if we are to know anything about the table, it must be\n",
      "by means of the sense-data--brown colour, oblong shape, smoothness,\n",
      "etc.--which we associate with the table; but, for the reasons which have\n",
      "been given, we cannot say that the table is the sense-data, or even\n",
      "that the sense-data are directly properties of the table. Thus a problem\n",
      "arises as to the relation of the sense-data to the real table, supposing\n",
      "there is such a thing.\n",
      "\n",
      "The real table, if it exists, we will call a 'physical object'. Thus\n",
      "we have to consider the relation of sense-data to physical objects.\n",
      "The collection of all physical objects is called 'matter'. Thus our two\n",
      "questions may be re-stated as follows: (1) Is there any such thing as\n",
      "matter? (2) If so, what is its nature?\n",
      "\n",
      "The philosopher who first brought prominently forward the reasons\n",
      "for regarding the immediate objects of our senses as not existing\n",
      "independently of us was Bishop Berkeley (1685-1753). His _Three\n",
      "Dialogues between Hylas and Philonous, in Opposition to Sceptics and\n",
      "Atheists_, undertake to prove that there is no such thing as matter at\n",
      "all, and that the world consists of nothing but minds and their ideas.\n",
      "Hylas has hitherto believed in matter, but he is no match for Philonous,\n",
      "who mercilessly drives him into contradictions and paradoxes, and makes\n",
      "his own denial of matter seem, in the end, as if it were almost common\n",
      "sense. The arguments employed are of very different value: some are\n",
      "important and sound, others are confused or quibbling. But Berkeley\n",
      "retains the merit of having shown that the existence of matter is\n",
      "capable of being denied without absurdity, and that if there are any\n",
      "things that exist independently of us they cannot be the immediate\n",
      "objects of our sensations.\n",
      "\n",
      "There are two different questions involved when we ask whether matter\n",
      "exists, and it is important to keep them clear. We commonly mean by\n",
      "'matter' something which is opposed to 'mind', something which we think\n",
      "of as occupying space and as radically incapable of any sort of thought\n",
      "or consciousness. It is chiefly in this sense that Berkeley denies\n",
      "matter; that is to say, he does not deny that the sense-data which we\n",
      "commonly take as signs of the existence of the table are really signs\n",
      "of the existence of _something_ independent of us, but he does deny\n",
      "that this something is non-mental, that it is neither mind nor ideas\n",
      "entertained by some mind. He admits that there must be something which\n",
      "continues to exist when we go out of the room or shut our eyes, and that\n",
      "what we call seeing the table does really give us reason for believing\n",
      "in something which persists even when we are not seeing it. But he\n",
      "thinks that this something cannot be radically different in nature from\n",
      "what we see, and cannot be independent of seeing altogether, though it\n",
      "must be independent of _our_ seeing. He is thus led to regard the 'real'\n",
      "table as an idea in the mind of God. Such an idea has the required\n",
      "permanence and independence of ourselves, without being--as matter would\n",
      "otherwise be--something quite unknowable, in the sense that we can only\n",
      "infer it, and can never be directly and immediately aware of it.\n"
     ]
    }
   ],
   "source": [
    "print(sampler.get_paragraph_chunk(2, slice(10,15)).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebfe0dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 5\n",
    "m_paragraphs_per_sample = 5\n",
    "\n",
    "for _ in range(n_sample):\n",
    "    sample_id = f'sample_{len(store.list_samples()) + 1:03d}'\n",
    "    segment = sampler.sample_segment(p_length=m_paragraphs_per_sample)\n",
    "    store.save_segment(sample_id, segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41492449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample keys:\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sample_001', 'sample_002', 'sample_003', 'sample_004', 'sample_005']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sample keys:\\n============')\n",
    "store.list_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b794d0",
   "metadata": {},
   "source": [
    "## Step 1: Construct the Analyst Agents and Analyze Text Samples\n",
    "\n",
    "Send the text samples through each specialist analyst. Each produces an independent analysis from their domain expertise.\n",
    "\n",
    "**Prompt structure for each analyst is:**\n",
    "1. Preamble instruction of task ahead \n",
    "2. Analyst-specific instruction template\n",
    "3. Text to analyze\n",
    "\n",
    "Note that the execution of this can take time since it involves invoking LLMs, once per analyst and text sample. These are however independent analyses, and can therefore *in principle* be run in parallel, though the implementation below does not utilize that fact.\n",
    "\n",
    "Note that the agents are distinguished by their prompts, which are obtained via prompt models defined within the `bellatrist` project library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a462866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from belletrist.models import (\n",
    "    PreambleInstructionConfig,\n",
    "    PreambleTextConfig,\n",
    "    RhetoricianConfig,\n",
    "    SyntacticianConfig,\n",
    "    LexicologistConfig,\n",
    "    InformationArchitectConfig,\n",
    "    EfficiencyAuditorConfig,\n",
    "    CrossPerspectiveIntegratorConfig,\n",
    ")\n",
    "ANALYSTS = [\"rhetorician\", \"syntactician\", \"lexicologist\", \"information_architect\", \"efficiency_auditor\"]\n",
    "ANALYST_CONFIGS = {\n",
    "    \"rhetorician\": RhetoricianConfig,\n",
    "    \"syntactician\": SyntacticianConfig,\n",
    "    \"lexicologist\": LexicologistConfig,\n",
    "    \"information_architect\": InformationArchitectConfig,\n",
    "    \"efficiency_auditor\": EfficiencyAuditorConfig,\n",
    "}\n",
    "\n",
    "def build_analyst_prompt(preamble_instruction: str, analyst_prompt: str, preamble_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Helper function to construct the full prompt for an analyst.\n",
    "    \n",
    "    \"\"\"\n",
    "    return f\"{preamble_instruction}\\n\\n{analyst_prompt}\\n\\n{preamble_text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f88c6346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 samples with 5 analysts each\n",
      "\n",
      "Sample: sample_001\n",
      "  Running rhetorician... ✓ (6819 chars)\n",
      "  Running syntactician... ✓ (11179 chars)\n",
      "  Running lexicologist... ✓ (6109 chars)\n",
      "  Running information_architect... ✓ (6680 chars)\n",
      "  Running efficiency_auditor... ✓ (6663 chars)\n",
      "\n",
      "Sample: sample_002\n",
      "  Running rhetorician... ✓ (4686 chars)\n",
      "  Running syntactician... ✓ (4952 chars)\n",
      "  Running lexicologist... ✓ (4490 chars)\n",
      "  Running information_architect... ✓ (7903 chars)\n",
      "  Running efficiency_auditor... ✓ (5699 chars)\n",
      "\n",
      "Sample: sample_003\n",
      "  Running rhetorician... ✓ (5365 chars)\n",
      "  Running syntactician... ✓ (6663 chars)\n",
      "  Running lexicologist... ✓ (6662 chars)\n",
      "  Running information_architect... ✓ (7487 chars)\n",
      "  Running efficiency_auditor... ✓ (6862 chars)\n",
      "\n",
      "Sample: sample_004\n",
      "  Running rhetorician... ✓ (4765 chars)\n",
      "  Running syntactician... ✓ (6505 chars)\n",
      "  Running lexicologist... ✓ (4465 chars)\n",
      "  Running information_architect... ✓ (11318 chars)\n",
      "  Running efficiency_auditor... ✓ (6815 chars)\n",
      "\n",
      "Sample: sample_005\n",
      "  Running rhetorician... ✓ (5854 chars)\n",
      "  Running syntactician... ✓ (13257 chars)\n",
      "  Running lexicologist... ✓ (6168 chars)\n",
      "  Running information_architect... ✓ (6627 chars)\n",
      "  Running efficiency_auditor... ✓ (6758 chars)\n",
      "\n",
      "All analyses complete for 5 samples\n"
     ]
    }
   ],
   "source": [
    "# Get all samples from the store\n",
    "all_samples = store.list_samples()\n",
    "print(f\"Processing {len(all_samples)} samples with {len(ANALYSTS)} analysts each\\n\")\n",
    "\n",
    "# Outer loop: iterate over each text sample\n",
    "for sample_id in all_samples:\n",
    "    print(f\"Sample: {sample_id}\")\n",
    "    \n",
    "    # Get the sample text\n",
    "    sample = store.get_sample(sample_id)\n",
    "    text = sample['text']\n",
    "    \n",
    "    # Build shared prompt components (reused across all analysts for this sample)\n",
    "    preamble_instruction = prompt_maker.render(PreambleInstructionConfig())\n",
    "    preamble_text = prompt_maker.render(PreambleTextConfig(text_to_analyze=text))\n",
    "    \n",
    "    # Inner loop: run each analyst on this sample\n",
    "    for analyst_name in ANALYSTS:\n",
    "        # Check if analysis already exists (resume support)\n",
    "        if store.get_analysis(sample_id, analyst_name):\n",
    "            print(f\"  ✓ {analyst_name} (already done)\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Running {analyst_name}...\", end=\" \")\n",
    "        \n",
    "        # Get analyst-specific prompt using the config class\n",
    "        analyst_config = ANALYST_CONFIGS[analyst_name]()\n",
    "        analyst_prompt = prompt_maker.render(analyst_config)\n",
    "        full_prompt = build_analyst_prompt(preamble_instruction, analyst_prompt, preamble_text)\n",
    "        \n",
    "        # Run analysis and save result\n",
    "        response = llm.complete(full_prompt)\n",
    "        store.save_analysis(sample_id, analyst_name, response.content, response.model)\n",
    "        \n",
    "        print(f\"✓ ({len(response.content)} chars)\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f\"All analyses complete for {len(all_samples)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbe6dd1",
   "metadata": {},
   "source": [
    "Verification that analysis was run as expected and yielded analysis results. Excerpt of one specific analysis retrieved from project database and printed for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e95d8e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete: True\n",
      "\n",
      "Sample: sample_005\n",
      "Source: File 5, paragraphs 84-89\n",
      "Analyses available: ['efficiency_auditor', 'information_architect', 'lexicologist', 'rhetorician', 'syntactician']\n",
      "\n",
      "--- Rhetorician Output (first 500 chars) ---\n",
      "### WORD ECONOMY PATTERNS\n",
      "\n",
      "1. **Degree of Verbal Economy**: The text exhibits a moderate degree of verbal economy. It is neither overly sparse nor excessively generous with words. The prose is clear and concise, avoiding unnecessary verbosity.\n",
      "\n",
      "2. **Redundancy**: Redundancy is minimal and appears to be intentional where it occurs. For instance, the repetition of \"reciprocal\" and \"reciprocity\" emphasizes the mutual nature of the effects described. This creates a sense of symmetry and balance, reinforcing the scientific principle being explained.\n",
      "   - Example: \"And all this is reciprocal... And all lengths in the direction of motion are diminished by twenty per cent, both for those who look into the train from outside and for those who look out of the train from inside.\"\n",
      "\n",
      "3. **Word Length Patterns**: The text balances short, Anglo-Saxon words with longer, Latinate words. This mix contributes to the clarity and precision of the scientific explanation.\n",
      "   - Short words: \"train,\" \"light,\" \"distance,\" \"move\"\n",
      "   - Longer words: \"reciprocal,\" \"electromagnetism,\" \"observations\"\n",
      "\n",
      "4. **Frequency and Placement of Modifiers**: Modifiers are used sparingly but effectively. Adjectives and adverbs are placed to enhance clarity and specificity.\n",
      "   - Example: \"an almost ideal lucidity\"\n",
      "\n",
      "### STRUCTURAL DENSITY\n",
      "\n",
      "1. **Sentence Complexity Distribution**: The text employs a mix of simple, compound, and complex sentences. Complex sentences are more frequent, contributing to the explanatory and analy\n"
     ]
    }
   ],
   "source": [
    "sample_id = 'sample_005'\n",
    "is_complete = store.is_complete(sample_id, ANALYSTS)\n",
    "print(f\"Analysis complete: {is_complete}\")\n",
    "\n",
    "# Retrieve sample and all analyses (both are now dicts)\n",
    "sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "\n",
    "print(f\"\\nSample: {sample['sample_id']}\")\n",
    "print(f\"Source: File {sample['file_index']}, paragraphs {sample['paragraph_start']}-{sample['paragraph_end']}\")\n",
    "print(f\"Analyses available: {list(analyses.keys())}\")\n",
    "\n",
    "# Examine one analysis\n",
    "print(f\"\\n--- Rhetorician Output (first 500 chars) ---\")\n",
    "print(analyses.get(\"efficiency_auditor\", \"Not found\")[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b08eeab",
   "metadata": {},
   "source": [
    "## Step 2a: Pattern Recognition (Cross-Perspective Integration) per Text Sample\n",
    "\n",
    "Synthesize all analyst perspectives to identify interactions, tensions, and load-bearing features. This is a per-text-cross-analyst transformation. This looks to integrate multiple perspectives on each text sample and indirectly distill the information content in the assessments of the text samples. \n",
    "\n",
    "If only a subset of samples are to be analyzed, filter or slice the list `samples_to_analyze`, which is a list of sample IDs, as created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51ef1691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_001', 'sample_002', 'sample_003', 'sample_004', 'sample_005']\n"
     ]
    }
   ],
   "source": [
    "samples_to_analyze = store.list_samples()\n",
    "print(samples_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f138cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pattern_prompt_from_(text: str, analyses: dict):\n",
    "    \"\"\"Convenience function to create the prompt, since the prompt depends on the kinds of analysts to integrate.\n",
    "    \n",
    "    \"\"\"\n",
    "    sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "\n",
    "    analyst_info = {}\n",
    "    for analyst_name in ANALYSTS:\n",
    "        config_class = ANALYST_CONFIGS[analyst_name]\n",
    "        analyst_info[analyst_name] = {\n",
    "            'analysis': analyses[analyst_name],\n",
    "            'analyst_descr_short': config_class.description()\n",
    "        }\n",
    "\n",
    "    pattern_config = CrossPerspectiveIntegratorConfig(\n",
    "        original_text=sample['text'],\n",
    "        analysts=analyst_info\n",
    "    )\n",
    "    return prompt_maker.render(pattern_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f9cba",
   "metadata": {},
   "source": [
    "Note that this loop can take time to execute, since LLMs are called. Each analysis is independent and can therefore in principle be parallelized, though the implementation below does not do that.\n",
    "\n",
    "Note also that the cross-perspective per-text result are stored in the result store, keyed on the sample ID and the analyst kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "800aa4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross-Perspective Integrator agent for sample_001... ✓ (8940 chars)\n",
      "Running Cross-Perspective Integrator agent for sample_002... ✓ (7221 chars)\n",
      "Running Cross-Perspective Integrator agent for sample_003... ✓ (7259 chars)\n",
      "Running Cross-Perspective Integrator agent for sample_004... ✓ (8607 chars)\n",
      "Running Cross-Perspective Integrator agent for sample_005... ✓ (10121 chars)\n"
     ]
    }
   ],
   "source": [
    "for sample_id in samples_to_analyze:\n",
    "    # Check if cross-perspective integration already exists (resume support)\n",
    "    pattern_analyst = CrossPerspectiveIntegratorConfig.analyst_name()\n",
    "    if store.get_analysis(sample_id, pattern_analyst):\n",
    "        print(f\"✓ {sample_id} cross-perspective integration (already done)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Running Cross-Perspective Integrator agent for {sample_id}...\", end=\" \")\n",
    "    \n",
    "    sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "    pattern_prompt = build_pattern_prompt_from_(text=sample['text'], analyses=analyses)\n",
    "\n",
    "    pattern_response = llm.complete(pattern_prompt)\n",
    "    \n",
    "    # Store pattern recognition result in result store\n",
    "    store.save_analysis(\n",
    "        sample_id, \n",
    "        pattern_analyst, \n",
    "        pattern_response.content, \n",
    "        pattern_response.model\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ ({len(pattern_response.content)} chars)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93e4887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cross_perspective_integrator', 'efficiency_auditor', 'information_architect', 'lexicologist', 'rhetorician', 'syntactician'])\n",
      "\n",
      "--- Pattern Analyst Output (first 2000 chars) ---\n",
      "## INTEGRATED ANALYSIS OF THE TEXT\n",
      "\n",
      "### I. Extracted Techniques\n",
      "\n",
      "#### 1. Concrete Analogies for Abstract Concepts\n",
      "- **Specification**: Use familiar, concrete examples to explain abstract scientific concepts.\n",
      "  - **Step 1**: Introduce a relatable scenario (e.g., a train moving at high speed).\n",
      "  - **Step 2**: Describe the scenario in detail, using everyday objects (e.g., dinner plates, fishing rod).\n",
      "  - **Step 3**: Draw parallels between the scenario and the abstract concept (e.g., relativity of measurement).\n",
      "- **Example from text**: \"Suppose that you are in a train on a long straight railway, and that you are traveling at three-fifths of the velocity of light.\"\n",
      "- **Source observations**: Rhetorician (use of examples), Lexicologist (pairing abstractions with concrete terms)\n",
      "- **Confidence**: HIGH (Multiple analysts noted this technique, and it is clearly demonstrated in the text)\n",
      "\n",
      "#### 2. Reciprocal Explanations\n",
      "- **Specification**: Explain scientific phenomena by showing how observations are reciprocal between different perspectives.\n",
      "  - **Step 1**: Present a scenario from one perspective (e.g., observer in a train).\n",
      "  - **Step 2**: Describe the observations made from this perspective.\n",
      "  - **Step 3**: Present the same scenario from another perspective (e.g., observer outside the train).\n",
      "  - **Step 4**: Show how the observations are reciprocal (e.g., both observers see the other's measurements as affected).\n",
      "- **Example from text**: \"And all this is reciprocal. Suppose you see out of the window a man carrying a fishing rod which, by his measurement, is fifteen feet long.\"\n",
      "- **Source observations**: Rhetorician (counterpositions), Lexicologist (recurring word families), Syntactician (complex sentences for explanatory details)\n",
      "- **Confidence**: HIGH (Clearly demonstrated and noted by multiple analysts)\n",
      "\n",
      "#### 3. Complex Sentences for Detailed Explanations\n",
      "- **Specification**: Use complex sentences to provide detailed, nuanced explanations of scientific principles.\n",
      "  - **S\n"
     ]
    }
   ],
   "source": [
    "sample_id = 'sample_005'\n",
    "sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "print(analyses.keys())\n",
    "\n",
    "print(f\"\\n--- Pattern Analyst Output (first 2000 chars) ---\")\n",
    "print(analyses.get(\"cross_perspective_integrator\", \"Not found\")[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e336785c",
   "metadata": {},
   "source": [
    "## Stage 2b: Cross-Text Synthesis of Integrated Analyses\n",
    "\n",
    "Patterns that appear across multiple text analyses are synthesized. This stage takes all the cross-perspective integration outputs and identifies overaching techniques, complementary findings, and so on, in order to construct a highly specific conclusion on the techniques that are employed in the text samples. It attempts in other words a synthesis of all analysis, across perspectives and across text samples.\n",
    "\n",
    "This is a single document. In order to track provenance, the text samples and analyst types that went into its construction are gathered and included in the storage in the project database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92d0cdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 cross-perspective integration results\n",
      "Sample IDs: ['sample_001', 'sample_002', 'sample_003', 'sample_004', 'sample_005']\n"
     ]
    }
   ],
   "source": [
    "from belletrist.models import CrossTextSynthesizerConfig\n",
    "\n",
    "# Get all samples that have cross-perspective integration results\n",
    "all_samples = store.list_samples()\n",
    "pattern_analyst = CrossPerspectiveIntegratorConfig.analyst_name()\n",
    "\n",
    "# Retrieve all pattern recognition analyses\n",
    "integrated_analyses = {}\n",
    "for sample_id in all_samples:\n",
    "    pattern_analysis = store.get_analysis(sample_id, pattern_analyst)\n",
    "    if pattern_analysis:\n",
    "        integrated_analyses[sample_id] = pattern_analysis\n",
    "    else:\n",
    "        print(f\"⚠ Sample {sample_id} missing cross-perspective integration results\")\n",
    "\n",
    "print(f\"Found {len(integrated_analyses)} cross-perspective integration results\")\n",
    "print(f\"Sample IDs: {list(integrated_analyses.keys())}\")\n",
    "\n",
    "if len(integrated_analyses) < 2:\n",
    "    print(f\"\\n⚠ Need at least 2 pattern recognition analyses for cross-text synthesis. Got {len(integrated_analyses)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c138e9ab",
   "metadata": {},
   "source": [
    "This is where the analysis is run. This can take time, since it requires running an LLM, however, only one LLM call in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76a60796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross-Text Synthesis... ✓ (18193 chars)\n",
      "Saved as: cross_text_synthesis_001\n"
     ]
    }
   ],
   "source": [
    "cross_text_config = CrossTextSynthesizerConfig(\n",
    "    integrated_analyses=integrated_analyses\n",
    ")\n",
    "\n",
    "# Check if cross-text synthesis already exists (resume support)\n",
    "existing_syntheses = store.list_syntheses('cross_text_synthesis')\n",
    "if existing_syntheses:\n",
    "    cross_text_id = existing_syntheses[-1]  # Use most recent\n",
    "    cross_text_synthesis = store.get_synthesis(cross_text_id)\n",
    "    print(f\"✓ Cross-text synthesis already exists: {cross_text_id}\")\n",
    "    print(f\"  (Created: {cross_text_synthesis['created_at']}, {len(cross_text_synthesis['output'])} chars)\")\n",
    "else:\n",
    "    cross_text_prompt = prompt_maker.render(cross_text_config)\n",
    "        \n",
    "    print(\"Running Cross-Text Synthesis...\", end=\" \")\n",
    "    cross_text_response = llm.complete(cross_text_prompt)\n",
    "    print(f\"✓ ({len(cross_text_response.content)} chars)\")\n",
    "        \n",
    "    # Save to ResultStore with auto-generated ID and full provenance\n",
    "    sample_contributions = [(sid, pattern_analyst) for sid in integrated_analyses.keys()]\n",
    "    cross_text_id = store.save_synthesis(\n",
    "        synthesis_type=cross_text_config.synthesis_type(),\n",
    "        output=cross_text_response.content,\n",
    "        model=cross_text_response.model,\n",
    "        sample_contributions=sample_contributions,\n",
    "        config=cross_text_config\n",
    "    )\n",
    "    print(f\"Saved as: {cross_text_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04cf7ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cross-Text Synthesis (first 1000 chars) ---\n",
      "## SYNTHESIS OF INTEGRATED TEXT ANALYSES\n",
      "\n",
      "### I. Stable Core Patterns\n",
      "\n",
      "#### 1. Clear and Concise Definitions\n",
      "   - **Frequency**: 5/5 texts\n",
      "   - **Specification**: Introduce complex concepts with clear, precise definitions followed by examples. Use a combination of theoretical definition and concrete illustrations to ensure clarity.\n",
      "   - **Examples**:\n",
      "     - \"The quality I have in mind is that of being affected pleasurably or the reverse by many things, and by the right things.\"\n",
      "     - \"Mind and matter alike are logical constructions.\"\n",
      "     - \"Suppose that you are in a train on a long straight railway, and that you are traveling at three-fifths of the velocity of light.\"\n",
      "   - **Centrality**: Foundational\n",
      "   - **Mechanical Specification**: Definitions typically 10-15 words, followed by 2-3 examples or analogies.\n",
      "   - **Distribution Pattern**: Uniformly distributed, primarily in introductory paragraphs.\n",
      "   - **Prescriptive Dosage**: STRUCTURAL (70-80%)\n",
      "\n",
      "#### 2. Complex Sentences with Subo\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Cross-Text Synthesis (first 1000 chars) ---\")\n",
    "print(cross_text_response.content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec70fd7",
   "metadata": {},
   "source": [
    "## Stage 3: Synthesize Prescriptive Writing Document\n",
    "\n",
    "The final stage converts the descriptive cross-text synthesis into actionable prescriptive writing principles. This generates a style guide that can be used to instruct an LLM to write in a similar style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc63cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cross-text synthesis: cross_text_synthesis_001\n"
     ]
    }
   ],
   "source": [
    "cross_text_syntheses = store.list_syntheses('cross_text_synthesis')\n",
    "cross_text_synthesis_to_analyze_id = cross_text_syntheses[-1]\n",
    "print(f\"Using cross-text synthesis: {cross_text_synthesis_to_analyze_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a3f0e",
   "metadata": {},
   "source": [
    "The following step executes the LLM and can therefore take time. The result is stored for provenance tracking in the project database alongside relevant metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1e2c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Synthesizer of Writing Style Principles... ✓ (24599 chars)\n",
      "Saved as: principles_guide_001\n"
     ]
    }
   ],
   "source": [
    "from belletrist.models import SynthesizerOfPrinciplesConfig\n",
    "\n",
    "# Check if principles guide already exists (resume support)\n",
    "existing_principles = store.list_syntheses('principles_guide')\n",
    "if existing_principles:\n",
    "    principles_id = existing_principles[-1]  # Use most recent\n",
    "    principles_synthesis = store.get_synthesis(principles_id)\n",
    "    print(f\"✓ Principles guide already exists: {principles_id}\")\n",
    "    print(f\"  (Created: {principles_synthesis['created_at']}, {len(principles_synthesis['output'])} chars)\")\n",
    "else:\n",
    "    # Build principles guide config and prompt\n",
    "    cross_text_synthesis_to_analyze = store.get_synthesis(cross_text_synthesis_to_analyze_id)\n",
    "    principles_config = SynthesizerOfPrinciplesConfig(\n",
    "        synthesis_document=cross_text_synthesis_to_analyze['output']\n",
    "    )\n",
    "    principles_prompt = prompt_maker.render(principles_config)\n",
    "        \n",
    "    # Run principles synthesis\n",
    "    print(\"Running Synthesizer of Writing Style Principles...\", end=\" \")\n",
    "    principles_response = llm.complete(principles_prompt)\n",
    "    print(f\"✓ ({len(principles_response.content)} chars)\")\n",
    "        \n",
    "    # Save to ResultStore with parent linkage (inherits provenance)\n",
    "    principles_id = store.save_synthesis(\n",
    "        synthesis_type=principles_config.synthesis_type(),\n",
    "        output=principles_response.content,\n",
    "        model=principles_response.model,\n",
    "        sample_contributions=[],  # Inherited from parent\n",
    "        config=principles_config,\n",
    "        parent_synthesis_id=cross_text_synthesis_to_analyze_id\n",
    "    )\n",
    "    print(f\"Saved as: {principles_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b4eb824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Principles Guide (first 2000 chars) ---\n",
      "# THE SYNTHESIST: A STYLE GUIDE FOR WRITERS\n",
      "\n",
      "## SECTION 1: FOUNDATIONAL PRINCIPLES\n",
      "\n",
      "### Subordinate Complexity to Simple Frames\n",
      "\n",
      "Place your core claim in an independent clause of 8-12 words. Let qualifications, complications, and elaborations occupy subordinate positions—trailing clauses, parenthetical asides, subsequent sentences.\n",
      "\n",
      "This works because readers process main clauses as assertions and subordinate clauses as modifications. When your central point occupies the grammatical center, it occupies the cognitive center. Bury it in a dependent clause and readers must excavate.\n",
      "\n",
      "Notice the efficiency: \"The quality I have in mind is that of being affected pleasurably or the reverse by many things, and by the right things.\" Eight words. The claim lands before any qualification. Complexity can follow; it cannot precede.\n",
      "\n",
      "This principle enables everything else. Without clear main clauses, analogies lose their anchor. Without syntactic hierarchy, even precise vocabulary cannot guide the reader's attention.\n",
      "\n",
      "### Use Precise Definitions\n",
      "\n",
      "Introduce complex concepts with clear, precise definitions followed by examples. This is STRUCTURAL (70-80%). Use in approximately 70-80% of explanatory sentences.\n",
      "\n",
      "This works because precise definitions set a foundational understanding that logical progression builds upon, ensuring the reader follows complex ideas seamlessly.\n",
      "\n",
      "Notice the clarity: \"Mind and matter alike are logical constructions.\" The definition is concise and followed by an example: \"The particulars out of which they are constructed, or from which they are inferred, have various relations, some of which are studied by physics, others by psychology.\"\n",
      "\n",
      "This principle ensures clarity and coherence throughout the text. Without clear definitions, the text would lack a foundational understanding of complex concepts, making it difficult for readers to follow.\n",
      "\n",
      "### Maintain Logical Progression\n",
      "\n",
      "Use logical progression within and between paragraphs. Employ explicit connectors an\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Principles Guide (first 2000 chars) ---\")\n",
    "print(principles_response.content[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e553843",
   "metadata": {},
   "source": [
    "## Querying Synthesis Metadata\n",
    "\n",
    "The ResultStore tracks full provenance for all syntheses. Query metadata to understand what samples, analysts, and models contributed to each synthesis.\n",
    "\n",
    "**This code is for convenience and not required to generate the writing instruction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b59af8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Syntheses\n",
      "==================================================\n",
      "\n",
      "cross_text_synthesis: 1 found\n",
      "  - cross_text_synthesis_001\n",
      "\n",
      "principles_guide: 1 found\n",
      "  - principles_guide_001\n",
      "\n",
      "\n",
      "Detailed Metadata Example\n",
      "==================================================\n",
      "\n",
      "Synthesis ID: principles_guide_001\n",
      "Type: principles_guide\n",
      "Model: mistral-large-2411\n",
      "Created: 2025-11-27T18:18:13.356530\n",
      "Parent: cross_text_synthesis_001\n",
      "\n",
      "Metadata:\n",
      "  Samples: 0\n",
      "  Sample IDs: []\n",
      "  Model homogeneous: True\n",
      "  Models used: ['mistral-large-2411']\n",
      "\n",
      "\n",
      "Full Provenance Tree\n",
      "==================================================\n",
      "\n",
      "Principles Guide: principles_guide_001\n",
      "  Created: 2025-11-27T18:18:13.356530\n",
      "  Model: mistral-large-2411\n",
      "\n",
      "  Parent (Cross-Text): cross_text_synthesis_001\n",
      "    Sample contributions: 5\n",
      "      - sample_001 / cross_perspective_integrator\n",
      "      - sample_002 / cross_perspective_integrator\n",
      "      - sample_003 / cross_perspective_integrator\n",
      "      ... and 2 more\n"
     ]
    }
   ],
   "source": [
    "# List all syntheses\n",
    "print(\"All Syntheses\")\n",
    "print(\"=\" * 50)\n",
    "for synth_type in ['cross_text_synthesis', 'principles_guide']:\n",
    "    syntheses = store.list_syntheses(synth_type)\n",
    "    print(f\"\\n{synth_type}: {len(syntheses)} found\")\n",
    "    for synth_id in syntheses:\n",
    "        print(f\"  - {synth_id}\")\n",
    "\n",
    "# Get detailed metadata for a synthesis\n",
    "if store.list_syntheses():\n",
    "    print(\"\\n\\nDetailed Metadata Example\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get first principles guide (or first cross-text if none)\n",
    "    principles = store.list_syntheses('principles_guide')\n",
    "    if principles:\n",
    "        synth_id = principles[0]\n",
    "    else:\n",
    "        synth_id = store.list_syntheses()[0]\n",
    "    \n",
    "    synth_with_meta = store.get_synthesis_with_metadata(synth_id)\n",
    "    \n",
    "    print(f\"\\nSynthesis ID: {synth_with_meta['synthesis_id']}\")\n",
    "    print(f\"Type: {synth_with_meta['type']}\")\n",
    "    print(f\"Model: {synth_with_meta['model']}\")\n",
    "    print(f\"Created: {synth_with_meta['created_at']}\")\n",
    "    print(f\"Parent: {synth_with_meta['parent_id']}\")\n",
    "    \n",
    "    if synth_with_meta.get('metadata'):\n",
    "        meta = synth_with_meta['metadata']\n",
    "        print(f\"\\nMetadata:\")\n",
    "        print(f\"  Samples: {meta['num_samples']}\")\n",
    "        print(f\"  Sample IDs: {meta['sample_ids']}\")\n",
    "        print(f\"  Model homogeneous: {meta['is_homogeneous_model']}\")\n",
    "        print(f\"  Models used: {meta['models_used']}\")\n",
    "\n",
    "# Get full provenance tree\n",
    "if store.list_syntheses('principles_guide'):\n",
    "    print(\"\\n\\nFull Provenance Tree\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for p_id in store.list_syntheses('principles_guide'):\n",
    "        provenance = store.get_synthesis_provenance(p_id)\n",
    "    \n",
    "        print(f\"\\nPrinciples Guide: {provenance['synthesis']['synthesis_id']}\")\n",
    "        print(f\"  Created: {provenance['synthesis']['created_at']}\")\n",
    "        print(f\"  Model: {provenance['synthesis']['model']}\")\n",
    "    \n",
    "        if provenance['parent']:\n",
    "            parent = provenance['parent']\n",
    "            print(f\"\\n  Parent (Cross-Text): {parent['synthesis']['synthesis_id']}\")\n",
    "            print(f\"    Sample contributions: {len(parent['sample_contributions'])}\")\n",
    "            for sample_id, analyst in parent['sample_contributions'][:3]:\n",
    "                print(f\"      - {sample_id} / {analyst}\")\n",
    "            if len(parent['sample_contributions']) > 3:\n",
    "                print(f\"      ... and {len(parent['sample_contributions']) - 3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434b288d",
   "metadata": {},
   "source": [
    "## Exporting Syntheses to Filesystem\n",
    "\n",
    "Export final syntheses to text files with YAML metadata headers for consumption by other tools or LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32628f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: outputs/cross_text_synthesis_001.txt\n",
      "Exported: outputs/principles_guide_001.txt\n",
      "Exported for style evaluation: outputs/derived_style_instructions_mistral_1127.txt\n",
      "\n",
      "All syntheses exported to /Users/andersohrn/PycharmProjects/russell_writes/outputs\n"
     ]
    }
   ],
   "source": [
    "# Create outputs directory\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export cross-text synthesis\n",
    "cross_text_syntheses = store.list_syntheses('cross_text_synthesis')\n",
    "if cross_text_syntheses:\n",
    "    for synth_id in cross_text_syntheses:\n",
    "        output_path = outputs_dir / f\"{synth_id}.txt\"\n",
    "        store.export_synthesis(synth_id, output_path, metadata_format='yaml')\n",
    "        print(f\"Exported: {output_path}\")\n",
    "\n",
    "# Export principles guide\n",
    "principles_guides = store.list_syntheses('principles_guide')\n",
    "if principles_guides:\n",
    "    for synth_id in principles_guides:\n",
    "        output_path = outputs_dir / f\"{synth_id}.txt\"\n",
    "        store.export_synthesis(synth_id, output_path, metadata_format='yaml')\n",
    "        print(f\"Exported: {output_path}\")\n",
    "        \n",
    "        # Also create a special \"derived_style_instructions.txt\" for style_evaluation.ipynb\n",
    "        if synth_id == principles_guides[-1]:  # Use latest\n",
    "            instructions_path = outputs_dir / \"derived_style_instructions_mistral_1127.txt\"\n",
    "            store.export_synthesis(synth_id, instructions_path, metadata_format='yaml')\n",
    "            print(f\"Exported for style evaluation: {instructions_path}\")\n",
    "\n",
    "print(f\"\\nAll syntheses exported to {outputs_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973acfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (russell_writes)",
   "language": "python",
   "name": "russell_writes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
