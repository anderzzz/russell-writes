{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec0fde1",
   "metadata": {},
   "source": [
    "# Multi-Analyst Text Analysis Pipeline\n",
    "\n",
    "In this notebook we demonstrate the full pipeline for analyzing text through multiple specialist lenses (rhetorician, syntactician, lexicologist, etc.) and synthesizing their observations into \n",
    "* a unified writing style analysis from the text samples,\n",
    "* an instruction of how to write in the analyzed style.\n",
    "\n",
    "The workflow is *agentic* in that it involves several distinct agents built on Large Language Models (LLMs), however, the order and relation between each agent is set, not dynamically derived.\n",
    "\n",
    "The analysis and its details are described in this blog post: **INSERT LINK**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031d3c6",
   "metadata": {},
   "source": [
    "## Installations and Preparations\n",
    "External libraries are installed and tested to be in working order.\n",
    "\n",
    "Key dependencies:\n",
    "* LiteLLM (model router such that different LLM APIs can be readily employed)\n",
    "* Jinja (create prompts with variables and conditional logic)\n",
    "* Pydantic (create prompts from variables with validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed7bac",
   "metadata": {},
   "source": [
    "**Install requirements.** Only needed if running in fresh kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f97959e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:02:22.033495Z",
     "start_time": "2025-11-19T18:02:20.240014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm==1.79.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.79.3)\n",
      "Requirement already satisfied: pydantic==2.7.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.7.4)\n",
      "Requirement already satisfied: jinja2>=3.1.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: aiohttp>=3.10 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (3.13.2)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (8.3.1)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: httpx>=0.23.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (8.7.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (4.25.1)\n",
      "Requirement already satisfied: openai>=1.99.5 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.22.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in ./venv/lib/python3.11/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./venv/lib/python3.11/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2>=3.1.0->-r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.22.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in ./venv/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.29.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./venv/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in ./venv/lib/python3.11/site-packages (from tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (1.1.4)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (6.0.3)\n",
      "Requirement already satisfied: shellingham in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (0.20.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad55d31",
   "metadata": {},
   "source": [
    "Check that LiteLLM was installed correctly. List the providers available via LiteLLM router."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d33edd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providers\n",
      "=========\n",
      "* openai\n",
      "* openai_like\n",
      "* bytez\n",
      "* xai\n",
      "* custom_openai\n",
      "* text-completion-openai\n",
      "* cohere\n",
      "* cohere_chat\n",
      "* clarifai\n",
      "* anthropic\n",
      "* anthropic_text\n",
      "* replicate\n",
      "* huggingface\n",
      "* together_ai\n",
      "* datarobot\n",
      "* openrouter\n",
      "* cometapi\n",
      "* vertex_ai\n",
      "* vertex_ai_beta\n",
      "* gemini\n",
      "* ai21\n",
      "* baseten\n",
      "* azure\n",
      "* azure_text\n",
      "* azure_ai\n",
      "* sagemaker\n",
      "* sagemaker_chat\n",
      "* bedrock\n",
      "* vllm\n",
      "* nlp_cloud\n",
      "* petals\n",
      "* oobabooga\n",
      "* ollama\n",
      "* ollama_chat\n",
      "* deepinfra\n",
      "* perplexity\n",
      "* mistral\n",
      "* groq\n",
      "* nvidia_nim\n",
      "* cerebras\n",
      "* baseten\n",
      "* ai21_chat\n",
      "* volcengine\n",
      "* codestral\n",
      "* text-completion-codestral\n",
      "* deepseek\n",
      "* sambanova\n",
      "* maritalk\n",
      "* cloudflare\n",
      "* fireworks_ai\n",
      "* friendliai\n",
      "* watsonx\n",
      "* watsonx_text\n",
      "* triton\n",
      "* predibase\n",
      "* databricks\n",
      "* empower\n",
      "* github\n",
      "* custom\n",
      "* litellm_proxy\n",
      "* hosted_vllm\n",
      "* llamafile\n",
      "* lm_studio\n",
      "* galadriel\n",
      "* gradient_ai\n",
      "* github_copilot\n",
      "* novita\n",
      "* meta_llama\n",
      "* featherless_ai\n",
      "* nscale\n",
      "* nebius\n",
      "* dashscope\n",
      "* moonshot\n",
      "* v0\n",
      "* heroku\n",
      "* oci\n",
      "* morph\n",
      "* lambda_ai\n",
      "* vercel_ai_gateway\n",
      "* wandb\n",
      "* ovhcloud\n",
      "* lemonade\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import litellm\n",
    "    print('Providers\\n=========')\n",
    "    print('* ' + '\\n* '.join(litellm.LITELLM_CHAT_PROVIDERS))\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Cannot import litellm: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1bbff",
   "metadata": {},
   "source": [
    "## Initialize Base Objects\n",
    "The base objects part of the current project library (`belletrist`) are initialized. They are:\n",
    "* `LLM`: the LLM object.\n",
    "* `LLMConfig`: the configuration of the LLM object, such as what model to use.\n",
    "* `PromptMaker`: generates prompts from templates and variables\n",
    "* `DataSampler`: retrieves and samples text at a source directory\n",
    "* `ResultStore`: simple database object to save intermediate and final outputs\n",
    "\n",
    "The LLM to use is set by the `model_string`, which is constructed as `<provider>/<model>`, the providers defined by the `litellm` package, see in particular `litellm.LITELLM_CHAT_PROVIDERS`. The API key to the provider should be stored in an environment variable with name defined in `model_provider_api_key_env_var`. You need to create that yourself for the provider of interest. \n",
    "\n",
    "Do **not** store the API key as a string variable directly in the notebook, you're at risk of exposing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5acd264",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_string = 'anthropic/claude-sonnet-4-5-20250929'\n",
    "model_provider_api_key_env_var = 'ANTHROPIC_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5439ec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:02:29.927627Z",
     "start_time": "2025-11-19T18:02:29.858316Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from belletrist import LLM, LLMConfig, PromptMaker, DataSampler, ResultStore\n",
    "\n",
    "llm = LLM(LLMConfig(\n",
    "    model=model_string,\n",
    "    api_key=os.environ.get(model_provider_api_key_env_var)\n",
    "))\n",
    "prompt_maker = PromptMaker()\n",
    "sampler = DataSampler(\n",
    "    data_path=(Path(os.getcwd()) / \"data\" / \"russell\").resolve()\n",
    ")\n",
    "store = ResultStore(Path(f\"{os.getcwd()}/belletrist_storage_sonnet.db\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39980881",
   "metadata": {},
   "source": [
    "In case a clean run is wanted, the old contents of the database are discarded with a result store reset. Do **not** run this reset if content should be preserved from previous runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b51422e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52be2000",
   "metadata": {},
   "source": [
    "## Generate and Store Text Samples to be Analyzed\n",
    "\n",
    "The `DataSampler` retrieves paragraphs from the corpus of text. The retrieval can be a random sample of consecutive paragraphs (via the method `sample_segment`) or a specific file and paragraph range (via the method `get_paragraph_chunk`).\n",
    "\n",
    "As illustration of the process, a random four-paragraph long segment is sampled below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d9634f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text source: /Users/andersohrn/PycharmProjects/russell_writes/data/russell/the_analysis_of_mind.txt\n",
      "Paragraph range: 323 - 327\n",
      "\n",
      "(1) Hume, who gives the names \"impressions\" and \"ideas\" to what may,\n",
      "for present purposes, be identified with our \"sensations\" and \"images,\"\n",
      "speaks of impressions as \"those perceptions which enter with most force\n",
      "and violence\" while he defines ideas as \"the faint images of these (i.e.\n",
      "of impressions) in thinking and reasoning.\" His immediately following\n",
      "observations, however, show the inadequacy of his criteria of \"force\"\n",
      "and \"faintness.\" He says:\n",
      "\n",
      "\"I believe it will not be very necessary to employ many words in\n",
      "explaining this distinction. Every one of himself will readily perceive\n",
      "the difference betwixt feeling and thinking. The common degrees of these\n",
      "are easily distinguished, though it is not impossible but in particular\n",
      "instances they may very nearly approach to each other. Thus in sleep, in\n",
      "a fever, in madness, or in any very violent emotions of soul, our ideas\n",
      "may approach to our impressions; as, on the other hand, it sometimes\n",
      "happens, that our impressions are so faint and low that we cannot\n",
      "distinguish them from our ideas. But notwithstanding this near\n",
      "resemblance in a few instances, they are in general so very different,\n",
      "that no one can make a scruple to rank them under distinct heads, and\n",
      "assign to each a peculiar name to mark the difference\" (\"Treatise of\n",
      "Human Nature,\" Part I, Section I).\n",
      "\n",
      "I think Hume is right in holding that they should be ranked under\n",
      "distinct heads, with a peculiar name for each. But by his own confession\n",
      "in the above passage, his criterion for distinguishing them is not\n",
      "always adequate. A definition is not sound if it only applies in cases\n",
      "where the difference is glaring: the essential purpose of a definition\n",
      "is to provide a mark which is applicable even in marginal cases--except,\n",
      "of course, when we are dealing with a conception, like, e.g. baldness,\n",
      "which is one of degree and has no sharp boundaries. But so far we have\n",
      "seen no reason to think that the difference between sensations and\n",
      "images is only one of degree.\n",
      "\n",
      "Professor Stout, in his \"Manual of Psychology,\" after discussing various\n",
      "ways of distinguishing sensations and images, arrives at a view which is\n",
      "a modification of Hume's. He says (I quote from the second edition):\n"
     ]
    }
   ],
   "source": [
    "text_sample = sampler.sample_segment(p_length=4)\n",
    "print(f'Text source: {text_sample.file_path}')\n",
    "print(f'Paragraph range: {text_sample.paragraph_start} - {text_sample.paragraph_end}')\n",
    "print(f'\\n{text_sample.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e4d412",
   "metadata": {},
   "source": [
    "A number of text samples are retrieved (**set `n_sample` to the desired number**) and each sample comprises a set number of paragraphs (**set `m_paragraphs_per_sample` to the desired number**). These text samples are stored in the project result stored with keys like `sample_001`, `sample_002` and so on; these keys are henceforth referring to specific text samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1ae300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus it becomes evident that the real table, if there is one, is not the\n",
      "same as what we immediately experience by sight or touch or hearing. The\n",
      "real table, if there is one, is not _immediately_ known to us at all,\n",
      "but must be an inference from what is immediately known. Hence, two very\n",
      "difficult questions at once arise; namely, (1) Is there a real table at\n",
      "all? (2) If so, what sort of object can it be?\n",
      "\n",
      "It will help us in considering these questions to have a few simple\n",
      "terms of which the meaning is definite and clear. Let us give the name\n",
      "of 'sense-data' to the things that are immediately known in sensation:\n",
      "such things as colours, sounds, smells, hardnesses, roughnesses, and\n",
      "so on. We shall give the name 'sensation' to the experience of being\n",
      "immediately aware of these things. Thus, whenever we see a colour,\n",
      "we have a sensation _of_ the colour, but the colour itself is a\n",
      "sense-datum, not a sensation. The colour is that _of_ which we are\n",
      "immediately aware, and the awareness itself is the sensation. It is\n",
      "plain that if we are to know anything about the table, it must be\n",
      "by means of the sense-data--brown colour, oblong shape, smoothness,\n",
      "etc.--which we associate with the table; but, for the reasons which have\n",
      "been given, we cannot say that the table is the sense-data, or even\n",
      "that the sense-data are directly properties of the table. Thus a problem\n",
      "arises as to the relation of the sense-data to the real table, supposing\n",
      "there is such a thing.\n",
      "\n",
      "The real table, if it exists, we will call a 'physical object'. Thus\n",
      "we have to consider the relation of sense-data to physical objects.\n",
      "The collection of all physical objects is called 'matter'. Thus our two\n",
      "questions may be re-stated as follows: (1) Is there any such thing as\n",
      "matter? (2) If so, what is its nature?\n",
      "\n",
      "The philosopher who first brought prominently forward the reasons\n",
      "for regarding the immediate objects of our senses as not existing\n",
      "independently of us was Bishop Berkeley (1685-1753). His _Three\n",
      "Dialogues between Hylas and Philonous, in Opposition to Sceptics and\n",
      "Atheists_, undertake to prove that there is no such thing as matter at\n",
      "all, and that the world consists of nothing but minds and their ideas.\n",
      "Hylas has hitherto believed in matter, but he is no match for Philonous,\n",
      "who mercilessly drives him into contradictions and paradoxes, and makes\n",
      "his own denial of matter seem, in the end, as if it were almost common\n",
      "sense. The arguments employed are of very different value: some are\n",
      "important and sound, others are confused or quibbling. But Berkeley\n",
      "retains the merit of having shown that the existence of matter is\n",
      "capable of being denied without absurdity, and that if there are any\n",
      "things that exist independently of us they cannot be the immediate\n",
      "objects of our sensations.\n",
      "\n",
      "There are two different questions involved when we ask whether matter\n",
      "exists, and it is important to keep them clear. We commonly mean by\n",
      "'matter' something which is opposed to 'mind', something which we think\n",
      "of as occupying space and as radically incapable of any sort of thought\n",
      "or consciousness. It is chiefly in this sense that Berkeley denies\n",
      "matter; that is to say, he does not deny that the sense-data which we\n",
      "commonly take as signs of the existence of the table are really signs\n",
      "of the existence of _something_ independent of us, but he does deny\n",
      "that this something is non-mental, that it is neither mind nor ideas\n",
      "entertained by some mind. He admits that there must be something which\n",
      "continues to exist when we go out of the room or shut our eyes, and that\n",
      "what we call seeing the table does really give us reason for believing\n",
      "in something which persists even when we are not seeing it. But he\n",
      "thinks that this something cannot be radically different in nature from\n",
      "what we see, and cannot be independent of seeing altogether, though it\n",
      "must be independent of _our_ seeing. He is thus led to regard the 'real'\n",
      "table as an idea in the mind of God. Such an idea has the required\n",
      "permanence and independence of ourselves, without being--as matter would\n",
      "otherwise be--something quite unknowable, in the sense that we can only\n",
      "infer it, and can never be directly and immediately aware of it.\n"
     ]
    }
   ],
   "source": [
    "print(sampler.get_paragraph_chunk(2, slice(10,15)).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72d3d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 5\n",
    "m_paragraphs_per_sample = 5\n",
    "\n",
    "for _ in range(n_sample):\n",
    "    sample_id = f'sample_{len(store.list_samples()) + 1:03d}'\n",
    "    segment = sampler.sample_segment(p_length=m_paragraphs_per_sample)\n",
    "    store.save_segment(sample_id, segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd0397a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample keys:\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sample_001', 'sample_002', 'sample_003', 'sample_004', 'sample_005']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sample keys:\\n============')\n",
    "store.list_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc02b93a",
   "metadata": {},
   "source": [
    "## Step 1: Construct the Analyst Agents and Analyze Text Samples\n",
    "\n",
    "Send the text samples through each specialist analyst. Each produces an independent analysis from their domain expertise.\n",
    "\n",
    "**Prompt structure for each analyst is:**\n",
    "1. Preamble instruction of task ahead \n",
    "2. Analyst-specific instruction template\n",
    "3. Text to analyze\n",
    "\n",
    "Note that the execution of this can take time since it involves invoking LLMs, once per analyst and text sample. These are however independent analyses, and can therefore *in principle* be run in parallel, though the implementation below does not utilize that fact.\n",
    "\n",
    "Note that the agents are distinguished by their prompts, which are obtained via prompt models defined within the `bellatrist` project library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658fca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from belletrist.models import (\n",
    "    PreambleInstructionConfig,\n",
    "    PreambleTextConfig,\n",
    "    RhetoricianConfig,\n",
    "    SyntacticianConfig,\n",
    "    LexicologistConfig,\n",
    "    InformationArchitectConfig,\n",
    "    EfficiencyAuditorConfig,\n",
    "    CrossPerspectiveIntegratorConfig,\n",
    ")\n",
    "ANALYSTS = [\"rhetorician\", \"syntactician\", \"lexicologist\", \"information_architect\", \"efficiency_auditor\"]\n",
    "ANALYST_CONFIGS = {\n",
    "    \"rhetorician\": RhetoricianConfig,\n",
    "    \"syntactician\": SyntacticianConfig,\n",
    "    \"lexicologist\": LexicologistConfig,\n",
    "    \"information_architect\": InformationArchitectConfig,\n",
    "    \"efficiency_auditor\": EfficiencyAuditorConfig,\n",
    "}\n",
    "\n",
    "def build_analyst_prompt(preamble_instruction: str, analyst_prompt: str, preamble_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Helper function to construct the full prompt for an analyst.\n",
    "    \n",
    "    \"\"\"\n",
    "    return f\"{preamble_instruction}\\n\\n{analyst_prompt}\\n\\n{preamble_text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf540537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 samples with 5 analysts each\n",
      "\n",
      "Sample: sample_001\n",
      "  ✓ rhetorician (already done)\n",
      "  ✓ syntactician (already done)\n",
      "  ✓ lexicologist (already done)\n",
      "  ✓ information_architect (already done)\n",
      "  ✓ efficiency_auditor (already done)\n",
      "\n",
      "Sample: sample_002\n",
      "  ✓ rhetorician (already done)\n",
      "  ✓ syntactician (already done)\n",
      "  ✓ lexicologist (already done)\n",
      "  ✓ information_architect (already done)\n",
      "  ✓ efficiency_auditor (already done)\n",
      "\n",
      "Sample: sample_003\n",
      "  ✓ rhetorician (already done)\n",
      "  ✓ syntactician (already done)\n",
      "  ✓ lexicologist (already done)\n",
      "  ✓ information_architect (already done)\n",
      "  ✓ efficiency_auditor (already done)\n",
      "\n",
      "Sample: sample_004\n",
      "  ✓ rhetorician (already done)\n",
      "  ✓ syntactician (already done)\n",
      "  ✓ lexicologist (already done)\n",
      "  ✓ information_architect (already done)\n",
      "  Running efficiency_auditor... ✓ (8652 chars)\n",
      "\n",
      "Sample: sample_005\n",
      "  Running rhetorician... ✓ (10576 chars)\n",
      "  Running syntactician... ✓ (13369 chars)\n",
      "  Running lexicologist... ✓ (8486 chars)\n",
      "  Running information_architect... ✓ (11830 chars)\n",
      "  Running efficiency_auditor... ✓ (8617 chars)\n",
      "\n",
      "All analyses complete for 5 samples\n"
     ]
    }
   ],
   "source": [
    "# Get all samples from the store\n",
    "all_samples = store.list_samples()\n",
    "print(f\"Processing {len(all_samples)} samples with {len(ANALYSTS)} analysts each\\n\")\n",
    "\n",
    "# Outer loop: iterate over each text sample\n",
    "for sample_id in all_samples:\n",
    "    print(f\"Sample: {sample_id}\")\n",
    "    \n",
    "    # Get the sample text\n",
    "    sample = store.get_sample(sample_id)\n",
    "    text = sample['text']\n",
    "    \n",
    "    # Build shared prompt components (reused across all analysts for this sample)\n",
    "    preamble_instruction = prompt_maker.render(PreambleInstructionConfig())\n",
    "    preamble_text = prompt_maker.render(PreambleTextConfig(text_to_analyze=text))\n",
    "    \n",
    "    # Inner loop: run each analyst on this sample\n",
    "    for analyst_name in ANALYSTS:\n",
    "        # Check if analysis already exists (resume support)\n",
    "        if store.get_analysis(sample_id, analyst_name):\n",
    "            print(f\"  ✓ {analyst_name} (already done)\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Running {analyst_name}...\", end=\" \")\n",
    "        \n",
    "        # Get analyst-specific prompt using the config class\n",
    "        analyst_config = ANALYST_CONFIGS[analyst_name]()\n",
    "        analyst_prompt = prompt_maker.render(analyst_config)\n",
    "        full_prompt = build_analyst_prompt(preamble_instruction, analyst_prompt, preamble_text)\n",
    "        \n",
    "        # Run analysis and save result\n",
    "        response = llm.complete(full_prompt)\n",
    "        store.save_analysis(sample_id, analyst_name, response.content, response.model)\n",
    "        \n",
    "        print(f\"✓ ({len(response.content)} chars)\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f\"All analyses complete for {len(all_samples)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aeaec6",
   "metadata": {},
   "source": [
    "Verification that analysis was run as expected and yielded analysis results. Excerpt of one specific analysis retrieved from project database and printed for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b3ba1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete: True\n",
      "\n",
      "Sample: sample_005\n",
      "Source: File 5, paragraphs 278-283\n",
      "Analyses available: ['efficiency_auditor', 'information_architect', 'lexicologist', 'rhetorician', 'syntactician']\n",
      "\n",
      "--- Rhetorician Output (first 500 chars) ---\n",
      "# ECONOMY AND NECESSITY ANALYSIS\n",
      "\n",
      "## 1. WORD ECONOMY\n",
      "\n",
      "### Redundancies Identified\n",
      "\n",
      "**\"certain\" overuse**: The word appears excessively (8 times), often adding no specificity:\n",
      "- \"certain light waves\" / \"certain sensations\" / \"certain concealed ways\" / \"certain groups\" / \"certain very abstract logical relations\" / \"certain points\" / \"certain distances\" / \"certain photographic plates\"\n",
      "\n",
      "In most cases, \"certain\" functions as a hedge rather than a specifier. Compare:\n",
      "- BEFORE: \"certain light waves reach its eyes\"\n",
      "- AFTER: \"light waves reach its eyes\"\n",
      "The loss is negligible; the author seems to use \"certain\" to suggest \"particular but unspecified,\" but this becomes formulaic.\n",
      "\n",
      "**Tautological phrasing**:\n",
      "- \"groups of occurrences happen together, that is to say, in neighboring parts of space-time\" — the appositive restates rather than clarifies\n",
      "- \"testimony consists of sound waves and demands psychological as well as physical interpretation\" — \"consists of\" + \"demands\" could be compressed\n",
      "\n",
      "### Long Words: Assessment\n",
      "\n",
      "Generally justified. The prose uses technical vocabulary appropriately:\n",
      "- \"electromagnetic disturbances\" (technical necessity)\n",
      "- \"experimentally\" (precise)\n",
      "- \"interpretation\" (conceptually distinct from \"meaning\" or \"reading\")\n",
      "\n",
      "One exception: \"conceivable\" in \"no conceivable apparatus\" — \"possible\" would suffice.\n",
      "\n",
      "### Modification Density\n",
      "\n",
      "Moderate to heavy. Examples of necessary modification:\n",
      "- \"gross delusion\" — \"gross\" adds rhetorical force\n",
      "- \"highly abbreviated form o\n"
     ]
    }
   ],
   "source": [
    "sample_id = 'sample_005'\n",
    "is_complete = store.is_complete(sample_id, ANALYSTS)\n",
    "print(f\"Analysis complete: {is_complete}\")\n",
    "\n",
    "# Retrieve sample and all analyses (both are now dicts)\n",
    "sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "\n",
    "print(f\"\\nSample: {sample['sample_id']}\")\n",
    "print(f\"Source: File {sample['file_index']}, paragraphs {sample['paragraph_start']}-{sample['paragraph_end']}\")\n",
    "print(f\"Analyses available: {list(analyses.keys())}\")\n",
    "\n",
    "# Examine one analysis\n",
    "print(f\"\\n--- Rhetorician Output (first 500 chars) ---\")\n",
    "print(analyses.get(\"efficiency_auditor\", \"Not found\")[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff3b653",
   "metadata": {},
   "source": [
    "## Step 2a: Pattern Recognition (Cross-Perspective Integration) per Text Sample\n",
    "\n",
    "Synthesize all analyst perspectives to identify interactions, tensions, and load-bearing features. This is a per-text-cross-analyst transformation. This looks to integrate multiple perspectives on each text sample and indirectly distill the information content in the assessments of the text samples. \n",
    "\n",
    "If only a subset of samples are to be analyzed, filter or slice the list `samples_to_analyze`, which is a list of sample IDs, as created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c7fb491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_001', 'sample_002', 'sample_003', 'sample_004', 'sample_005']\n"
     ]
    }
   ],
   "source": [
    "samples_to_analyze = store.list_samples()\n",
    "print(samples_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cef01feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pattern_prompt_from_(text: str, analyses: dict):\n",
    "    \"\"\"Convenience function to create the prompt, since the prompt depends on the kinds of analysts to integrate.\n",
    "    \n",
    "    \"\"\"\n",
    "    sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "\n",
    "    analyst_info = {}\n",
    "    for analyst_name in ANALYSTS:\n",
    "        config_class = ANALYST_CONFIGS[analyst_name]\n",
    "        analyst_info[analyst_name] = {\n",
    "            'analysis': analyses[analyst_name],\n",
    "            'analyst_descr_short': config_class.description()\n",
    "        }\n",
    "\n",
    "    pattern_config = CrossPerspectiveIntegratorConfig(\n",
    "        original_text=sample['text'],\n",
    "        analysts=analyst_info\n",
    "    )\n",
    "    return prompt_maker.render(pattern_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddc10a5",
   "metadata": {},
   "source": [
    "Note that this loop can take time to execute, since LLMs are called. Each analysis is independent and can therefore in principle be parallelized, though the implementation below does not do that.\n",
    "\n",
    "Note also that the cross-perspective per-text result are stored in the result store, keyed on the sample ID and the analyst kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0f49cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross-Perspective Integrator agent for sample_001... ✓ (17510 chars)\n",
      "Running Cross-Perspective Integrator agent for sample_002... ✓ (18089 chars)\n",
      "Running Cross-Perspective Integrator agent for sample_003... ✓ (17144 chars)\n",
      "Running Cross-Perspective Integrator agent for sample_004... ✓ (17902 chars)\n",
      "Running Cross-Perspective Integrator agent for sample_005... ✓ (17055 chars)\n"
     ]
    }
   ],
   "source": [
    "for sample_id in samples_to_analyze:\n",
    "    # Check if cross-perspective integration already exists (resume support)\n",
    "    pattern_analyst = CrossPerspectiveIntegratorConfig.analyst_name()\n",
    "    if store.get_analysis(sample_id, pattern_analyst):\n",
    "        print(f\"✓ {sample_id} cross-perspective integration (already done)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Running Cross-Perspective Integrator agent for {sample_id}...\", end=\" \")\n",
    "    \n",
    "    sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "    pattern_prompt = build_pattern_prompt_from_(text=sample['text'], analyses=analyses)\n",
    "\n",
    "    pattern_response = llm.complete(pattern_prompt)\n",
    "    \n",
    "    # Store pattern recognition result in result store\n",
    "    store.save_analysis(\n",
    "        sample_id, \n",
    "        pattern_analyst, \n",
    "        pattern_response.content, \n",
    "        pattern_response.model\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ ({len(pattern_response.content)} chars)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aa24721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cross_perspective_integrator', 'efficiency_auditor', 'information_architect', 'lexicologist', 'rhetorician', 'syntactician'])\n",
      "\n",
      "--- Pattern Analyst Output (first 2000 chars) ---\n",
      "# CROSS-PERSPECTIVE INTEGRATION ANALYSIS\n",
      "\n",
      "## I. EXTRACTED TECHNIQUES\n",
      "\n",
      "### Technique 1: CONCRETE-TO-ABSTRACT SCAFFOLDING\n",
      "**Name:** The Anchoring Concrete Example\n",
      "\n",
      "**Specification:** \n",
      "- Open with maximally concrete, everyday object (8+ repetitions in opening section)\n",
      "- Use object as stable reference point while introducing progressive abstraction\n",
      "- Return to concrete anchor at structural pivots\n",
      "- Ratio: 1 concrete term repeated 6-8 times per 200 words of abstract exposition\n",
      "\n",
      "**Example from text:**\n",
      "\"Common sense imagines that when it sees a table it sees a table.\" → [8 repetitions of \"table\" through paragraph 1] → \"when we say that a man 'sees a table,' we use a highly abbreviated form of expression\"\n",
      "\n",
      "**Source observations:**\n",
      "- **Rhetorician:** \"The table example does heavy persuasive work, making the later abstractions seem like natural extensions\"\n",
      "- **Lexicologist:** \"The **table** functions as the anchoring concrete image throughout the first paragraph, appearing 8 times, while abstract terminology builds around it\"\n",
      "- **Information_architect:** \"returns to opening phrase ('sees a table') with meta-commentary on the expression itself\"\n",
      "\n",
      "**Operating conditions:** Deploy when introducing counterintuitive philosophical/scientific claims. The concrete anchor must be universally familiar (table, not microscope). Use in opening 20-30% of exposition, then allow abstraction to dominate.\n",
      "\n",
      "**Confidence:** HIGH — Multiple analysts identified this independently; exact repetition count available; clear functional purpose.\n",
      "\n",
      "---\n",
      "\n",
      "### Technique 2: PERIODIC SENTENCE ARCHITECTURE FOR CAUSAL CHAINS\n",
      "**Name:** The Delayed-Resolution Causal Sentence\n",
      "\n",
      "**Specification:**\n",
      "- Place 3-5 subordinate clauses (temporal, conditional, or circumstantial) before main clause\n",
      "- Each subordinate clause: 8-15 words\n",
      "- Main clause: 8-12 words, containing core assertion\n",
      "- Total sentence length: 28-50 words\n",
      "- Pattern: [When X], [condition Y], [qualification Z], **MAIN ASSERTION**\n",
      "\n",
      "**Example from text:**\n",
      "\"When \n"
     ]
    }
   ],
   "source": [
    "sample_id = 'sample_005'\n",
    "sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "print(analyses.keys())\n",
    "\n",
    "print(f\"\\n--- Pattern Analyst Output (first 2000 chars) ---\")\n",
    "print(analyses.get(\"cross_perspective_integrator\", \"Not found\")[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e607c7",
   "metadata": {},
   "source": [
    "## Stage 2b: Cross-Text Synthesis of Integrated Analyses\n",
    "\n",
    "Patterns that appear across multiple text analyses are synthesized. This stage takes all the cross-perspective integration outputs and identifies overaching techniques, complementary findings, and so on, in order to construct a highly specific conclusion on the techniques that are employed in the text samples. It attempts in other words a synthesis of all analysis, across perspectives and across text samples.\n",
    "\n",
    "This is a single document. In order to track provenance, the text samples and analyst types that went into its construction are gathered and included in the storage in the project database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9028e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 cross-perspective integration results\n",
      "Sample IDs: ['sample_001', 'sample_002', 'sample_003', 'sample_004', 'sample_005']\n"
     ]
    }
   ],
   "source": [
    "from belletrist.models import CrossTextSynthesizerConfig\n",
    "\n",
    "# Get all samples that have cross-perspective integration results\n",
    "all_samples = store.list_samples()\n",
    "pattern_analyst = CrossPerspectiveIntegratorConfig.analyst_name()\n",
    "\n",
    "# Retrieve all pattern recognition analyses\n",
    "integrated_analyses = {}\n",
    "for sample_id in all_samples:\n",
    "    pattern_analysis = store.get_analysis(sample_id, pattern_analyst)\n",
    "    if pattern_analysis:\n",
    "        integrated_analyses[sample_id] = pattern_analysis\n",
    "    else:\n",
    "        print(f\"⚠ Sample {sample_id} missing cross-perspective integration results\")\n",
    "\n",
    "print(f\"Found {len(integrated_analyses)} cross-perspective integration results\")\n",
    "print(f\"Sample IDs: {list(integrated_analyses.keys())}\")\n",
    "\n",
    "if len(integrated_analyses) < 2:\n",
    "    print(f\"\\n⚠ Need at least 2 pattern recognition analyses for cross-text synthesis. Got {len(integrated_analyses)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea83fd",
   "metadata": {},
   "source": [
    "This is where the analysis is run. This can take time, since it requires running an LLM, however, only one LLM call in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b2757f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross-Text Synthesis... ✓ (15506 chars)\n",
      "Saved as: cross_text_synthesis_001\n"
     ]
    }
   ],
   "source": [
    "cross_text_config = CrossTextSynthesizerConfig(\n",
    "    integrated_analyses=integrated_analyses\n",
    ")\n",
    "\n",
    "# Check if cross-text synthesis already exists (resume support)\n",
    "existing_syntheses = store.list_syntheses('cross_text_synthesis')\n",
    "if existing_syntheses:\n",
    "    cross_text_id = existing_syntheses[-1]  # Use most recent\n",
    "    cross_text_synthesis = store.get_synthesis(cross_text_id)\n",
    "    print(f\"✓ Cross-text synthesis already exists: {cross_text_id}\")\n",
    "    print(f\"  (Created: {cross_text_synthesis['created_at']}, {len(cross_text_synthesis['output'])} chars)\")\n",
    "else:\n",
    "    cross_text_prompt = prompt_maker.render(cross_text_config)\n",
    "        \n",
    "    print(\"Running Cross-Text Synthesis...\", end=\" \")\n",
    "    cross_text_response = llm.complete(cross_text_prompt)\n",
    "    print(f\"✓ ({len(cross_text_response.content)} chars)\")\n",
    "        \n",
    "    # Save to ResultStore with auto-generated ID and full provenance\n",
    "    sample_contributions = [(sid, pattern_analyst) for sid in integrated_analyses.keys()]\n",
    "    cross_text_id = store.save_synthesis(\n",
    "        synthesis_type=cross_text_config.synthesis_type(),\n",
    "        output=cross_text_response.content,\n",
    "        model=cross_text_response.model,\n",
    "        sample_contributions=sample_contributions,\n",
    "        config=cross_text_config\n",
    "    )\n",
    "    print(f\"Saved as: {cross_text_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f70d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Clean up orphaned records caused by disabled foreign keys\n",
    "#  cursor = store.conn.execute(\"\"\"\n",
    "#      DELETE FROM synthesis_samples\n",
    "#      WHERE synthesis_id NOT IN (SELECT synthesis_id FROM syntheses)\n",
    "#  \"\"\")\n",
    "#  print(f\"Deleted {cursor.rowcount} orphaned synthesis_samples records\")#\n",
    "#\n",
    "#  cursor = store.conn.execute(\"\"\"\n",
    "#      DELETE FROM synthesis_metadata\n",
    "#      WHERE synthesis_id NOT IN (SELECT synthesis_id FROM syntheses)\n",
    "#  \"\"\")\n",
    "#  print(f\"Deleted {cursor.rowcount} orphaned synthesis_metadata records\")#\n",
    "#\n",
    "#  store.conn.commit()\n",
    "#\n",
    "#  # Verify cleanup\n",
    "#  orphans = store.conn.execute(\"\"\"\n",
    "#      SELECT COUNT(*) FROM synthesis_samples ss\n",
    "#      LEFT JOIN syntheses s ON ss.synthesis_id = s.synthesis_id\n",
    "#      WHERE s.synthesis_id IS NULL\n",
    "#  \"\"\").fetchone()[0]\n",
    "#  print(f\"Remaining orphaned records: {orphans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_contributions = [(sid, pattern_analyst) for sid in integrated_analyses.keys()]\n",
    "#cross_text_id = store.save_synthesis(\n",
    "#    synthesis_type=cross_text_config.synthesis_type(),\n",
    "#    output=cross_text_response.content,\n",
    "#    model=cross_text_response.model,\n",
    "#    sample_contributions=sample_contributions,\n",
    "#    config=cross_text_config\n",
    "#)\n",
    "#print(f\"Saved as: {cross_text_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6f5b8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cross-Text Synthesis (first 1000 chars) ---\n",
      "# CROSS-TEXT SYNTHESIS: PATTERNS AND PRINCIPLES\n",
      "\n",
      "## 0. TECHNIQUE CONSOLIDATION\n",
      "\n",
      "### CONSOLIDATED TECHNIQUE: Simple Anchor Frames\n",
      "**Variations found:**\n",
      "- Sample 001: \"Staccato Declarative Anchoring\" / \"Brevity = Certainty Punctuation\"\n",
      "- Sample 002: \"Journey-Framing with Recursive Closure\" (opening component)\n",
      "- Sample 003: \"Concrete-Abstract-Concrete Sandwich\" (opening component)\n",
      "- Sample 004: \"Concrete-Before-Abstract Sequencing\"\n",
      "- Sample 005: \"Concrete-to-Abstract Scaffolding\" / \"The Anchoring Concrete Example\"\n",
      "\n",
      "**Common mechanical specification:**\n",
      "- Open complex conceptual territory with 3-12 word simple declarative\n",
      "- Use concrete, universally accessible referent (table, room, Caesar, chicken, sun)\n",
      "- Repeat anchor term 5-8 times in opening 150-200 words\n",
      "- Place anchor in independent clauses, not subordinate structures\n",
      "- Return to anchor at structural pivots\n",
      "\n",
      "**Collected examples:**\n",
      "1. \"These we know to exist.\" (5 words - Russell, epistemology)\n",
      "2. \"This knowledge supplies our data.\" (5 words - Russell, epistemology)\n",
      "3. \"Common sense imagines that when it sees a table it sees a table.\" (14 words - Russell, perception)\n",
      "4. \"Thus our instincts certainly cause us to believe that the sun will rise to-morrow\" (15 words - Russell, induction)\n",
      "5. \"Suppose you are thinking of some familiar room.\" (8 words - Russell, memory)\n",
      "\n",
      "**Confidence: HIGH** - Appears in 5/5 texts; mechanical specs align; function identical.\n",
      "\n",
      "---\n",
      "\n",
      "### CONSOLIDATED TECHNIQUE: Provisional-Then-Complicate\n",
      "**Variations found:**\n",
      "- Sample 002: \"Provisional-Then-Complicate Structure\"\n",
      "- Sample 003: \"Preemptive Objection Architecture\"\n",
      "- Sample 004: \"Counterargument-Then-Demolition Structure\"\n",
      "\n",
      "**Common mechanical specification:**\n",
      "- Present prior/opposing view in 25-45 words\n",
      "- Use explicit markers: \"provisionally,\" \"it may be said that,\" \"it has been argued\"\n",
      "- Add qualification/concession: \"it may be admitted\" (8-15 words)\n",
      "- Pivot with \"But\" + systematic reversal (20-35 words)\n",
      "- Use first-person plural for shared inq\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Cross-Text Synthesis (first 1000 chars) ---\")\n",
    "print(cross_text_response.content[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867ebf82",
   "metadata": {},
   "source": [
    "## Stage 3: Synthesize Prescriptive Writing Document\n",
    "\n",
    "The final stage converts the descriptive cross-text synthesis into actionable prescriptive writing principles. This generates a style guide that can be used to instruct an LLM to write in a similar style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acb6d269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cross-text synthesis: cross_text_synthesis_001\n"
     ]
    }
   ],
   "source": [
    "cross_text_syntheses = store.list_syntheses('cross_text_synthesis')\n",
    "cross_text_synthesis_to_analyze_id = cross_text_syntheses[-1]\n",
    "print(f\"Using cross-text synthesis: {cross_text_synthesis_to_analyze_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab528627",
   "metadata": {},
   "source": [
    "The following step executes the LLM and can therefore take time. The result is stored for provenance tracking in the project database alongside relevant metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10cdce92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Synthesizer of Writing Style Principles... ✓ (18173 chars)\n",
      "Saved as: principles_guide_001\n"
     ]
    }
   ],
   "source": [
    "from belletrist.models import SynthesizerOfPrinciplesConfig\n",
    "\n",
    "# Check if principles guide already exists (resume support)\n",
    "existing_principles = store.list_syntheses('principles_guide')\n",
    "if existing_principles:\n",
    "    principles_id = existing_principles[-1]  # Use most recent\n",
    "    principles_synthesis = store.get_synthesis(principles_id)\n",
    "    print(f\"✓ Principles guide already exists: {principles_id}\")\n",
    "    print(f\"  (Created: {principles_synthesis['created_at']}, {len(principles_synthesis['output'])} chars)\")\n",
    "else:\n",
    "    # Build principles guide config and prompt\n",
    "    cross_text_synthesis_to_analyze = store.get_synthesis(cross_text_synthesis_to_analyze_id)\n",
    "    principles_config = SynthesizerOfPrinciplesConfig(\n",
    "        synthesis_document=cross_text_synthesis_to_analyze['output']\n",
    "    )\n",
    "    principles_prompt = prompt_maker.render(principles_config)\n",
    "        \n",
    "    # Run principles synthesis\n",
    "    print(\"Running Synthesizer of Writing Style Principles...\", end=\" \")\n",
    "    principles_response = llm.complete(principles_prompt)\n",
    "    print(f\"✓ ({len(principles_response.content)} chars)\")\n",
    "        \n",
    "    # Save to ResultStore with parent linkage (inherits provenance)\n",
    "    principles_id = store.save_synthesis(\n",
    "        synthesis_type=principles_config.synthesis_type(),\n",
    "        output=principles_response.content,\n",
    "        model=principles_response.model,\n",
    "        sample_contributions=[],  # Inherited from parent\n",
    "        config=principles_config,\n",
    "        parent_synthesis_id=cross_text_synthesis_to_analyze_id\n",
    "    )\n",
    "    print(f\"Saved as: {principles_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52b344ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Principles Guide (first 2000 chars) ---\n",
      "# A GUIDE TO PHILOSOPHICAL PRECISION PROSE\n",
      "## Principles Extracted from Pattern Analysis\n",
      "\n",
      "---\n",
      "\n",
      "## PART I: FOUNDATIONS\n",
      "\n",
      "### Core Principles\n",
      "\n",
      "#### PRINCIPLE 1: Anchor Complexity in Simplicity\n",
      "\n",
      "**State a complex idea's foundation in the simplest possible terms—then build outward.**\n",
      "\n",
      "Every abstract argument needs a concrete home base. When entering difficult conceptual territory, establish your anchor with a 3-12 word declarative sentence using something everyone can picture: a table, a room, the sun, Caesar. This anchor is not metaphor or illustration—it's the actual case you'll reason from. Return to this concrete anchor 5-8 times in your opening 150-200 words, always in independent clauses, never buried in subordinate structures. The anchor creates gravity: it prevents your argument from floating into abstraction and gives readers a stable point to return to when the reasoning grows complex.\n",
      "\n",
      "**Demonstration:**\n",
      "\n",
      "\"These we know to exist.\" (5 words)\n",
      "\n",
      "Notice the radical simplicity: a five-word independent clause establishing bedrock certainty. The demonstrative \"these\" points to sense-data just discussed; the verb \"know\" asserts epistemic access; \"to exist\" stakes an ontological claim. Everything complex that follows—questions about matter, causation, inference—radiates from this anchor.\n",
      "\n",
      "\"Suppose you are thinking of some familiar room.\" (8 words)\n",
      "\n",
      "The imperative \"suppose\" invites participation. \"Some familiar room\"—not \"a room\" but one already in the reader's memory. The anchor is installed before the philosophical problem even appears. Watch what this enables: for the next 200 words, \"room\" appears seven times, each occurrence adding complexity while the concrete referent holds steady.\n",
      "\n",
      "\"Common sense imagines that when it sees a table it sees a table.\" (14 words)\n",
      "\n",
      "The repetition of \"table\" in a single sentence performs the anchoring work: the first \"table\" is the physical object, the second is the perceptual content. The apparent tautology conceals the entire problem of perception. This anchor will support 800 words of analysis about sense-data, physics, and epistemology.\n",
      "\n",
      "**Dependencies:**\n",
      "\n",
      "This principle enables:\n",
      "- Technical Term Immersion (you can use abstract vocabulary because the concrete anchor prevents drift)\n",
      "- Rhythmic Length Modulation (simple anchor sentences provide the \"simple\" poles in your rhythm)\n",
      "- Qualification Integration (you can qualify heavily because the anchor keeps claims grounded)\n",
      "\n",
      "Without this principle:\n",
      "- Abstract arguments become untethered from cases\n",
      "- Readers lose orientation in complex reasoning\n",
      "- Technical vocabulary feels pedantic rather than precise\n",
      "\n",
      "---\n",
      "\n",
      "#### PRINCIPLE 2: Let Structure Carry Meaning\n",
      "\n",
      "**Use sentence length and clause structure—not emphasis words or emotional appeals—to signal importance and manage complexity.**\n",
      "\n",
      "Your sentences should breathe. Complex sentences (35-60 words with 3-5 subordinate clauses) do the work of qualification, integration, and systematic reasoning. Simple sentences (3-12 words, independent clause only) do the work of assertion, foundation, and emphasis. Alternate them in a 2:1 or 3:1 ratio—two or three complex sentences, then one simple. The length ratio should be roughly 4:1 to 6:1 (complex to simple word count). This creates intellectual rhythm: the complex sentences build and qualify and integrate; the simple sentences land the point. Never use italics, exclamation points, or intensifiers (\"very,\" \"extremely\") to create emphasis. Structure is your emphasis.\n",
      "\n",
      "**Demonstration:**\n",
      "\n",
      "*Complex (56 words):*\n",
      "\"But if we are to be able to draw inferences from these data—if we are to know of the existence of matter, of other people, of the past before our individual memory begins, or of the future, we must know general principles of some kind by means of which such inferences can be drawn.\"\n",
      "\n",
      "Three conditional clauses (\"if we are to be able,\" \"if we are to know\") build hypothetical pressure. The dashes and commas create suspensions. The main clause arrives only after 45 words of subordination: \"we must know general principles.\" The structure enacts the logical dependency it describes.\n",
      "\n",
      "*Simple (5 words):*\n",
      "\"These we know to exist.\"\n",
      "\n",
      "After the 56-word complex sentence, this lands with absolute certainty. No hedging, no subordination, no qualification. The brevity is the emphasis. The structure announces: this is bedrock.\n",
      "\n",
      "*Complex (50 words):*\n",
      "\"When common sense sees a table, certain light waves reach its eyes, and these are of a sort which, in its previous experience, has been associated with certain sensations of touch, as well as with other people's testimony that they also saw the table.\"\n",
      "\n",
      "The subordinate clause (\"When common sense sees a table\") establishes the scenario. The main clause traces a causal chain through three coordinated elements. The length mirrors the complexity of the perceptual process being described.\n",
      "\n",
      "*Simple (12 words):*\n",
      "\"But none of this ever brought us to the table itself.\"\n",
      "\n",
      "The pivot word \"But\" plus the emphatic \"ever\" plus the stark \"none\"—all in a simple independent clause. The structure performs the philosophical disappointment: after all that perceptual machinery, we never reach the object. The brevity is the punch.\n",
      "\n",
      "**Dependencies:**\n",
      "\n",
      "This principle enables:\n",
      "- Qualification Integration (complex sentences can carry multiple qualifications without feeling hedged)\n",
      "- Meta-Discourse Signposting (simple sentences can mark transitions crisply)\n",
      "- Provisional-Then-Complicate structures (the complexity lives in sentence structure, not vocabulary)\n",
      "\n",
      "Without this principle:\n",
      "- All sentences feel the same weight\n",
      "- Emphasis requires artificial intensifiers\n",
      "- Complex ideas need simplification rather than structural accommodation\n",
      "\n",
      "---\n",
      "\n",
      "#### PRINCIPLE 3: Complicate Honestly, Then Resolve\n",
      "\n",
      "**Present the strongest version of opposing views, concede what's genuinely true in them, then show why they nevertheless fail.**\n",
      "\n",
      "Intellectual honesty builds authority. When addressing counterarguments or prior views, state them in their strongest form (25-45 words), using phrases like \"it may be said that\" or \"provisionally we might hold.\" Then concede whatever is actually true in the position (8-15 words): \"it may be admitted that there is some truth in this.\" Then pivot—always with \"But\"—and systematically dismantle what remains (20-35 words). This three-part structure shows you've genuinely grappled with alternatives rather than constructing strawmen. The concession costs you nothing because the reversal is coming; the reader trusts you because you've been fair.\n",
      "\n",
      "**Demonstration:**\n",
      "\n",
      "\"It may be said that even in this very simple case the objective reference of the word-content is not quite the same as that of the image-content, that images have a wealth of concrete features which are lost when words are substituted... In reply, it may be admitted at once that there is, as a rule, a certain amount of truth in the objection. But two points may be urged to minimize its force.\"\n",
      "\n",
      "Part 1 (25 words): \"It may be said that even in this very simple case the objective reference of the word-content is not quite the same as that of the image-content\"—the objection stated neutrally, even sympathetically.\n",
      "\n",
      "Part 2 (15 words): \"In reply, it may be admitted at once that there is, as a rule, a certain amount of truth in the objection\"—genuine concession using the formulaic \"it may be admitted.\"\n",
      "\n",
      "Part 3 (10 words): \"But two points may be urged to minimize its force\"—the pivot with \"But,\" announcing the reversal. Notice \"minimize its force\" rather than \"refute it\"—the language stays measured even in disagreement.\n",
      "\n",
      "\"It has been argued that we have reason to know that the future will resemble the past, because what was the future has constantly become the past, and has always been found to resemble the past, so that we really have experience of the future, namely of times which were formerly future, which we may call past futures. But such an argument really begs the very question at issue.\"\n",
      "\n",
      "Part 1 (45 words): The entire inductive argument laid out in its full form, with technical precision (\"past futures\"). No caricature, no dismissive language.\n",
      "\n",
      "Part 2 (implicit concession): The structure itself concedes the argument's surface plausibility by presenting it so fully.\n",
      "\n",
      "Part 3 (10 words): \"But such an argument really begs the very question at issue\"—the reversal is swift and total. The word \"really\" does quiet work: it signals that beneath the surface plausibility lies a fundamental error.\n",
      "\n",
      "**Dependencies:**\n",
      "\n",
      "This principle enables:\n",
      "- First-Person Plural Authority (the \"we\" can explore wrong paths together before finding the right one)\n",
      "- Meta-Discourse Signposting (you can explicitly mark these three-part structures)\n",
      "- Qualification Integration (the concessions are themselves qualifications that strengthen rather than weaken)\n",
      "\n",
      "Without this principle:\n",
      "- Arguments feel one-sided or dogmatic\n",
      "- Counterarguments seem like strawmen\n",
      "- Readers distrust your fairness\n",
      "\n",
      "---\n",
      "\n",
      "#### PRINCIPLE 4: Immerse, Don't Define\n",
      "\n",
      "**Use technical terms in concrete contexts 5-7 times before defining them—or never define them at all.**\n",
      "\n",
      "Definitions are pedagogically weak. They front-load abstraction when the reader needs concrete footing. Instead, immerse your technical terms in use. Deploy the term in 5-7 different concrete contexts: \"We have acquaintance with sense-data,\" \"particulars and universals with which we are acquainted,\" \"Julius Caesar is a noise or shape with which we are acquainted.\" Meaning emerges through pattern recognition, the way children learn language. Maintain absolute terminological consistency—never vary your technical term with synonyms. If you must define, do it after immersion: give a genus-differentia definition, then 3-4 examples, then negative boundaries (what the term excludes). But prefer immersion. The reader who understands through use understands more deeply than the reader who memorizes definitions.\n",
      "\n",
      "**Demonstration:**\n",
      "\n",
      "The term \"acquaintance\" appears seven times before any definition:\n",
      "- \"We have acquaintance with sense-data\"\n",
      "- \"particulars and universals with which we are acquainted\"\n",
      "- \"Julius Caesar is a noise or shape with which we are acquainted\"\n",
      "\n",
      "Each use adds a facet: first, acquaintance with sense-data (concrete perceptual content); second, with particulars and universals (ontological categories); third, with names and shapes (linguistic and perceptual forms). By the seventh use, \"acquaintance\" has a precise meaning the reader has built through context. No definition has been given, yet the term is fully operational.\n",
      "\n",
      "Four paragraphs discuss repeated occurrences and expectations before \"induction\" appears: \"the whole of the results obtained by induction.\" The term arrives after the reader has been thinking about the problem induction solves. The word names what the reader already grasps.\n",
      "\n",
      "When definition does occur, it follows immersion:\n",
      "\"The content of a belief, when expressed in words, is the same thing (or very nearly the same thing) as what in logic is called a 'proposition.' A proposition is a series of words (or sometimes a single word) expressing the kind of thing that can be asserted or denied. 'That all men are mortal,' 'that Columbus discovered America,' 'that Charles I died in his bed,' 'that all philosophers are wise,' are propositions.\"\n",
      "\n",
      "Genus: \"a series of words\"\n",
      "Differentia: \"expressing the kind of thing that can be asserted or denied\"\n",
      "Four examples: all in parallel form, all using \"that\" clauses\n",
      "Negative boundary (implied): single words that don't assert or deny aren't propositions\n",
      "\n",
      "But this definition comes after \"proposition\" has been used contextually. The definition clarifies; it doesn't introduce.\n",
      "\n",
      "**Dependencies:**\n",
      "\n",
      "This principle enables:\n",
      "- Simple Anchor Frames (you can introduce technical terms while staying concrete)\n",
      "- Technical Term Immersion (obvious, but: this is the mechanism)\n",
      "- Qualification Integration (you can qualify technical terms without stopping to define)\n",
      "\n",
      "Without this principle:\n",
      "- Arguments become front-loaded with definitions\n",
      "- Readers memorize rather than understand\n",
      "- Technical vocabulary feels pedantic\n",
      "\n",
      "---\n",
      "\n",
      "#### PRINCIPLE 5: Qualify in Motion, Never at Rest\n",
      "\n",
      "**Place qualifications in subordinate clauses or mid-clause positions—never front-load them before your main claim.**\n",
      "\n",
      "Qualification is essential to philosophical honesty, but positioning determines whether it strengthens or weakens. Bad: \"It might perhaps be tentatively suggested that possibly there is some reason to think...\" This front-loads uncertainty until the claim arrives stillborn. Good: \"There is reason to think, so far as our experience extends, that...\" The claim arrives with confidence; the qualification calibrates it. Place qualifications after the subject and auxiliary but before the main verb (\"probably,\" \"in some way or other\"), or in subordinate clauses (\"so far as our experience extends,\" \"as a rule\"). Use standard phrases: \"probably,\" \"as a rule,\" \"it may be admitted,\" \"so far as our experience extends.\" Frequency: 1-2 qualifications per paragraph (about 15-20% of claims). The main clause carries the assertion; the qualification shows you know its limits.\n",
      "\n",
      "**Demonstration:**\n",
      "\n",
      "\"and, probably, with ourselves\"\n",
      "\n",
      "The qualification \"probably\" sits mid-clause, after the conjunction \"and,\" before the prepositional phrase \"with ourselves.\" It modifies without undermining. The sentence continues with momentum.\n",
      "\n",
      "\"in some way or other, it must be possible\"\n",
      "\n",
      "The hedging phrase \"in some way or other\" comes first, but notice: it's set off by commas and immediately followed by the strong modal \"must.\" The qualification acknowledges ignorance about mechanism while asserting confidence about possibility.\n",
      "\n",
      "\"The business of science is to find uniformities, such as the laws of motion and the law of gravitation, to which, **so far as our experience extends**, there are no exceptions.\"\n",
      "\n",
      "The main claim: \"The business of science is to find uniformities... to which there are no exceptions.\" The qualification \"so far as our experience extends\" sits in a subordinate position, surrounded by commas. It calibrates the scope without weakening the assertion. The structure says: within the domain I'm claiming, this is certain.\n",
      "\n",
      "\"But it seems **fairly clear** that all the facts and laws of physics can be interpreted without assuming that 'matter' is anything more than groups of events\"\n",
      "\n",
      "The qualification \"fairly clear\" comes after the subject and verb \"it seems.\" The main claim \"all the facts and laws of physics can be interpreted without assuming...\" arrives with force. \"Fairly clear\" signals epistemic modesty without hedging the claim into meaninglessness.\n",
      "\n",
      "**Dependencies:**\n",
      "\n",
      "This principle enables:\n",
      "- Rhythmic Length Modulation (qualifications add complexity to complex sentences without making them feel hedged)\n",
      "- Provisional-Then-Complicate (the concession phase uses these qualification patterns)\n",
      "- First-Person Plural Authority (qualifications signal collaborative inquiry, not personal uncertainty)\n",
      "\n",
      "Without this principle:\n",
      "- Claims feel either dogmatic or timid\n",
      "- Front-loaded qualifications kill momentum\n",
      "- Readers can't distinguish confident claims from speculative ones\n",
      "\n",
      "---\n",
      "\n",
      "#### PRINCIPLE 6: Make Your Architecture Visible\n",
      "\n",
      "**Tell the reader exactly what you're doing, where you're going, and why—using explicit signposts at 15-25% of your word count.**\n",
      "\n",
      "Transparency is not weakness; it's respect. Use explicit meta-discourse to mark transitions, announce structure, and orient the reader: \"The question we have now to consider,\" \"Let us take in illustration,\" \"For the present,\" \"In this lecture I propose to.\" These phrases should constitute 15-25% of your word count. Position them sentence-initial (60% of the time) or paragraph-initial (40%). Standard length: 6-10 words per signpost. This is not hand-holding; it's architectural clarity. The reader who knows where they are in your argument can focus on the argument itself rather than on navigation. Complex reasoning demands visible structure.\n",
      "\n",
      "**Demonstration:**\n",
      "\n",
      "\"In this last lecture I propose to pass in review various suggested methods of distinguishing mind from matter. I shall then briefly sketch the nature of that fundamental science which I believe to be the true metaphysic...\"\n",
      "\n",
      "Two signposts in two sentences:\n",
      "1. \"In this last lecture I propose to pass in review\"—announces the lecture's first task\n",
      "2. \"I shall then briefly sketch\"—announces the second task\n",
      "\n",
      "The architecture is completely transparent. The reader knows: first a review, then a sketch. The word \"briefly\" even sets length expectations. This is 30 words of pure signposting, roughly 15% of the paragraph's opening.\n",
      "\n",
      "\"The question we have now to consider is...\"\n",
      "\n",
      "Seven words of pure orientation. \"The question\" names the genre (inquiry). \"We have now to consider\" uses first-person plural and the modal \"have to\" (obligation, not choice). \"Now\" marks temporal progression through the argument. The reader knows: we're shifting to a new question.\n",
      "\n",
      "\"Let us take in illustration a case of memory.\"\n",
      "\n",
      "Eight words. \"Let us take\" is an invitation using first-person plural. \"In illustration\" names the function of what follows. \"A case of memory\" specifies the content. The reader knows: an example is coming, and its purpose is illustrative.\n",
      "\n",
      "\"But we are in danger of becoming entangled in psychological questions, which we must avoid if we can. Let us therefore return to the purely physical point of view.\"\n",
      "\n",
      "Meta-discourse about meta-discourse: the first sentence names a danger (\"becoming entangled\") and announces a constraint (\"which we must avoid\"). The second sentence, with \"Let us therefore return,\" executes a methodological pivot. The reader sees the seams in the argument and understands why they're there.\n",
      "\n",
      "**Dependencies:**\n",
      "\n",
      "This principle enables:\n",
      "- Provisional-Then-Complicate (you can explicitly mark the three-part structure)\n",
      "- Meta-Discourse Signposting (obvious, but: this is the mechanism)\n",
      "- First-Person Plural Authority (signposts use \"we\" to create collaborative movement)\n",
      "\n",
      "Without this principle:\n",
      "- Readers get lost\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Principles Guide (first 2000 chars) ---\")\n",
    "print(principles_response.content[:18100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f8952d",
   "metadata": {},
   "source": [
    "## Querying Synthesis Metadata\n",
    "\n",
    "The ResultStore tracks full provenance for all syntheses. Query metadata to understand what samples, analysts, and models contributed to each synthesis.\n",
    "\n",
    "**This code is for convenience and not required to generate the writing instruction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82af5029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Syntheses\n",
      "==================================================\n",
      "\n",
      "cross_text_synthesis: 1 found\n",
      "  - cross_text_synthesis_001\n",
      "\n",
      "principles_guide: 1 found\n",
      "  - principles_guide_001\n",
      "\n",
      "\n",
      "Detailed Metadata Example\n",
      "==================================================\n",
      "\n",
      "Synthesis ID: principles_guide_001\n",
      "Type: principles_guide\n",
      "Model: claude-sonnet-4-5-20250929\n",
      "Created: 2025-11-27T13:26:37.471619\n",
      "Parent: cross_text_synthesis_001\n",
      "\n",
      "Metadata:\n",
      "  Samples: 0\n",
      "  Sample IDs: []\n",
      "  Model homogeneous: True\n",
      "  Models used: ['claude-sonnet-4-5-20250929']\n",
      "\n",
      "\n",
      "Full Provenance Tree\n",
      "==================================================\n",
      "\n",
      "Principles Guide: principles_guide_001\n",
      "  Created: 2025-11-27T13:26:37.471619\n",
      "  Model: claude-sonnet-4-5-20250929\n",
      "\n",
      "  Parent (Cross-Text): cross_text_synthesis_001\n",
      "    Sample contributions: 5\n",
      "      - sample_001 / cross_perspective_integrator\n",
      "      - sample_002 / cross_perspective_integrator\n",
      "      - sample_003 / cross_perspective_integrator\n",
      "      ... and 2 more\n"
     ]
    }
   ],
   "source": [
    "# List all syntheses\n",
    "print(\"All Syntheses\")\n",
    "print(\"=\" * 50)\n",
    "for synth_type in ['cross_text_synthesis', 'principles_guide']:\n",
    "    syntheses = store.list_syntheses(synth_type)\n",
    "    print(f\"\\n{synth_type}: {len(syntheses)} found\")\n",
    "    for synth_id in syntheses:\n",
    "        print(f\"  - {synth_id}\")\n",
    "\n",
    "# Get detailed metadata for a synthesis\n",
    "if store.list_syntheses():\n",
    "    print(\"\\n\\nDetailed Metadata Example\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get first principles guide (or first cross-text if none)\n",
    "    principles = store.list_syntheses('principles_guide')\n",
    "    if principles:\n",
    "        synth_id = principles[0]\n",
    "    else:\n",
    "        synth_id = store.list_syntheses()[0]\n",
    "    \n",
    "    synth_with_meta = store.get_synthesis_with_metadata(synth_id)\n",
    "    \n",
    "    print(f\"\\nSynthesis ID: {synth_with_meta['synthesis_id']}\")\n",
    "    print(f\"Type: {synth_with_meta['type']}\")\n",
    "    print(f\"Model: {synth_with_meta['model']}\")\n",
    "    print(f\"Created: {synth_with_meta['created_at']}\")\n",
    "    print(f\"Parent: {synth_with_meta['parent_id']}\")\n",
    "    \n",
    "    if synth_with_meta.get('metadata'):\n",
    "        meta = synth_with_meta['metadata']\n",
    "        print(f\"\\nMetadata:\")\n",
    "        print(f\"  Samples: {meta['num_samples']}\")\n",
    "        print(f\"  Sample IDs: {meta['sample_ids']}\")\n",
    "        print(f\"  Model homogeneous: {meta['is_homogeneous_model']}\")\n",
    "        print(f\"  Models used: {meta['models_used']}\")\n",
    "\n",
    "# Get full provenance tree\n",
    "if store.list_syntheses('principles_guide'):\n",
    "    print(\"\\n\\nFull Provenance Tree\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for p_id in store.list_syntheses('principles_guide'):\n",
    "        provenance = store.get_synthesis_provenance(p_id)\n",
    "    \n",
    "        print(f\"\\nPrinciples Guide: {provenance['synthesis']['synthesis_id']}\")\n",
    "        print(f\"  Created: {provenance['synthesis']['created_at']}\")\n",
    "        print(f\"  Model: {provenance['synthesis']['model']}\")\n",
    "    \n",
    "        if provenance['parent']:\n",
    "            parent = provenance['parent']\n",
    "            print(f\"\\n  Parent (Cross-Text): {parent['synthesis']['synthesis_id']}\")\n",
    "            print(f\"    Sample contributions: {len(parent['sample_contributions'])}\")\n",
    "            for sample_id, analyst in parent['sample_contributions'][:3]:\n",
    "                print(f\"      - {sample_id} / {analyst}\")\n",
    "            if len(parent['sample_contributions']) > 3:\n",
    "                print(f\"      ... and {len(parent['sample_contributions']) - 3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5e7dd",
   "metadata": {},
   "source": [
    "## Exporting Syntheses to Filesystem\n",
    "\n",
    "Export final syntheses to text files with YAML metadata headers for consumption by other tools or LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2761aac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: outputs/cross_text_synthesis_001.txt\n",
      "Exported: outputs/principles_guide_001.txt\n",
      "Exported for style evaluation: outputs/derived_style_instructions.txt\n",
      "\n",
      "All syntheses exported to /Users/andersohrn/PycharmProjects/russell_writes/outputs\n"
     ]
    }
   ],
   "source": [
    "# Create outputs directory\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export cross-text synthesis\n",
    "cross_text_syntheses = store.list_syntheses('cross_text_synthesis')\n",
    "if cross_text_syntheses:\n",
    "    for synth_id in cross_text_syntheses:\n",
    "        output_path = outputs_dir / f\"{synth_id}.txt\"\n",
    "        store.export_synthesis(synth_id, output_path, metadata_format='yaml')\n",
    "        print(f\"Exported: {output_path}\")\n",
    "\n",
    "# Export principles guide\n",
    "principles_guides = store.list_syntheses('principles_guide')\n",
    "if principles_guides:\n",
    "    for synth_id in principles_guides:\n",
    "        output_path = outputs_dir / f\"{synth_id}.txt\"\n",
    "        store.export_synthesis(synth_id, output_path, metadata_format='yaml')\n",
    "        print(f\"Exported: {output_path}\")\n",
    "        \n",
    "        # Also create a special \"derived_style_instructions.txt\" for style_evaluation.ipynb\n",
    "        if synth_id == principles_guides[-1]:  # Use latest\n",
    "            instructions_path = outputs_dir / \"derived_style_instructions.txt\"\n",
    "            store.export_synthesis(synth_id, instructions_path, metadata_format='yaml')\n",
    "            print(f\"Exported for style evaluation: {instructions_path}\")\n",
    "\n",
    "print(f\"\\nAll syntheses exported to {outputs_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a310c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (russell_writes)",
   "language": "python",
   "name": "russell_writes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
