{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Multi-Analyst Text Analysis Pipeline\n\nThis notebook demonstrates the full pipeline for analyzing text through multiple specialist lenses (rhetorician, syntactician, lexicologist, etc.) and synthesizing their observations.",
   "id": "1c136d9f420cc279"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Setup: Import all components\nfrom pathlib import Path\nfrom src.llm import LLM\nfrom src.prompt_maker import PromptMaker\nfrom src.data_sampler import DataSampler\nfrom src.result_store import ResultStore\nfrom src.models.llm_config_models import LLMConfig\nfrom src.models.prompt_models import (\n    PreambleInstructionConfig,\n    PreambleTextConfig,\n    RhetoricianConfig,\n    SyntacticianConfig,\n    LexicologistConfig,\n    InformationArchitectConfig,\n    EfficiencyAuditorConfig,\n    PatternRecognizerTextConfig,\n)\n\n# Initialize components\n# LLM accepts either LLMConfig object (explicit) or model string (shorthand)\n# Explicit: llm = LLM(LLMConfig(model=\"claude-3-sonnet-20240229\", temperature=0.7))\n# Shorthand: llm = LLM(\"claude-3-sonnet-20240229\", temperature=0.7)\nllm = LLM(\"claude-3-sonnet-20240229\")  # Using shorthand for notebook simplicity\n\nmaker = PromptMaker()\nsampler = DataSampler()\nstore = ResultStore(Path(\"results/analyses.db\"))\n\n# Define the analyst types we'll use\nANALYSTS = [\n    \"rhetorician\",\n    \"syntactician\", \n    \"lexicologist\",\n    \"information_architect\",\n    \"efficiency_auditor\"\n]\n\nprint(\"Pipeline initialized successfully\")",
   "id": "1c5f6303ac0364df"
  },
  {
   "cell_type": "markdown",
   "id": "j1skw5031fk",
   "source": "## Step 1: Generate and Store Sample\n\nSample text from the data corpus and store it with full provenance (which file, which paragraphs).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "x7mfjhknvg",
   "source": "# Option 1: Random sample (weighted by file length)\n# paragraphs = sampler.sample_segment(p_length=10)\n# file_index = None  # Random sampling doesn't track which file\n\n# Option 2: Specific file and paragraph range (better for provenance)\nfile_index = 0\nparagraph_range = slice(10, 20)  # Paragraphs 10-20 from file\nparagraphs = sampler.get_paragraph_chunk(file_index, paragraph_range)\ntext = \"\\n\\n\".join(paragraphs)\n\n# Generate sample ID\nsample_id = f\"sample_{len(store.list_samples()) + 1:03d}\"\n\n# Store sample with full provenance\nstore.save_sample(\n    sample_id=sample_id,\n    text=text,\n    file_index=file_index,\n    paragraph_start=paragraph_range.start,\n    paragraph_end=paragraph_range.stop\n)\n\nprint(f\"Created {sample_id}\")\nprint(f\"Text length: {len(text)} characters\")\nprint(f\"First 200 chars: {text[:200]}...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "mehuoydmu7j",
   "source": "## Step 2: Run Multi-Analyst Pipeline\n\nSend the text through each specialist analyst. Each produces an independent analysis from their domain expertise.\n\n**Prompt structure for caching optimization:**\n1. Preamble instruction (static)\n2. Analyst-specific template (static per analyst)\n3. Text to analyze (dynamic)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0gmne9cj92y7",
   "source": "# Get the sample text\nsample = store.get_sample(sample_id)\ntext = sample.text\n\n# Build shared prompt components (reused across all analysts)\npreamble_instruction = maker.render(PreambleInstructionConfig())\npreamble_text = maker.render(PreambleTextConfig(text_to_analyze=text))\n\n# --- RHETORICIAN ---\nprint(\"Running rhetorician...\", end=\" \")\nrhetorician_prompt = maker.render(RhetoricianConfig())  # All sections enabled by default\nfull_prompt = f\"{preamble_instruction}\\n\\n{rhetorician_prompt}\\n\\n{preamble_text}\"\nresponse = llm.complete(full_prompt)\nstore.save_analysis(sample_id, \"rhetorician\", response.content, response.model)\nprint(f\"✓ ({len(response.content)} chars)\")\n\n# --- SYNTACTICIAN ---\nprint(\"Running syntactician...\", end=\" \")\nsyntactician_prompt = maker.render(SyntacticianConfig())\nfull_prompt = f\"{preamble_instruction}\\n\\n{syntactician_prompt}\\n\\n{preamble_text}\"\nresponse = llm.complete(full_prompt)\nstore.save_analysis(sample_id, \"syntactician\", response.content, response.model)\nprint(f\"✓ ({len(response.content)} chars)\")\n\n# --- LEXICOLOGIST ---\nprint(\"Running lexicologist...\", end=\" \")\nlexicologist_prompt = maker.render(LexicologistConfig())\nfull_prompt = f\"{preamble_instruction}\\n\\n{lexicologist_prompt}\\n\\n{preamble_text}\"\nresponse = llm.complete(full_prompt)\nstore.save_analysis(sample_id, \"lexicologist\", response.content, response.model)\nprint(f\"✓ ({len(response.content)} chars)\")\n\n# --- INFORMATION ARCHITECT ---\nprint(\"Running information_architect...\", end=\" \")\ninfo_arch_prompt = maker.render(InformationArchitectConfig())\nfull_prompt = f\"{preamble_instruction}\\n\\n{info_arch_prompt}\\n\\n{preamble_text}\"\nresponse = llm.complete(full_prompt)\nstore.save_analysis(sample_id, \"information_architect\", response.content, response.model)\nprint(f\"✓ ({len(response.content)} chars)\")\n\n# --- EFFICIENCY AUDITOR ---\nprint(\"Running efficiency_auditor...\", end=\" \")\nefficiency_prompt = maker.render(EfficiencyAuditorConfig())\nfull_prompt = f\"{preamble_instruction}\\n\\n{efficiency_prompt}\\n\\n{preamble_text}\"\nresponse = llm.complete(full_prompt)\nstore.save_analysis(sample_id, \"efficiency_auditor\", response.content, response.model)\nprint(f\"✓ ({len(response.content)} chars)\")\n\nprint(f\"\\nAll analyses complete for {sample_id}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "iqsdzl8c0ql",
   "source": "## Step 3: Retrieve and Examine Results\n\nCheck what's been stored and verify all analyses are present.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "lyqb6ozkpto",
   "source": "# Check if all required analyses are present\nis_complete = store.is_complete(sample_id, ANALYSTS)\nprint(f\"Analysis complete: {is_complete}\")\n\n# Retrieve sample and all analyses\nsample, analyses = store.get_sample_with_analyses(sample_id)\n\nprint(f\"\\nSample: {sample.sample_id}\")\nprint(f\"Source: File {sample.file_index}, paragraphs {sample.paragraph_start}-{sample.paragraph_end}\")\nprint(f\"Analyses available: {list(analyses.keys())}\")\n\n# Examine one analysis\nprint(f\"\\n--- Rhetorician Output (first 500 chars) ---\")\nprint(analyses.get(\"rhetorician\", \"Not found\")[:500])",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "pkx2w2obd8",
   "source": "## Step 4: Pattern Recognition (Cross-Perspective Integration)\n\nSynthesize all analyst perspectives to identify interactions, tensions, and load-bearing features.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "q8b62mqyn5",
   "source": "# Get sample and all analyses\nsample, analyses = store.get_sample_with_analyses(sample_id)\n\n# Format all analyst reports into a single string\nspecialist_analyses = f\"\"\"**RHETORICIAN:**\n{analyses['rhetorician']}\n\n**SYNTACTICIAN:**\n{analyses['syntactician']}\n\n**LEXICOLOGIST:**\n{analyses['lexicologist']}\n\n**INFORMATION ARCHITECT:**\n{analyses['information_architect']}\n\n**EFFICIENCY AUDITOR:**\n{analyses['efficiency_auditor']}\n\"\"\"\n\n# Build pattern recognizer prompt using PromptMaker\npattern_config = PatternRecognizerTextConfig(\n    original_text=sample.text,\n    specialist_analyses=specialist_analyses\n)\npattern_prompt = maker.render(pattern_config)\n\n# Get cross-perspective integration\nprint(\"Running pattern recognizer...\", end=\" \")\npattern_response = llm.complete(pattern_prompt)\nprint(f\"✓ ({len(pattern_response.content)} chars)\")\n\n# Display first part of the synthesis\nprint(\"\\n--- Pattern Recognition Output (first 1000 chars) ---\")\nprint(pattern_response.content[:1000])",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "59zv7clcaiw",
   "source": "## Utilities: Working with Stored Samples\n\nHelper functions for browsing and managing stored results.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "yrt9y7zsmsj",
   "source": "# List all samples in the database\nall_samples = store.list_samples()\nprint(f\"Total samples: {len(all_samples)}\")\nprint(f\"Sample IDs: {all_samples}\")\n\n# Check completion status for each\nprint(\"\\nCompletion status:\")\nfor sid in all_samples:\n    complete = store.is_complete(sid, ANALYSTS)\n    status = \"✓\" if complete else \"✗\"\n    print(f\"  {status} {sid}\")\n\n# Close database connection when done\n# store.close()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}