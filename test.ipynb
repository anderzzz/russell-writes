{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f676368c",
   "metadata": {},
   "source": [
    "# Multi-Analyst Text Analysis Pipeline\n",
    "\n",
    "This notebook demonstrates the full pipeline for analyzing text through multiple specialist lenses (rhetorician, syntactician, lexicologist, etc.) and synthesizing their observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0372334",
   "metadata": {},
   "source": [
    "## Installations and Preparations\n",
    "First, external modules are installed and ensured to be in working order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f386e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:02:22.033495Z",
     "start_time": "2025-11-19T18:02:20.240014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm==1.79.3 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.79.3)\n",
      "Requirement already satisfied: pydantic==2.7.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.7.4)\n",
      "Requirement already satisfied: jinja2>=3.1.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: aiohttp>=3.10 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (3.13.2)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (8.3.1)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: httpx>=0.23.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (8.7.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (4.25.1)\n",
      "Requirement already satisfied: openai>=1.99.5 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in ./venv/lib/python3.11/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.22.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in ./venv/lib/python3.11/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./venv/lib/python3.11/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2>=3.1.0->-r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.22.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in ./venv/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.29.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./venv/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in ./venv/lib/python3.11/site-packages (from tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (1.1.4)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (6.0.3)\n",
      "Requirement already satisfied: shellingham in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in ./venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.79.3->-r requirements.txt (line 1)) (0.20.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Optional: Install requirements if running in a fresh kernel\n",
    "# Uncomment if needed:\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Or install individual packages:\n",
    "# !pip install litellm pydantic jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52604d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providers\n",
      "=========\n",
      "* openai\n",
      "* openai_like\n",
      "* bytez\n",
      "* xai\n",
      "* custom_openai\n",
      "* text-completion-openai\n",
      "* cohere\n",
      "* cohere_chat\n",
      "* clarifai\n",
      "* anthropic\n",
      "* anthropic_text\n",
      "* replicate\n",
      "* huggingface\n",
      "* together_ai\n",
      "* datarobot\n",
      "* openrouter\n",
      "* cometapi\n",
      "* vertex_ai\n",
      "* vertex_ai_beta\n",
      "* gemini\n",
      "* ai21\n",
      "* baseten\n",
      "* azure\n",
      "* azure_text\n",
      "* azure_ai\n",
      "* sagemaker\n",
      "* sagemaker_chat\n",
      "* bedrock\n",
      "* vllm\n",
      "* nlp_cloud\n",
      "* petals\n",
      "* oobabooga\n",
      "* ollama\n",
      "* ollama_chat\n",
      "* deepinfra\n",
      "* perplexity\n",
      "* mistral\n",
      "* groq\n",
      "* nvidia_nim\n",
      "* cerebras\n",
      "* baseten\n",
      "* ai21_chat\n",
      "* volcengine\n",
      "* codestral\n",
      "* text-completion-codestral\n",
      "* deepseek\n",
      "* sambanova\n",
      "* maritalk\n",
      "* cloudflare\n",
      "* fireworks_ai\n",
      "* friendliai\n",
      "* watsonx\n",
      "* watsonx_text\n",
      "* triton\n",
      "* predibase\n",
      "* databricks\n",
      "* empower\n",
      "* github\n",
      "* custom\n",
      "* litellm_proxy\n",
      "* hosted_vllm\n",
      "* llamafile\n",
      "* lm_studio\n",
      "* galadriel\n",
      "* gradient_ai\n",
      "* github_copilot\n",
      "* novita\n",
      "* meta_llama\n",
      "* featherless_ai\n",
      "* nscale\n",
      "* nebius\n",
      "* dashscope\n",
      "* moonshot\n",
      "* v0\n",
      "* heroku\n",
      "* oci\n",
      "* morph\n",
      "* lambda_ai\n",
      "* vercel_ai_gateway\n",
      "* wandb\n",
      "* ovhcloud\n",
      "* lemonade\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import litellm\n",
    "    print('Providers\\n=========')\n",
    "    print('* ' + '\\n* '.join(litellm.LITELLM_CHAT_PROVIDERS))\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Cannot import litellm: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3512c2bd",
   "metadata": {},
   "source": [
    "## Initialize Base Objects\n",
    "Set up connections to a Large Language Model provider via `litellm` model router. Also, setup up tools to retrieve text data to be part of the context window, that is, instruction prompts and texts to analyze. A basic result storage is also initialized.\n",
    "\n",
    "The LLM to use is set by the `model_string`, which is constructed as `<provider>/<model>`, the providers defined by the `litellm` package, see in particular `litellm.LITELLM_CHAT_PROVIDERS`. The API key to the provider should be stored in an environment variable with name defined in `model_provider_api_key_env_var`. Do **not** store the API key as a string variable directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f45193",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_string = 'mistral/mistral-large-2411'\n",
    "model_provider_api_key_env_var = 'MISTRAL_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e9c471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:02:29.927627Z",
     "start_time": "2025-11-19T18:02:29.858316Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from belletrist import LLM, LLMConfig, PromptMaker, DataSampler, ResultStore\n",
    "\n",
    "llm = LLM(LLMConfig(\n",
    "    model=model_string,\n",
    "    api_key=os.environ.get(model_provider_api_key_env_var)\n",
    "))\n",
    "prompt_maker = PromptMaker()\n",
    "sampler = DataSampler()\n",
    "store = ResultStore(Path(f\"{os.getcwd()}/belletrist_storage.db\"))\n",
    "store.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadf84eb",
   "metadata": {},
   "source": [
    "## Generate and Store Text Samples to be Analyzed\n",
    "\n",
    "A random text sample is taken from the data corpus and stored with full provenance (which file, which paragraphs). Each sample is an instance of `TextSegment`.\n",
    "\n",
    "The sample size is set by the variable `n_sample` and each sample comprises `m_paragraphs_per_sample` number of consecutive paragraphs.\n",
    "\n",
    "If non-random text samples are preferred, use the `get_paragraph_chunk` method of the `DataSampler` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b2efb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text source: /Users/andersohrn/PycharmProjects/russell_writes/data/russell/an_essay_on_the_foundations_of_geometry.txt\n",
      "Paragraph range: 573 - 577\n",
      "\n",
      "[124] Due to v. Staudt's \"Geometrie der Lage.\"\n",
      "\n",
      "[125] See Cremona, op. cit. Chapter VIII.\n",
      "\n",
      "[126] The corresponding definitions, for the two-dimensional manifold\n",
      "of lines through a point, follow by the principle of duality.\n",
      "\n",
      "[127] It is important to observe that this definition of the Point\n",
      "introduces metrical ideas. Without metrical ideas, we saw, nothing\n",
      "appears to give the Point precedence of the straight line, or indeed\n",
      "to distinguish it conceptually from the straight line. A reference\n",
      "to quantity is therefore inevitable in defining the Point, if the\n",
      "definition is to be geometrical. A non-metrical definition would have\n",
      "to be also non-geometrical. See Chap. IV. §§ 196-199.\n"
     ]
    }
   ],
   "source": [
    "text_sample = sampler.sample_segment(p_length=4)\n",
    "print(f'Text source: {text_sample.file_path}')\n",
    "print(f'Paragraph range: {text_sample.paragraph_start} - {text_sample.paragraph_end}')\n",
    "print(f'\\n{text_sample.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf5598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 1\n",
    "m_paragraphs_per_sample = 10\n",
    "\n",
    "for _ in range(n_sample):\n",
    "    sample_id = f'sample_{len(store.list_samples()) + 1:03d}'\n",
    "    segment = sampler.sample_segment(p_length=m_paragraphs_per_sample)\n",
    "    store.save_segment(sample_id, segment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce71cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample keys:\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sample_001']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sample keys:\\n============')\n",
    "store.list_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a042f",
   "metadata": {},
   "source": [
    "## Construct the Analyst Agents and Analyze\n",
    "\n",
    "Send the text samples through each specialist analyst. Each produces an independent analysis from their domain expertise.\n",
    "\n",
    "**Prompt structure for caching optimization:**\n",
    "1. Preamble instruction (static)\n",
    "2. Analyst-specific template (static per analyst)\n",
    "3. Text to analyze (dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f3d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from belletrist.models import (\n",
    "    PreambleInstructionConfig,\n",
    "    PreambleTextConfig,\n",
    "    RhetoricianConfig,\n",
    "    SyntacticianConfig,\n",
    "    LexicologistConfig,\n",
    "    InformationArchitectConfig,\n",
    "    EfficiencyAuditorConfig,\n",
    "    PatternRecognizerTextConfig,\n",
    ")\n",
    "ANALYSTS = [\"rhetorician\", \"syntactician\", \"lexicologist\", \"information_architect\", \"efficiency_auditor\"]\n",
    "ANALYST_CONFIGS = {\n",
    "    \"rhetorician\": RhetoricianConfig,\n",
    "    \"syntactician\": SyntacticianConfig,\n",
    "    \"lexicologist\": LexicologistConfig,\n",
    "    \"information_architect\": InformationArchitectConfig,\n",
    "    \"efficiency_auditor\": EfficiencyAuditorConfig,\n",
    "}\n",
    "\n",
    "def build_analyst_prompt(preamble_instruction: str, analyst_prompt: str, preamble_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Helper function to construct the full prompt for an analyst.\n",
    "    \n",
    "    \"\"\"\n",
    "    return f\"{preamble_instruction}\\n\\n{analyst_prompt}\\n\\n{preamble_text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8811e32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 samples with 5 analysts each\n",
      "\n",
      "Sample: sample_001\n",
      "  Running rhetorician... "
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMResponse\nraw_response\n  Input should be a valid dictionary [type=dict_type, input_value=ModelResponse(id='967e887...pt_tokens_details=None)), input_type=ModelResponse]\n    For further information visit https://errors.pydantic.dev/2.7/v/dict_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m full_prompt = build_analyst_prompt(preamble_instruction, analyst_prompt, preamble_text)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Run analysis\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m store.save_analysis(sample_id, analyst_name, response.content, response.model)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(response.content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chars)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/russell_writes/belletrist/llm.py:83\u001b[39m, in \u001b[36mLLM.complete\u001b[39m\u001b[34m(self, prompt, system, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m raw_response = litellm.completion(**request_params)\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Parse and return the response\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_response\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/russell_writes/belletrist/llm.py:146\u001b[39m, in \u001b[36mLLM._parse_response\u001b[39m\u001b[34m(self, raw_response)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m'\u001b[39m\u001b[33musage\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    140\u001b[39m     usage = {\n\u001b[32m    141\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprompt_tokens\u001b[39m\u001b[33m\"\u001b[39m: raw_response.usage.prompt_tokens,\n\u001b[32m    142\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcompletion_tokens\u001b[39m\u001b[33m\"\u001b[39m: raw_response.usage.completion_tokens,\n\u001b[32m    143\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtotal_tokens\u001b[39m\u001b[33m\"\u001b[39m: raw_response.usage.total_tokens\n\u001b[32m    144\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLLMResponse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_calls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtool_calls\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfinish_reason\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinish_reason\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43musage\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_response\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pydantic/main.py:176\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    175\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for LLMResponse\nraw_response\n  Input should be a valid dictionary [type=dict_type, input_value=ModelResponse(id='967e887...pt_tokens_details=None)), input_type=ModelResponse]\n    For further information visit https://errors.pydantic.dev/2.7/v/dict_type"
     ]
    }
   ],
   "source": [
    "# Get all samples from the store\n",
    "all_samples = store.list_samples()\n",
    "print(f\"Processing {len(all_samples)} samples with {len(ANALYSTS)} analysts each\\n\")\n",
    "\n",
    "# Outer loop: iterate over each text sample\n",
    "for sample_id in all_samples:\n",
    "    print(f\"Sample: {sample_id}\")\n",
    "    \n",
    "    # Get the sample text\n",
    "    sample = store.get_sample(sample_id)\n",
    "    text = sample['text']\n",
    "    \n",
    "    # Build shared prompt components (reused across all analysts for this sample)\n",
    "    preamble_instruction = prompt_maker.render(PreambleInstructionConfig())\n",
    "    preamble_text = prompt_maker.render(PreambleTextConfig(text_to_analyze=text))\n",
    "    \n",
    "    # Inner loop: run each analyst on this sample\n",
    "    for analyst_name in ANALYSTS:\n",
    "        print(f\"  Running {analyst_name}...\", end=\" \")\n",
    "        \n",
    "        # Get analyst-specific prompt using the config class\n",
    "        analyst_config = ANALYST_CONFIGS[analyst_name]()\n",
    "        analyst_prompt = prompt_maker.render(analyst_config)\n",
    "        \n",
    "        # Build full prompt using helper function\n",
    "        full_prompt = build_analyst_prompt(preamble_instruction, analyst_prompt, preamble_text)\n",
    "        \n",
    "        # Run analysis\n",
    "        response = llm.complete(full_prompt)\n",
    "        store.save_analysis(sample_id, analyst_name, response.content, response.model)\n",
    "        \n",
    "        print(f\"✓ ({len(response.content)} chars)\")\n",
    "    \n",
    "    print()  # Blank line between samples\n",
    "\n",
    "print(f\"All analyses complete for {len(all_samples)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fa961e",
   "metadata": {},
   "source": [
    "## Step 3: Retrieve and Examine Results\n",
    "\n",
    "Check what's been stored and verify all analyses are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all required analyses are present\n",
    "is_complete = store.is_complete(sample_id, ANALYSTS)\n",
    "print(f\"Analysis complete: {is_complete}\")\n",
    "\n",
    "# Retrieve sample and all analyses (both are now dicts)\n",
    "sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "\n",
    "print(f\"\\nSample: {sample['sample_id']}\")\n",
    "print(f\"Source: File {sample['file_index']}, paragraphs {sample['paragraph_start']}-{sample['paragraph_end']}\")\n",
    "print(f\"Analyses available: {list(analyses.keys())}\")\n",
    "\n",
    "# Examine one analysis\n",
    "print(f\"\\n--- Rhetorician Output (first 500 chars) ---\")\n",
    "print(analyses.get(\"rhetorician\", \"Not found\")[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a7be39",
   "metadata": {},
   "source": [
    "## Step 4: Pattern Recognition (Cross-Perspective Integration)\n",
    "\n",
    "Synthesize all analyst perspectives to identify interactions, tensions, and load-bearing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample and all analyses (both are dicts now)\n",
    "sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "\n",
    "# Format all analyst reports into a single string\n",
    "specialist_analyses = f\"\"\"**RHETORICIAN:**\n",
    "{analyses['rhetorician']}\n",
    "\n",
    "**SYNTACTICIAN:**\n",
    "{analyses['syntactician']}\n",
    "\n",
    "**LEXICOLOGIST:**\n",
    "{analyses['lexicologist']}\n",
    "\n",
    "**INFORMATION ARCHITECT:**\n",
    "{analyses['information_architect']}\n",
    "\n",
    "**EFFICIENCY AUDITOR:**\n",
    "{analyses['efficiency_auditor']}\n",
    "\"\"\"\n",
    "\n",
    "# Build pattern recognizer prompt using PromptMaker\n",
    "pattern_config = PatternRecognizerTextConfig(\n",
    "    original_text=sample['text'],  # Access dict with key\n",
    "    specialist_analyses=specialist_analyses\n",
    ")\n",
    "pattern_prompt = prompt_maker.render(pattern_config)\n",
    "\n",
    "# Get cross-perspective integration\n",
    "print(\"Running pattern recognizer...\", end=\" \")\n",
    "pattern_response = llm.complete(pattern_prompt)\n",
    "print(f\"✓ ({len(pattern_response.content)} chars)\")\n",
    "\n",
    "# Display first part of the synthesis\n",
    "print(\"\\n--- Pattern Recognition Output (first 1000 chars) ---\")\n",
    "print(pattern_response.content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca08c4",
   "metadata": {},
   "source": [
    "## Utilities: Working with Stored Samples\n",
    "\n",
    "Helper functions for browsing and managing stored results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a737cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all samples in the database\n",
    "all_samples = store.list_samples()\n",
    "print(f\"Total samples: {len(all_samples)}\")\n",
    "print(f\"Sample IDs: {all_samples}\")\n",
    "\n",
    "# Check completion status for each\n",
    "print(\"\\nCompletion status:\")\n",
    "for sid in all_samples:\n",
    "    complete = store.is_complete(sid, ANALYSTS)\n",
    "    status = \"✓\" if complete else \"✗\"\n",
    "    print(f\"  {status} {sid}\")\n",
    "\n",
    "# Close database connection when done\n",
    "# store.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (russell_writes)",
   "language": "python",
   "name": "russell_writes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
