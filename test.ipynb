{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0129e9",
   "metadata": {},
   "source": [
    "# Multi-Analyst Text Analysis Pipeline\n",
    "\n",
    "This notebook demonstrates the full pipeline for analyzing text through multiple specialist lenses (rhetorician, syntactician, lexicologist, etc.) and synthesizing their observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53dc0c84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:02:22.033495Z",
     "start_time": "2025-11-19T18:02:20.240014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm==1.79.3 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.79.3)\n",
      "Requirement already satisfied: pydantic==2.7.4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (2.7.4)\n",
      "Requirement already satisfied: jinja2>=3.1.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (3.10.11)\n",
      "Requirement already satisfied: click in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (8.5.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.99.5 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: tokenizers in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.9.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (4.13.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jinja2>=3.1.0->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: anyio in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.7.1)\n",
      "Requirement already satisfied: certifi in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: sniffio in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=6.8.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.20.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (5.10.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (2023.12.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.20.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (0.9.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (4.64.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2022.4.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2.27.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from anyio->httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.1.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2.0.12)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (0.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Optional: Install requirements if running in a fresh kernel\n",
    "# Uncomment if needed:\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Or install individual packages:\n",
    "# !pip install litellm pydantic jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b53969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENVIRONMENT DIAGNOSIS ===\n",
      "\n",
      "Jupyter kernel Python: /Users/andersohrn/PycharmProjects/yolo_playnice/bin/python3\n",
      "Python version: 3.9.19 (main, Mar 19 2024, 16:08:27) \n",
      "[Clang 15.0.0 (clang-1500.3.9.4)]\n",
      "\n",
      "System Python: /Users/andersohrn/opt/anaconda3/bin/python\n",
      "System Python3: /Users/andersohrn/opt/anaconda3/bin/python3\n",
      "Pip location: /Users/andersohrn/opt/anaconda3/bin/pip\n",
      "\n",
      "Litellm is installed via pip:\n",
      "  Location: /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages\n",
      "\n",
      "Jupyter's Python can see these site-packages:\n",
      "  /Users/andersohrn/PycharmProjects/yolo_playnice/lib/python3.9/site-packages\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"=== ENVIRONMENT DIAGNOSIS ===\\n\")\n",
    "\n",
    "# 1. What Python is Jupyter using?\n",
    "print(f\"Jupyter kernel Python: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\\n\")\n",
    "\n",
    "# 2. What Python is pip using?\n",
    "pip_python = subprocess.run(['which', 'python'], capture_output=True, text=True)\n",
    "print(f\"System Python: {pip_python.stdout.strip()}\")\n",
    "\n",
    "pip_python3 = subprocess.run(['which', 'python3'], capture_output=True, text=True)\n",
    "print(f\"System Python3: {pip_python3.stdout.strip()}\")\n",
    "\n",
    "pip_location = subprocess.run(['which', 'pip'], capture_output=True, text=True)\n",
    "print(f\"Pip location: {pip_location.stdout.strip()}\\n\")\n",
    "\n",
    "# 3. Where is pip installing packages?\n",
    "pip_show = subprocess.run(['pip', 'show', 'litellm'], capture_output=True, text=True)\n",
    "if pip_show.returncode == 0:\n",
    "    print(\"Litellm is installed via pip:\")\n",
    "    for line in pip_show.stdout.split('\\n'):\n",
    "        if 'Location' in line:\n",
    "            print(f\"  {line}\")\n",
    "else:\n",
    "    print(\"Litellm NOT found via pip show\\n\")\n",
    "\n",
    "# 4. What's in Jupyter's Python path?\n",
    "print(\"\\nJupyter's Python can see these site-packages:\")\n",
    "for path in sys.path:\n",
    "    if 'site-packages' in path:\n",
    "        print(f\"  {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e1f403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Cannot import litellm: No module named 'litellm'\n",
      "\n",
      "Current directory: /Users/andersohrn/PycharmProjects/russell_writes\n",
      "src folder exists: True\n",
      "src/llm.py exists: True\n",
      "\n",
      "Python executable: /Users/andersohrn/PycharmProjects/yolo_playnice/bin/python3\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import litellm\n",
    "    print(f\"✓ litellm {litellm.__version__} is installed and importable\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Cannot import litellm: {e}\")\n",
    "    \n",
    "# Check if your src directory is accessible  \n",
    "import os\n",
    "print(f\"\\nCurrent directory: {os.getcwd()}\")\n",
    "print(f\"src folder exists: {os.path.exists('src')}\")\n",
    "print(f\"src/llm.py exists: {os.path.exists('src/llm.py')}\")\n",
    "\n",
    "# Check Python environment\n",
    "import sys\n",
    "print(f\"\\nPython executable: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06600121",
   "metadata": {},
   "source": [
    "## Initialize Objects\n",
    "Set up connections to a Large Language Model provider via `litellm` model router. Also, setup up tools to retrieve text data to be part of the context window, that is, instructions and texts to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8f8d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:02:29.927627Z",
     "start_time": "2025-11-19T18:02:29.858316Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from src.llm import LLM\n",
    "from src.models.llm_config_models import LLMConfig\n",
    "from src.models.prompt_models import (\n",
    "    PreambleInstructionConfig,\n",
    "    PreambleTextConfig,\n",
    "    RhetoricianConfig,\n",
    "    SyntacticianConfig,\n",
    "    LexicologistConfig,\n",
    "    InformationArchitectConfig,\n",
    "    EfficiencyAuditorConfig,\n",
    "    PatternRecognizerTextConfig,\n",
    ")\n",
    "\n",
    "llm = LLM(LLMConfig(\n",
    "    model=\"mistral/mistral-large-2411\",\n",
    "    api_key=os.environ.get(\"MISTRAL_API_KEY\")\n",
    "))\n",
    "\n",
    "from src.prompt_maker import PromptMaker\n",
    "from src.data_sampler import DataSampler\n",
    "\n",
    "prompt_maker = PromptMaker()\n",
    "sampler = DataSampler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1747d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8eb283",
   "metadata": {},
   "source": [
    "## Step 1: Generate and Store Sample\n",
    "\n",
    "Sample text from the data corpus and store it with full provenance (which file, which paragraphs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Random sample (weighted by file length)\n",
    "# paragraphs = sampler.sample_segment(p_length=10)\n",
    "# file_index = None  # Random sampling doesn't track which file\n",
    "\n",
    "# Option 2: Specific file and paragraph range (better for provenance)\n",
    "file_index = 0\n",
    "paragraph_range = slice(10, 20)  # Paragraphs 10-20 from file\n",
    "paragraphs = sampler.get_paragraph_chunk(file_index, paragraph_range)\n",
    "text = \"\\n\\n\".join(paragraphs)\n",
    "\n",
    "# Generate sample ID\n",
    "sample_id = f\"sample_{len(store.list_samples()) + 1:03d}\"\n",
    "\n",
    "# Store sample with full provenance\n",
    "store.save_sample(\n",
    "    sample_id=sample_id,\n",
    "    text=text,\n",
    "    file_index=file_index,\n",
    "    paragraph_start=paragraph_range.start,\n",
    "    paragraph_end=paragraph_range.stop\n",
    ")\n",
    "\n",
    "print(f\"Created {sample_id}\")\n",
    "print(f\"Text length: {len(text)} characters\")\n",
    "print(f\"First 200 chars: {text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7707c4bf",
   "metadata": {},
   "source": [
    "## Step 2: Run Multi-Analyst Pipeline\n",
    "\n",
    "Send the text through each specialist analyst. Each produces an independent analysis from their domain expertise.\n",
    "\n",
    "**Prompt structure for caching optimization:**\n",
    "1. Preamble instruction (static)\n",
    "2. Analyst-specific template (static per analyst)\n",
    "3. Text to analyze (dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1bb421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sample text\n",
    "sample = store.get_sample(sample_id)\n",
    "text = sample.text\n",
    "\n",
    "# Build shared prompt components (reused across all analysts)\n",
    "preamble_instruction = maker.render(PreambleInstructionConfig())\n",
    "preamble_text = maker.render(PreambleTextConfig(text_to_analyze=text))\n",
    "\n",
    "# --- RHETORICIAN ---\n",
    "print(\"Running rhetorician...\", end=\" \")\n",
    "rhetorician_prompt = maker.render(RhetoricianConfig())  # All sections enabled by default\n",
    "full_prompt = f\"{preamble_instruction}\\n\\n{rhetorician_prompt}\\n\\n{preamble_text}\"\n",
    "response = llm.complete(full_prompt)\n",
    "store.save_analysis(sample_id, \"rhetorician\", response.content, response.model)\n",
    "print(f\"✓ ({len(response.content)} chars)\")\n",
    "\n",
    "# --- SYNTACTICIAN ---\n",
    "print(\"Running syntactician...\", end=\" \")\n",
    "syntactician_prompt = maker.render(SyntacticianConfig())\n",
    "full_prompt = f\"{preamble_instruction}\\n\\n{syntactician_prompt}\\n\\n{preamble_text}\"\n",
    "response = llm.complete(full_prompt)\n",
    "store.save_analysis(sample_id, \"syntactician\", response.content, response.model)\n",
    "print(f\"✓ ({len(response.content)} chars)\")\n",
    "\n",
    "# --- LEXICOLOGIST ---\n",
    "print(\"Running lexicologist...\", end=\" \")\n",
    "lexicologist_prompt = maker.render(LexicologistConfig())\n",
    "full_prompt = f\"{preamble_instruction}\\n\\n{lexicologist_prompt}\\n\\n{preamble_text}\"\n",
    "response = llm.complete(full_prompt)\n",
    "store.save_analysis(sample_id, \"lexicologist\", response.content, response.model)\n",
    "print(f\"✓ ({len(response.content)} chars)\")\n",
    "\n",
    "# --- INFORMATION ARCHITECT ---\n",
    "print(\"Running information_architect...\", end=\" \")\n",
    "info_arch_prompt = maker.render(InformationArchitectConfig())\n",
    "full_prompt = f\"{preamble_instruction}\\n\\n{info_arch_prompt}\\n\\n{preamble_text}\"\n",
    "response = llm.complete(full_prompt)\n",
    "store.save_analysis(sample_id, \"information_architect\", response.content, response.model)\n",
    "print(f\"✓ ({len(response.content)} chars)\")\n",
    "\n",
    "# --- EFFICIENCY AUDITOR ---\n",
    "print(\"Running efficiency_auditor...\", end=\" \")\n",
    "efficiency_prompt = maker.render(EfficiencyAuditorConfig())\n",
    "full_prompt = f\"{preamble_instruction}\\n\\n{efficiency_prompt}\\n\\n{preamble_text}\"\n",
    "response = llm.complete(full_prompt)\n",
    "store.save_analysis(sample_id, \"efficiency_auditor\", response.content, response.model)\n",
    "print(f\"✓ ({len(response.content)} chars)\")\n",
    "\n",
    "print(f\"\\nAll analyses complete for {sample_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcd9a79",
   "metadata": {},
   "source": [
    "## Step 3: Retrieve and Examine Results\n",
    "\n",
    "Check what's been stored and verify all analyses are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all required analyses are present\n",
    "is_complete = store.is_complete(sample_id, ANALYSTS)\n",
    "print(f\"Analysis complete: {is_complete}\")\n",
    "\n",
    "# Retrieve sample and all analyses\n",
    "sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "\n",
    "print(f\"\\nSample: {sample.sample_id}\")\n",
    "print(f\"Source: File {sample.file_index}, paragraphs {sample.paragraph_start}-{sample.paragraph_end}\")\n",
    "print(f\"Analyses available: {list(analyses.keys())}\")\n",
    "\n",
    "# Examine one analysis\n",
    "print(f\"\\n--- Rhetorician Output (first 500 chars) ---\")\n",
    "print(analyses.get(\"rhetorician\", \"Not found\")[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd6a83",
   "metadata": {},
   "source": [
    "## Step 4: Pattern Recognition (Cross-Perspective Integration)\n",
    "\n",
    "Synthesize all analyst perspectives to identify interactions, tensions, and load-bearing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b84827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample and all analyses\n",
    "sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "\n",
    "# Format all analyst reports into a single string\n",
    "specialist_analyses = f\"\"\"**RHETORICIAN:**\n",
    "{analyses['rhetorician']}\n",
    "\n",
    "**SYNTACTICIAN:**\n",
    "{analyses['syntactician']}\n",
    "\n",
    "**LEXICOLOGIST:**\n",
    "{analyses['lexicologist']}\n",
    "\n",
    "**INFORMATION ARCHITECT:**\n",
    "{analyses['information_architect']}\n",
    "\n",
    "**EFFICIENCY AUDITOR:**\n",
    "{analyses['efficiency_auditor']}\n",
    "\"\"\"\n",
    "\n",
    "# Build pattern recognizer prompt using PromptMaker\n",
    "pattern_config = PatternRecognizerTextConfig(\n",
    "    original_text=sample.text,\n",
    "    specialist_analyses=specialist_analyses\n",
    ")\n",
    "pattern_prompt = maker.render(pattern_config)\n",
    "\n",
    "# Get cross-perspective integration\n",
    "print(\"Running pattern recognizer...\", end=\" \")\n",
    "pattern_response = llm.complete(pattern_prompt)\n",
    "print(f\"✓ ({len(pattern_response.content)} chars)\")\n",
    "\n",
    "# Display first part of the synthesis\n",
    "print(\"\\n--- Pattern Recognition Output (first 1000 chars) ---\")\n",
    "print(pattern_response.content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778de35",
   "metadata": {},
   "source": [
    "## Utilities: Working with Stored Samples\n",
    "\n",
    "Helper functions for browsing and managing stored results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a73caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all samples in the database\n",
    "all_samples = store.list_samples()\n",
    "print(f\"Total samples: {len(all_samples)}\")\n",
    "print(f\"Sample IDs: {all_samples}\")\n",
    "\n",
    "# Check completion status for each\n",
    "print(\"\\nCompletion status:\")\n",
    "for sid in all_samples:\n",
    "    complete = store.is_complete(sid, ANALYSTS)\n",
    "    status = \"✓\" if complete else \"✗\"\n",
    "    print(f\"  {status} {sid}\")\n",
    "\n",
    "# Close database connection when done\n",
    "# store.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
