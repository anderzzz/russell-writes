{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Modeling Pipeline\n",
    "\n",
    "This notebook implements a 5-stage pipeline for modeling an author's characteristic writing patterns through few-shot example curation.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "Rather than extracting explicit style rules, this approach models the author's **decision-making patterns** and **sensibility**, then curates exemplary passages for tacit transmission via few-shot learning.\n",
    "\n",
    "## Pipeline Stages\n",
    "\n",
    "0. From a set of template texts, a sample of paragraphs are drawn. Cardinality N.\n",
    "1. Each text sample is analyzed from three perspectives; implied author, decision patterns by author, functional texture. This entails invoking LLMs, cardinality 3N.\n",
    "2. Each perspective is integrated and synthesized across all texts in order to arrive at some total view of said three perspectives. Cardinality 3.\n",
    "3. The three total perspectives are combined and transformed in order to model the author's writing mind, thus producing an \"incantation\" that would make an LLM write like the analyzed author.\n",
    "\n",
    "## Note\n",
    "\n",
    "This pipeline is author-agnostic. The Russell corpus is used as a test case, but the same approach applies to any author, public or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm>=1.80.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.80.0)\n",
      "Requirement already satisfied: pydantic==2.7.4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (2.7.4)\n",
      "Requirement already satisfied: jinja2>=3.1.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (4.13.2)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (3.10.11)\n",
      "Requirement already satisfied: click in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (8.5.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.99.5 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: tokenizers in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (0.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jinja2>=3.1.0->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: anyio in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (3.7.1)\n",
      "Requirement already satisfied: certifi in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: sniffio in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=6.8.0->litellm>=1.80.0->-r requirements.txt (line 1)) (3.20.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (5.10.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2023.12.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (0.20.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from openai>=1.99.5->litellm>=1.80.0->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from openai>=1.99.5->litellm>=1.80.0->-r requirements.txt (line 1)) (0.9.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from openai>=1.99.5->litellm>=1.80.0->-r requirements.txt (line 1)) (4.64.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from tiktoken>=0.7.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2022.4.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from tiktoken>=0.7.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2.27.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from anyio->httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.1.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2.0.12)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (0.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providers\n",
      "=========\n",
      "* openai\n",
      "* openai_like\n",
      "* bytez\n",
      "* xai\n",
      "* custom_openai\n",
      "* text-completion-openai\n",
      "* cohere\n",
      "* cohere_chat\n",
      "* clarifai\n",
      "* anthropic\n",
      "* anthropic_text\n",
      "* replicate\n",
      "* huggingface\n",
      "* together_ai\n",
      "* datarobot\n",
      "* openrouter\n",
      "* cometapi\n",
      "* vertex_ai\n",
      "* vertex_ai_beta\n",
      "* gemini\n",
      "* ai21\n",
      "* baseten\n",
      "* azure\n",
      "* azure_text\n",
      "* azure_ai\n",
      "* sagemaker\n",
      "* sagemaker_chat\n",
      "* bedrock\n",
      "* vllm\n",
      "* nlp_cloud\n",
      "* petals\n",
      "* oobabooga\n",
      "* ollama\n",
      "* ollama_chat\n",
      "* deepinfra\n",
      "* perplexity\n",
      "* mistral\n",
      "* groq\n",
      "* nvidia_nim\n",
      "* cerebras\n",
      "* baseten\n",
      "* ai21_chat\n",
      "* volcengine\n",
      "* codestral\n",
      "* text-completion-codestral\n",
      "* deepseek\n",
      "* sambanova\n",
      "* maritalk\n",
      "* cloudflare\n",
      "* fireworks_ai\n",
      "* friendliai\n",
      "* watsonx\n",
      "* watsonx_text\n",
      "* triton\n",
      "* predibase\n",
      "* databricks\n",
      "* empower\n",
      "* github\n",
      "* custom\n",
      "* litellm_proxy\n",
      "* hosted_vllm\n",
      "* llamafile\n",
      "* lm_studio\n",
      "* galadriel\n",
      "* gradient_ai\n",
      "* github_copilot\n",
      "* novita\n",
      "* meta_llama\n",
      "* featherless_ai\n",
      "* nscale\n",
      "* nebius\n",
      "* dashscope\n",
      "* moonshot\n",
      "* v0\n",
      "* heroku\n",
      "* oci\n",
      "* morph\n",
      "* lambda_ai\n",
      "* vercel_ai_gateway\n",
      "* wandb\n",
      "* ovhcloud\n",
      "* lemonade\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import litellm\n",
    "    print('Providers\\n=========')\n",
    "    print('* ' + '\\n* '.join(litellm.LITELLM_CHAT_PROVIDERS))\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Cannot import litellm: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from belletrist import (\n",
    "    LLM,\n",
    "    LLMConfig,\n",
    "    PromptMaker,\n",
    "    DataSampler,\n",
    "    ResultStore,\n",
    "    \n",
    "    # Stage 1 configs\n",
    "    ImpliedAuthorConfig,\n",
    "    DecisionPatternConfig,\n",
    "    FunctionalTextureConfig,\n",
    "    \n",
    "    # Stage 2 configs\n",
    "    ImpliedAuthorSynthesisConfig,\n",
    "    DecisionPatternSynthesisConfig,\n",
    "    TexturalSynthesisConfig,\n",
    "    \n",
    "    # Stage 3 config\n",
    "    AuthorModelDefinitionConfig,\n",
    ")\n",
    "\n",
    "print(\"Dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Base Objects\n",
    "The LLM, the prompt maker, text data sampler and result store are initialized. Relevant parameters:\n",
    "* `MODEL_NAME`: the string path that defines which model to invoke via `litellm` library. The format is `{provider}/{providers_model_string}`, wherein provider list is given in an earlier cell.\n",
    "* `API_KEY_ENV_VAR`: the environment variable name that contains the API key for the provider. You need to have acquired this key from the provider; **do not** store the key as a string in the notebook, that is playing with fire.\n",
    "* `CORPUS_DIR`: relative path to the place containing template text\n",
    "* `DATABASE_NAME`: name of the result store file for all intermediate outputs, which enables restart\n",
    "* `OUTPUT_DIR`: relative path to the directory for the final output file\n",
    "* `FILE_APPENDIX`: additional string appended to final output file name; note that if the result store contains multiple final outputs, these are already disambiguated by a numeric index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_NAME = 'together_ai/moonshotai/Kimi-K2-Instruct-0905'\n",
    "#MODEL_NAME = 'mistral/mistral-large-2411'\n",
    "MODEL_NAME = 'anthropic/claude-sonnet-4-5-20250929'\n",
    "API_KEY_ENV_VAR = 'ANTHROPIC_API_KEY'\n",
    "#MODEL_TEMPERATURE = 0.7\n",
    "#API_KEY_ENV_VAR = 'TOGETHER_AI_API_KEY'\n",
    "\n",
    "# Initialize LLM\n",
    "llm_config = LLMConfig(\n",
    "    model=MODEL_NAME,\n",
    "    api_key=os.environ.get(API_KEY_ENV_VAR),\n",
    "    #temperature=MODEL_TEMPERATURE\n",
    ")\n",
    "llm = LLM(llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_DIR = Path(\"data/russell\")\n",
    "DATABASE_NAME = \"russell_author_modeling_sonnet.db\"\n",
    "OUTPUT_DIR = Path(\"outputs/author_modeling\")\n",
    "FILE_APPENDIX = 'sonnet'\n",
    "\n",
    "prompt_maker = PromptMaker()\n",
    "sampler = DataSampler(CORPUS_DIR)\n",
    "store = ResultStore(DATABASE_NAME)\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run the following in case you want a clean result store; partial deletes and clean up possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store.reset('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration: Select Samples for Analysis\n",
    "\n",
    "For Stages 1-3, we'll analyze 3-5 samples to extract stable cross-text patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will analyze 5 samples through Stages 1-3\n"
     ]
    }
   ],
   "source": [
    "# Select samples for Stage 1-3 analysis\n",
    "# These should be diverse, substantial passages (500-800 words recommended)\n",
    "ANALYSIS_SAMPLES = [\n",
    "    \"sample_001\",\n",
    "    \"sample_002\",\n",
    "    \"sample_003\",\n",
    "    \"sample_004\",\n",
    "    \"sample_005\",\n",
    "    # Add more as needed for richer cross-text synthesis\n",
    "]\n",
    "\n",
    "# For this demo, we'll generate samples if they don't exist\n",
    "# In production, you might use specific pre-selected samples\n",
    "NUM_SAMPLES = 5\n",
    "SAMPLE_PARAGRAPH_LENGTH = 10\n",
    "\n",
    "print(f\"Will analyze {NUM_SAMPLES} samples through Stages 1-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Analytical Mining\n",
    "\n",
    "Run three specialized analyses on each sample:\n",
    "- **Implied Author**: What sensibility emerges from the prose?\n",
    "- **Decision Patterns**: What compositional choices are made at key junctures?\n",
    "- **Functional Texture**: How do surface features serve purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate or Load Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sample_001\n",
      "Generated sample_002\n",
      "Generated sample_003\n",
      "Generated sample_004\n",
      "Generated sample_005\n",
      "\n",
      "Sample 001 preview:\n",
      "Apart from the special doctrines advocated by Kant, it is very common\n",
      "among philosophers to regard what is _a priori_ as in some sense mental,\n",
      "as concerned rather with the way we must think than with any fact of\n",
      "the outer world. We noted in the preceding chapter the three principles\n",
      "commonly called 'laws of thought'. The view which led to their being so\n",
      "named is a natural one, but there are strong reasons for thinking\n",
      "that it is erroneous. Let us take as an illustration the law of\n",
      "contradiction. This is commonly stated in the form 'Nothing can both be\n",
      "and not be', which is intended to express the fact that nothing can at\n",
      "once have and not have a given quality. Thus, for example, if a tree\n",
      "is a beech it cannot also be not a beech; if my table is rectangular it\n",
      "cannot also be not rectangular, and so on.\n",
      "\n",
      "Now what makes it natural to call this principle a law of _thought_\n",
      "is that it is by thought rather than by outward observation that we\n",
      "persuade ourselves of its necessary truth. When we have seen that a tree\n",
      "is a beech, we do not need to look again in order to ascertain whether\n",
      "it is also not a beech; thought alone makes us know that this is\n",
      "impossible. But the conclusion that the law of contradiction is a law\n",
      "of _thought_ is nevertheless erroneous. What we believe, when we believe\n",
      "the law of contradiction, is not that the mind is so made that it must\n",
      "believe the law of contradiction. _This_ belief is a subsequent result\n",
      "of psychological reflection, which presupposes the belief in the law of\n",
      "contradiction. The belief in the law of contradiction is a belief about\n",
      "things, not only about thoughts. It is not, e.g., the belief that if we\n",
      "_think_ a certain tree is a beech, we cannot at the same time _think_\n",
      "that it is not a beech; it is the belief that if the tree _is_ a\n",
      "beech, it cannot at the same time _be_ not a beech. Thus the law of\n",
      "contradiction is about things, and not merely about thoughts; and\n",
      "although belief in the law of contradiction is a thought, the law of\n",
      "contradiction itself is not a thought, but a fact concerning the things\n",
      "in the world. If this, which we believe when we believe the law of\n",
      "contradiction, were not true of the things in the world, the fact\n",
      "that we were compelled to _think_ it true would not save the law of\n",
      "contradiction from being false; and this shows that the law is not a law\n",
      "of _thought_.\n",
      "\n",
      "A similar argument applies to any other _a priori_ judgement. When we\n",
      "judge that two and two are four, we are not making a judgement about our\n",
      "thoughts, but about all actual or possible couples. The fact that our\n",
      "minds are so constituted as to believe that two and two are four, though\n",
      "it is true, is emphatically not what we assert when we assert that two\n",
      "and two are four. And no fact about the constitution of our minds could\n",
      "make it _true_ that two and two are four. Thus our _a priori_ knowledge,\n",
      "if it is not erroneous, is not merely knowledge about the constitution\n",
      "of our minds, but is applicable to whatever the world may contain, both\n",
      "what is mental and what is non-mental.\n",
      "\n",
      "The fact seems to be that all our _a priori_ knowledge is concerned with\n",
      "entities which do not, properly speaking, _exist_, either in the mental\n",
      "or in the physical world. These entities are such as can be named by\n",
      "parts of speech which are not substantives; they are such entities as\n",
      "qualities and relations. Suppose, for instance, that I am in my room. I\n",
      "exist, and my room exists; but does 'in' exist? Yet obviously the word\n",
      "'in' has a meaning; it denotes a relation which holds between me and my\n",
      "room. This relation is something, although we cannot say that it exists\n",
      "_in the same sense_ in which I and my room exist. The relation 'in' is\n",
      "something which we can think about and understand, for, if we could not\n",
      "understand it, we could not understand the sentence 'I am in my room'.\n",
      "Many philosophers, following Kant, have maintained that relations are\n",
      "the work of the mind, that things in themselves have no relations,\n",
      "but that the mind brings them together in one act of thought and thus\n",
      "produces the relations which it judges them to have.\n",
      "\n",
      "This view, however, seems open to objections similar to those which we\n",
      "urged before against Kant. It seems plain that it is not thought which\n",
      "produces the truth of the proposition 'I am in my room'. It may be true\n",
      "that an earwig is in my room, even if neither I nor the earwig nor any\n",
      "one else is aware of this truth; for this truth concerns only the earwig\n",
      "and the room, and does not depend upon anything else. Thus relations, as\n",
      "we shall see more fully in the next chapter, must be placed in a world\n",
      "which is neither mental nor physical. This world is of great importance\n",
      "to philosophy, and in particular to the problems of _a priori_\n",
      "knowledge. In the next chapter we shall proceed to develop its nature\n",
      "and its bearing upon the questions with which we have been dealing.\n",
      "\n",
      "CHAPTER IX. THE WORLD OF UNIVERSALS\n",
      "\n",
      "At the end of the preceding chapter we saw that such entities as\n",
      "relations appear to have a being which is in some way different from\n",
      "that of physical objects, and also different from that of minds and from\n",
      "that of sense-data. In the present chapter we have to consider what is\n",
      "the nature of this kind of being, and also what objects there are that\n",
      "have this kind of being. We will begin with the latter question.\n",
      "\n",
      "The problem with which we are now concerned is a very old one, since it\n",
      "was brought into philosophy by Plato. Plato's 'theory of ideas' is an\n",
      "attempt to solve this very problem, and in my opinion it is one of the\n",
      "most successful attempts hitherto made. The theory to be advocated in\n",
      "what follows is largely Plato's, with merely such modifications as time\n",
      "has shown to be necessary.\n",
      "\n",
      "The way the problem arose for Plato was more or less as follows. Let\n",
      "us consider, say, such a notion as _justice_. If we ask ourselves what\n",
      "justice is, it is natural to proceed by considering this, that, and the\n",
      "other just act, with a view to discovering what they have in common.\n",
      "They must all, in some sense, partake of a common nature, which will be\n",
      "found in whatever is just and in nothing else. This common nature, in\n",
      "virtue of which they are all just, will be justice itself, the pure\n",
      "essence the admixture of which with facts of ordinary life produces the\n",
      "multiplicity of just acts. Similarly with any other word which may be\n",
      "applicable to common facts, such as 'whiteness' for example. The word\n",
      "will be applicable to a number of particular things because they all\n",
      "participate in a common nature or essence. This pure essence is what\n",
      "Plato calls an 'idea' or 'form'. (It must not be supposed that 'ideas',\n",
      "in his sense, exist in minds, though they may be apprehended by minds.)\n",
      "The 'idea' _justice_ is not identical with anything that is just: it is\n",
      "something other than particular things, which particular things partake\n",
      "of. Not being particular, it cannot itself exist in the world of sense.\n",
      "Moreover it is not fleeting or changeable like the things of sense: it\n",
      "is eternally itself, immutable and indestructible.\n",
      "\n",
      "Thus Plato is led to a supra-sensible world, more real than the common\n",
      "world of sense, the unchangeable world of ideas, which alone gives to\n",
      "the world of sense whatever pale reflection of reality may belong to it.\n",
      "The truly real world, for Plato, is the world of ideas; for whatever\n",
      "we may attempt to say about things in the world of sense, we can only\n",
      "succeed in saying that they participate in such and such ideas, which,\n",
      "therefore, constitute all their character. Hence it is easy to pass\n",
      "on into a mysticism. We may hope, in a mystic illumination, to see the\n",
      "ideas as we see objects of sense; and we may imagine that the ideas\n",
      "exist in heaven. These mystical developments are very natural, but the\n",
      "basis of the theory is in logic, and it is as based in logic that we\n",
      "have to consider it....\n"
     ]
    }
   ],
   "source": [
    "# Generate samples if they don't exist\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    \n",
    "    # Skip if already saved\n",
    "    if store.get_sample(sample_id):\n",
    "        print(f\"✓ {sample_id} already gathered\")\n",
    "        continue\n",
    "        \n",
    "    # Generate new sample\n",
    "    segment = sampler.sample_segment(p_length=SAMPLE_PARAGRAPH_LENGTH)\n",
    "    store.save_segment(sample_id, segment)\n",
    "    print(f\"Generated {sample_id}\")\n",
    "\n",
    "# Display first sample for reference\n",
    "sample = store.get_sample(\"sample_001\")\n",
    "print(f\"\\nSample 001 preview:\\n{sample['text']}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Stage 1A: Implied Author Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_001: Running implied_author analysis...\n",
      "sample_001: implied_author analysis complete\n",
      "sample_002: Running implied_author analysis...\n",
      "sample_002: implied_author analysis complete\n",
      "sample_003: Running implied_author analysis...\n",
      "sample_003: implied_author analysis complete\n",
      "sample_004: Running implied_author analysis...\n",
      "sample_004: implied_author analysis complete\n",
      "sample_005: Running implied_author analysis...\n",
      "sample_005: implied_author analysis complete\n",
      "\n",
      "Stage 1A complete: All samples analyzed for implied author\n"
     ]
    }
   ],
   "source": [
    "# Analyze each sample for implied author\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    analyst_name = ImpliedAuthorConfig.analyst_name()\n",
    "    \n",
    "    # Check if analysis already exists (resume support)\n",
    "    if store.get_analysis(sample_id, analyst_name):\n",
    "        print(f\"{sample_id}: {analyst_name} analysis already complete\")\n",
    "        continue\n",
    "    \n",
    "    # Get sample text\n",
    "    sample = store.get_sample(sample_id)\n",
    "    \n",
    "    # Generate prompt\n",
    "    config = ImpliedAuthorConfig(text=sample['text'])\n",
    "    prompt = prompt_maker.render(config)\n",
    "    \n",
    "    # Run LLM\n",
    "    print(f\"{sample_id}: Running {analyst_name} analysis...\")\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    # Save analysis\n",
    "    store.save_analysis(\n",
    "        sample_id=sample_id,\n",
    "        analyst=analyst_name,\n",
    "        output=response.content,\n",
    "        model=response.model\n",
    "    )\n",
    "    print(f\"{sample_id}: {analyst_name} analysis complete\")\n",
    "\n",
    "print(\"\\nStage 1A complete: All samples analyzed for implied author\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Stage 1B: Decision Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_001: Running decision_pattern analysis...\n",
      "sample_001: decision_pattern analysis complete\n",
      "sample_002: Running decision_pattern analysis...\n",
      "sample_002: decision_pattern analysis complete\n",
      "sample_003: Running decision_pattern analysis...\n",
      "sample_003: decision_pattern analysis complete\n",
      "sample_004: Running decision_pattern analysis...\n",
      "sample_004: decision_pattern analysis complete\n",
      "sample_005: Running decision_pattern analysis...\n",
      "sample_005: decision_pattern analysis complete\n",
      "\n",
      "Stage 1B complete: All samples analyzed for decision patterns\n"
     ]
    }
   ],
   "source": [
    "# Analyze each sample for decision patterns\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    analyst_name = DecisionPatternConfig.analyst_name()\n",
    "    \n",
    "    if store.get_analysis(sample_id, analyst_name):\n",
    "        print(f\"{sample_id}: {analyst_name} analysis already complete\")\n",
    "        continue\n",
    "    \n",
    "    sample = store.get_sample(sample_id)\n",
    "    config = DecisionPatternConfig(text=sample['text'])\n",
    "    prompt = prompt_maker.render(config)\n",
    "    \n",
    "    print(f\"{sample_id}: Running {analyst_name} analysis...\")\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    store.save_analysis(\n",
    "        sample_id=sample_id,\n",
    "        analyst=analyst_name,\n",
    "        output=response.content,\n",
    "        model=response.model\n",
    "    )\n",
    "    print(f\"{sample_id}: {analyst_name} analysis complete\")\n",
    "\n",
    "print(\"\\nStage 1B complete: All samples analyzed for decision patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Stage 1C: Functional Texture Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_001: Running functional_texture analysis...\n",
      "sample_001: functional_texture analysis complete\n",
      "sample_002: Running functional_texture analysis...\n",
      "sample_002: functional_texture analysis complete\n",
      "sample_003: Running functional_texture analysis...\n",
      "sample_003: functional_texture analysis complete\n",
      "sample_004: Running functional_texture analysis...\n",
      "sample_004: functional_texture analysis complete\n",
      "sample_005: Running functional_texture analysis...\n",
      "sample_005: functional_texture analysis complete\n",
      "\n",
      "Stage 1C complete: All samples analyzed for functional texture\n"
     ]
    }
   ],
   "source": [
    "# Analyze each sample for functional texture\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    analyst_name = FunctionalTextureConfig.analyst_name()\n",
    "    \n",
    "    if store.get_analysis(sample_id, analyst_name):\n",
    "        print(f\"{sample_id}: {analyst_name} analysis already complete\")\n",
    "        continue\n",
    "    \n",
    "    sample = store.get_sample(sample_id)\n",
    "    config = FunctionalTextureConfig(text=sample['text'])\n",
    "    prompt = prompt_maker.render(config)\n",
    "    \n",
    "    print(f\"{sample_id}: Running {analyst_name} analysis...\")\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    store.save_analysis(\n",
    "        sample_id=sample_id,\n",
    "        analyst=analyst_name,\n",
    "        output=response.content,\n",
    "        model=response.model\n",
    "    )\n",
    "    print(f\"{sample_id}: {analyst_name} analysis complete\")\n",
    "\n",
    "print(\"\\nStage 1C complete: All samples analyzed for functional texture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Stage 1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_001: 3 analyses complete\n",
      "  - decision_pattern\n",
      "  - functional_texture\n",
      "  - implied_author\n",
      "sample_002: 3 analyses complete\n",
      "  - decision_pattern\n",
      "  - functional_texture\n",
      "  - implied_author\n",
      "sample_003: 3 analyses complete\n",
      "  - decision_pattern\n",
      "  - functional_texture\n",
      "  - implied_author\n",
      "sample_004: 3 analyses complete\n",
      "  - decision_pattern\n",
      "  - functional_texture\n",
      "  - implied_author\n",
      "sample_005: 3 analyses complete\n",
      "  - decision_pattern\n",
      "  - functional_texture\n",
      "  - implied_author\n",
      "\n",
      "--- Sample Implied Author Analysis (first 500 chars) ---\n",
      "Total chars: 16382\n",
      "# IMPLIED AUTHOR CONSTRUCTION\n",
      "\n",
      "## PART 1: DIMENSIONAL ANALYSIS\n",
      "\n",
      "### 1. RELATIONSHIP TO MATERIAL\n",
      "\n",
      "**Observation**: This author approaches philosophical problems with the stance of a diagnostician identifying disease—specifically, the disease of inherited error. The writing exhibits intellectual confidence combined with reformist zeal; the author is not discovering so much as *correcting*, dismantling structures that persist through inertia rather than merit.\n",
      "\n",
      "**Evidence**:\n",
      "\n",
      "**Passage 1**: \"I believe the conception of 'the universe' to be, as its etymology indicates, a mere relic of pre-Copernican astronomy: and I believe the question of optimism and pessimism to be one which the philosopher will regard as outside his scope, except, possibly, to the extent of maintaining that it is insoluble.\"\n",
      "\n",
      "**Passage 2**: \"When Copernicus swept away the astronomical basis of this system of thought, it had grown so familiar, and had associated itself so intimately with men's aspirations, that it survived with scarcely diminished force--survived even Kant's 'Copernican revolution,' and is still now the unconscious premiss of most metaphysical systems.\"\n",
      "\n",
      "**Passage 3**: \"The prudent man of science acquires a certain instinct as to the kind of uses which may be made of present scientific beliefs without incurring the danger of complete and utter refutation from the modifications likely to be introduced by subsequent discoveries.\"\n",
      "\n",
      "**What these reveal**: The first passage demonstrates the author's willingness to make bold dismissals—calling a foundational philosophical concept a \"mere relic\" and declaring entire questions \"outside scope.\" The second shows the author's characteristic move: tracing contemporary errors to historical origins, explaining persistence through psychology (\"men's aspirations\") rather than validity. The third reveals comfort with complexity through the notion of \"instinct\"—the author doesn't simplify the relationship between science and philosophy but articulates its nuanced difficulty. Throughout, the stance is that of someone who has seen through illusions and is methodically explaining how others remain captive to them.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. RELATIONSHIP TO READER\n",
      "\n",
      "**Observation**: The author addresses a reader presumed to be educated in philosophy but potentially trapped in conventional thinking. The relationship is tutorial but not condescending—more like a senior colleague alerting a junior to systematic errors than a teacher instructing a novice. The author assumes familiarity with philosophical debates but not necessarily agreement or full clarity.\n",
      "\n",
      "**Evidence**:\n",
      "\n",
      "**Passage 1**: \"'Reality is not merely one and self-consistent, but is a system of reciprocally determinate parts'[19]--such a statement would pass almost unnoticed as a mere truism. Yet I believe that it embodies a failure to effect thoroughly the 'Copernican revolution,' and that the apparent oneness of the world is merely the oneness of what is seen by a single spectator or apprehended by a single mind.\"\n",
      "\n",
      "**Passage 2**: \"We may illustrate these general considerations by means of two examples, namely, the conservation of energy and the principle of evolution.\"\n",
      "\n",
      "**Passage 3**: \"There are here, as it seems to me, three distinct errors. First, the detailed scientific investigation of nature does not _presuppose_ any such general laws as its results are found to verify.\"\n",
      "\n",
      "**What these reveal**: The first passage shows the author imagining a reader who would find the quoted statement unremarkable (\"would pass almost unnoticed\")—thus a reader immersed in philosophical discourse. The author then positions himself as revealing what lies hidden in plain sight. The second passage's transitional clarity (\"We may illustrate\") suggests pedagogical intent but assumes the reader can follow \"general considerations\" into specific cases. The third passage's enumeration (\"three distinct errors. First...\") and the qualifier \"as it seems to me\" establishes a tone of collaborative reasoning—the author is making a case, not issuing pronouncements. The relationship is one of intellectual partnership with asymmetric insight.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. RELATIONSHIP TO UNCERTAINTY\n",
      "\n",
      "**Observation**: The author distinguishes sharply between legitimate certainty and overreach, showing comfort with provisional conclusions while being uncompromising about logical boundaries. Uncertainty is acknowledged precisely where it matters—in empirical generalizations—while conceptual clarifications are stated with confidence.\n",
      "\n",
      "**Evidence**:\n",
      "\n",
      "**Passage 1**: \"In part, no doubt, its despair was well founded, but not, I think, in any absolute or ultimate sense. Still less was it a ground for rejoicing, or for supposing that the nescience to which it ought to have given rise could be legitimately exchanged for a metaphysical dogmatism.\"\n",
      "\n",
      "**Passage 2**: \"Mass, which used to be regarded as the most indubitable of physical quantities, is now generally believed to vary according to velocity, and to be, in fact, a vector quantity which at a given moment is different in different directions.\"\n",
      "\n",
      "**Passage 3**: \"The prudent philosopher, therefore, though he may with advantage study the methods of physics, will be very chary of basing anything upon what happen at the moment to be the most general results apparently obtained by those methods.\"\n",
      "\n",
      "**What these reveal**: The first passage shows careful qualification (\"In part, no doubt... but not, I think\") where assessing philosophical positions, yet firm judgment about what follows from this uncertainty. The author is comfortable saying something is partially but not wholly true. The second passage demonstrates intellectual honesty about the provisional nature of scientific \"certainty\"—even mass, \"the most indubitable,\" is now under revision. The author reports this without anxiety. The third passage reveals the author's ethical stance toward uncertainty: the \"prudent philosopher\" exercises caution not from timidity but from understanding the nature of scientific knowledge. The word \"chary\" is particularly telling—suggesting wariness born of wisdom rather than doubt born of confusion.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. RELATIONSHIP TO THE ACT OF WRITING\n",
      "\n",
      "**Observation**: The prose pursues clarity with occasional flashes of rhetorical pleasure, particularly in exposure of absurdity. The writing is primarily instrumental—designed to convey complex arguments transparently—but the author cannot resist moments of elegant demolition and ironic observation.\n",
      "\n",
      "**Evidence**:\n",
      "\n",
      "**Passage 1**: \"I believe the conception of 'the universe' to be, as its etymology indicates, a mere relic of pre-Copernican astronomy\"\n",
      "\n",
      "**Passage 2**: \"The importance attached by certain monistic writers to the fact that any chaos may become a universe by merely being named, is to me incomprehensible.\"\n",
      "\n",
      "**Passage 3**: \"Thus what is surprising in physics is not the existence of general laws, but their extreme simplicity. It is not the uniformity of nature that should surprise us, for, by sufficient analytic ingenuity, any conceivable course of nature might be shown to exhibit uniformity. What should surprise us is the fact that the uniformity is simple enough for us to be able to discover it.\"\n",
      "\n",
      "**What these reveal**: The first passage shows pleasure in etymological exposure—the universe revealed as \"universe\" through its own name. There's wit in making the word indict itself. The second passage's concluding \"is to me incomprehensible\" carries rhetorical force beyond mere statement—it's a dismissal with edge, suggesting the position is not just wrong but beneath serious consideration. The third passage demonstrates the author's capacity for elegant inversion: building through parallel structure (\"is not... but,\" \"It is not... What should\") to redirect attention from the obvious to the genuinely remarkable. The repetition of \"surprise\" creates rhythm that serves argument. While the prose doesn't call excessive attention to itself, these moments reveal an author who takes satisfaction in well-constructed sentences that do philosophical work.\n",
      "\n",
      "---\n",
      "\n",
      "## PART 2: SIGNATURE MOMENTS\n",
      "\n",
      "### Signature Moment 1\n",
      "\n",
      "**Passage**: \"When Copernicus swept away the astronomical basis of this system of thought, it had grown so familiar, and had associated itself so intimately with men's aspirations, that it survived with scarcely diminished force--survived even Kant's 'Copernican revolution,' and is still now the unconscious premiss of most metaphysical systems.\"\n",
      "\n",
      "**What makes it recognizable**: This sentence encapsulates the author's historical-diagnostic method: identifying a moment of scientific revolution (Copernicus), tracing psychological resistance to change (\"men's aspirations\"), noting ironic persistence (surviving even Kant's metaphorical invocation of the same revolution), and delivering a damning assessment of the contemporary state (\"unconscious premiss\"). The structure moves from past to present, from explicit to unconscious, building a case for how error perpetuates itself.\n",
      "\n",
      "**Dimensions converging**: Relationship to material (diagnostic stance), relationship to reader (assuming familiarity with Kant), relationship to uncertainty (confident about this historical-philosophical claim), relationship to writing (the elegant irony of Kant's \"Copernican revolution\" failing to complete what Copernicus began).\n",
      "\n",
      "---\n",
      "\n",
      "### Signature Moment 2\n",
      "\n",
      "**Passage**: \"That the things which we experience have the common property of being experienced by us is a truism from which obviously nothing of importance can be deducible: it is clearly fallacious to draw from the fact that whatever we experience is experienced the conclusion that therefore everything must be experienced.\"\n",
      "\n",
      "**What makes it recognizable**: This demonstrates the author's method of exposing fallacy through patient logical analysis. The tautology is stated plainly (\"things which we experience... being experienced by us\"), its triviality is asserted (\"a truism\"), and then the specific error in reasoning is articulated with precision. The repetition of \"experience/experienced\" hammers home the circularity. The tone is one of someone explaining what should be obvious but apparently isn't.\n",
      "\n",
      "**Dimensions converging**: Relationship to material (dismantling inherited error), relationship to reader (explaining what the reader may have missed), relationship to uncertainty (complete confidence in this logical point), relationship to writing (clarity as the primary virtue, though with rhetorical force in the repetition).\n",
      "\n",
      "---\n",
      "\n",
      "### Signature Moment 3\n",
      "\n",
      "**Passage**: \"Thus what is surprising in physics is not the existence of general laws, but their extreme simplicity. It is not the uniformity of nature that should surprise us, for, by sufficient analytic ingenuity, any conceivable course of nature might be shown to exhibit uniformity. What should surprise us is the fact that the uniformity is simple enough for us to be able to discover it.\"\n",
      "\n",
      "**What makes it recognizable**: This passage exemplifies the author's ability to redirect philosophical attention from conventional puzzlement to what genuinely merits it. The parallel structure (\"is not... but,\" \"It is not... What should\") creates a pedagogical rhythm, guiding the reader from mistaken to correct understanding. The phrase \"by sufficient analytic ingenuity\" reveals the author's technical sophistication—understanding that mathematical formalization can impose apparent order on any data. The conclusion points toward epistemic humility (we can only discover simple laws) while maintaining analytical precision.\n",
      "\n",
      "**Dimensions converging**: Relationship to material (correcting widespread misunderstanding), relationship to reader (reorienting the reader's sense of wonder), relationship to uncertainty (acknowledging limits of what we can know), relationship to writing (using parallel structure for philosophical effect).\n",
      "\n",
      "---\n",
      "\n",
      "### Signature Moment 4\n",
      "\n",
      "**Passage**: \"The prudent man of science acquires a certain instinct as to the kind of uses which may be made of present scientific beliefs without incurring the danger of complete and utter refutation from the modifications likely to be introduced by subsequent discoveries. Unfortunately the use of scientific generalisations of a sweeping kind as the basis of philosophy is just that kind of use which an instinct of scientific caution would avoid, since, as a rule, it would only lead to true results if the generalisation upon which it is based stood in _no_ need of correction.\"\n",
      "\n",
      "**What makes it recognizable**: This passage reveals the author's characteristic move of articulating tacit knowledge (\"a certain instinct\") and then using it as a standard against which to judge philosophical practice. The \"prudent man of science\" serves as an implicit rebuke to the imprudent philosopher. The sentence structure is complex but controlled, building toward the devastating conclusion that philosophy's typical use of science is precisely what scientific wisdom would avoid. The italicized \"_no_\" emphasizes the impossibility of the required condition.\n",
      "\n",
      "**Dimensions converging**: Relationship to material (methodological critique), relationship to reader (assuming the reader can follow complex conditional reasoning), relationship to uncertainty (the entire passage is about proper response to provisional knowledge), relationship to writing (the long, carefully constructed sentence that delivers its point at the end).\n",
      "\n",
      "---\n",
      "\n",
      "### Signature Moment 5\n",
      "\n",
      "**Passage**: \"The whole conception of quantity, involving, as it does, numerical measurement based largely upon conventions, is far more artificial, far more an embodiment of mathematical convenience, than is commonly believed by those who philosophise on physics.\"\n",
      "\n",
      "**What makes it recognizable**: This sentence demonstrates the author's ability to puncture philosophical pretension with technical knowledge. The parenthetical insertion (\"as it does\") adds emphasis while maintaining flow. The repetition of \"far more\" creates rhetorical force, and the phrase \"those who philosophise on physics\" carries a subtle dismissiveness—these are not physicists themselves but philosophers working at second hand. The claim is bold (quantity is \"largely conventional\") but stated as established fact, revealing the author's confidence in having superior understanding of scientific practice.\n",
      "\n",
      "**Dimensions converging**: Relationship to material (exposing philosophical naiveté about science), relationship to reader (distinguishing the author and reader from \"those who philosophise on physics\"), relationship to uncertainty (confident about this epistemological point), relationship to writing (the balanced, emphatic construction).\n",
      "\n",
      "---\n",
      "\n",
      "## PART 3: SYNTHETIC PORTRAIT\n",
      "\n",
      "This author writes as a philosophical reformer armed with logical analysis and scientific literacy, determined to free philosophy from the gravitational pull of pre-scientific worldviews. The temperament is confident without being dogmatic—bold in dismissing inherited errors, careful in distinguishing legitimate from illegitimate certainty. There is intellectual impatience with muddle, particularly with philosophy's tendency to inflate empirical generalizations into metaphysical necessities, yet patience in explaining precisely where and why reasoning goes wrong.\n",
      "\n",
      "The sensibility values clarity, precision, and intellectual honesty above systematic completeness. The author takes visible satisfaction in exposing how seemingly sophisticated positions rest on elementary confusions, tracing contemporary errors to historical origins that reveal their contingency. While the prose is primarily instrumental—designed to convey complex arguments transparently—there are flashes of rhetorical pleasure in elegant demolition and ironic observation.\n",
      "\n",
      "The stance toward readers is tutorial but collegial: assuming philosophical education but not necessarily clear thinking, offering correction as collaborative enlightenment rather than authoritative pronouncement. The author exhibits the ethos of the \"prudent man of science\"—understanding that the most general claims are most provisional, that what persists through scientific revolution is method rather than results, and that philosophy's proper relation to science is methodological rather than parasitic. Above all, this is a mind committed to thinking clearly about thinking itself.\n"
     ]
    }
   ],
   "source": [
    "# Display completion status\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "    print(f\"{sample_id}: {len(analyses)} analyses complete\")\n",
    "    for analyst_name in analyses.keys():\n",
    "        print(f\"  - {analyst_name}\")\n",
    "\n",
    "# Optionally display one analysis\n",
    "print(\"\\n--- Sample Implied Author Analysis (first 500 chars) ---\")\n",
    "sample, analyses = store.get_sample_with_analyses(\"sample_005\")\n",
    "implied_author = analyses.get(ImpliedAuthorConfig.analyst_name(), \"Not found\")\n",
    "print(f\"Total chars: {len(implied_author)}\")\n",
    "print(implied_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Cross-Text Synthesis\n",
    "\n",
    "Synthesize each analytical dimension across samples to identify stable patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2A: Implied Author Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running implied author synthesis...\n",
      "Synthesis saved: implied_author_synthesis_001\n",
      "\n",
      "Preview (first 400 chars):\n",
      "# SYNTHETIC IMPLIED AUTHOR PORTRAIT\n",
      "\n",
      "## PART 1: THE STABLE CORE\n",
      "\n",
      "### Fundamental Stance Toward Ideas and Inquiry\n",
      "\n",
      "This author consistently engages with subject matter as **problems yielding to patient analysis rather than mysteries requiring special insight**. Whether addressing logical principles, civilizational patterns, or scientific methodology, the stance is that of someone who has achieved c...\n"
     ]
    }
   ],
   "source": [
    "# Collect all implied author analyses\n",
    "implied_author_analyses = {}\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    analysis = store.get_analysis(sample_id, ImpliedAuthorConfig.analyst_name())\n",
    "    if analysis:\n",
    "        implied_author_analyses[sample_id] = analysis\n",
    "\n",
    "# Check if synthesis already exists\n",
    "synthesis_type = ImpliedAuthorSynthesisConfig.synthesis_type()\n",
    "existing = store.list_syntheses(synthesis_type)\n",
    "\n",
    "if existing:\n",
    "    print(f\"Implied author synthesis already exists: {existing[0]}\")\n",
    "    implied_author_synthesis_id = existing[0]\n",
    "else:\n",
    "    # Generate synthesis prompt\n",
    "    config = ImpliedAuthorSynthesisConfig(\n",
    "        implied_author_analyses=implied_author_analyses\n",
    "    )\n",
    "    prompt = prompt_maker.render(config)\n",
    "    \n",
    "    # Run synthesis\n",
    "    print(\"Running implied author synthesis...\")\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    # Save synthesis\n",
    "    sample_contributions = [\n",
    "        (sample_id, ImpliedAuthorConfig.analyst_name())\n",
    "        for sample_id in implied_author_analyses.keys()\n",
    "    ]\n",
    "    \n",
    "    implied_author_synthesis_id = store.save_synthesis(\n",
    "        synthesis_type=synthesis_type,\n",
    "        output=response.content,\n",
    "        model=response.model,\n",
    "        sample_contributions=sample_contributions,\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"Synthesis saved: {implied_author_synthesis_id}\")\n",
    "\n",
    "# Display preview\n",
    "synth = store.get_synthesis(implied_author_synthesis_id)\n",
    "print(f\"\\nPreview (first 400 chars):\\n{synth['output'][:400]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2B: Decision Pattern Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running decision pattern synthesis...\n",
      "Synthesis saved: decision_pattern_synthesis_001\n",
      "\n",
      "Preview (first 400 chars):\n",
      "# SYNTHESIS: COMPOSITIONAL DECISION PATTERNS\n",
      "\n",
      "## PART 1: COMPOSITIONAL PROBLEM TAXONOMY\n",
      "\n",
      "### 1. **Opening Complex Arguments**\n",
      "Establishing the stakes, scope, and oppositional frame of a philosophical argument without losing readers in abstraction or appearing to strawman opposing views.\n",
      "\n",
      "### 2. **Making Abstract Distinctions Concrete**\n",
      "Rendering philosophical differences (thought vs. thing, episte...\n"
     ]
    }
   ],
   "source": [
    "# Collect all decision pattern analyses\n",
    "decision_pattern_analyses = {}\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    analysis = store.get_analysis(sample_id, DecisionPatternConfig.analyst_name())\n",
    "    if analysis:\n",
    "        decision_pattern_analyses[sample_id] = analysis\n",
    "\n",
    "# Check if synthesis already exists\n",
    "synthesis_type = DecisionPatternSynthesisConfig.synthesis_type()\n",
    "existing = store.list_syntheses(synthesis_type)\n",
    "\n",
    "if existing:\n",
    "    print(f\"Decision pattern synthesis already exists: {existing[0]}\")\n",
    "    decision_pattern_synthesis_id = existing[0]\n",
    "else:\n",
    "    config = DecisionPatternSynthesisConfig(\n",
    "        decision_pattern_analyses=decision_pattern_analyses\n",
    "    )\n",
    "    prompt = prompt_maker.render(config)\n",
    "    \n",
    "    print(\"Running decision pattern synthesis...\")\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    sample_contributions = [\n",
    "        (sample_id, DecisionPatternConfig.analyst_name())\n",
    "        for sample_id in decision_pattern_analyses.keys()\n",
    "    ]\n",
    "    \n",
    "    decision_pattern_synthesis_id = store.save_synthesis(\n",
    "        synthesis_type=synthesis_type,\n",
    "        output=response.content,\n",
    "        model=response.model,\n",
    "        sample_contributions=sample_contributions,\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"Synthesis saved: {decision_pattern_synthesis_id}\")\n",
    "\n",
    "synth = store.get_synthesis(decision_pattern_synthesis_id)\n",
    "print(f\"\\nPreview (first 400 chars):\\n{synth['output'][:400]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2C: Textural Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running textural synthesis...\n",
      "Synthesis saved: textural_synthesis_001\n",
      "\n",
      "Preview (first 400 chars):\n",
      "# SYNTHESIS: CHARACTERISTIC PROSE TEXTURE\n",
      "\n",
      "## PART 1: SENTENCE ARCHITECTURE\n",
      "\n",
      "### Structural Character\n",
      "\n",
      "This author builds sentences as **instruments of progressive clarification**. The characteristic movement is **assertion followed by elaborative refinement**—a main clause establishes a position or observation, then the sentence unfolds rightward through qualifying phrases, contrastive elements, ...\n"
     ]
    }
   ],
   "source": [
    "# Collect all functional texture analyses\n",
    "textural_analyses = {}\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    analysis = store.get_analysis(sample_id, FunctionalTextureConfig.analyst_name())\n",
    "    if analysis:\n",
    "        textural_analyses[sample_id] = analysis\n",
    "\n",
    "# Check if synthesis already exists\n",
    "synthesis_type = TexturalSynthesisConfig.synthesis_type()\n",
    "existing = store.list_syntheses(synthesis_type)\n",
    "\n",
    "if existing:\n",
    "    print(f\"Textural synthesis already exists: {existing[0]}\")\n",
    "    textural_synthesis_id = existing[0]\n",
    "else:\n",
    "    config = TexturalSynthesisConfig(\n",
    "        textural_analyses=textural_analyses\n",
    "    )\n",
    "    prompt = prompt_maker.render(config)\n",
    "    \n",
    "    print(\"Running textural synthesis...\")\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    sample_contributions = [\n",
    "        (sample_id, FunctionalTextureConfig.analyst_name())\n",
    "        for sample_id in textural_analyses.keys()\n",
    "    ]\n",
    "    \n",
    "    textural_synthesis_id = store.save_synthesis(\n",
    "        synthesis_type=synthesis_type,\n",
    "        output=response.content,\n",
    "        model=response.model,\n",
    "        sample_contributions=sample_contributions,\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"Synthesis saved: {textural_synthesis_id}\")\n",
    "\n",
    "synth = store.get_synthesis(textural_synthesis_id)\n",
    "print(f\"\\nPreview (first 400 chars):\\n{synth['output'][:400]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Author Model Creation\n",
    "At the final stage, the outputs from steps 2 are joined and integrated into a prescriptive text that can be used to imbue another LLM with the writing style and sensibilities of the author of the analyzed texts. This yields the final output, which in addition to being stored in the database, is exported as a meta data enhanced markdown file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing author model definition...\n",
      "Author model definition saved: author_model_definition_001\n",
      "\n",
      "Total chars of Author Model: 20176\n",
      "\n",
      "Author Model Preview (first 800 chars):\n",
      "# AUTHOR MIND MODEL: BERTRAND RUSSELL\n",
      "\n",
      "---\n",
      "\n",
      "## PART 1: THE GENERATIVE STANCE\n",
      "\n",
      "When you write as this author, you inhabit a position of **clarity achieved and being transmitted**. You are not discovering in real-time; you have thought through the confusions, identified where thinking goes wrong, and now demonstrate the path to understanding. Your relationship to your material is that of someone who has **solved the puzzle and now shows others the solution**—not with condescension, but with the confidence that clear thinking is accessible to anyone willing to follow the reasoning.\n",
      "\n",
      "**Your orientation to material** is fundamentally diagnostic. When you encounter a philosophical problem or cultural phenomenon, you ask: *Where does the confusion originate? What historical accident or logical er...\n",
      "\n",
      "Author model exported to: outputs/author_modeling/author_model_definition_001_sonnet.txt\n"
     ]
    }
   ],
   "source": [
    "implied_synth = store.get_synthesis(implied_author_synthesis_id)\n",
    "decision_synth = store.get_synthesis(decision_pattern_synthesis_id)\n",
    "textural_synth = store.get_synthesis(textural_synthesis_id)\n",
    "\n",
    "# Check if author model definition already exists\n",
    "synthesis_type = AuthorModelDefinitionConfig.synthesis_type()\n",
    "existing = store.list_syntheses(synthesis_type)\n",
    "\n",
    "if existing:\n",
    "    print(f\"Author model definition already exists: {existing[0]}\")\n",
    "    author_model_id = existing[0]\n",
    "else:\n",
    "    # Generate author model definition\n",
    "    config = AuthorModelDefinitionConfig(\n",
    "        implied_author_synthesis=implied_synth['output'],\n",
    "        decision_pattern_synthesis=decision_synth['output'],\n",
    "        textural_synthesis=textural_synth['output']\n",
    "    )\n",
    "    prompt = prompt_maker.render(config)\n",
    "\n",
    "    print(\"Constructing author model definition...\")\n",
    "    response = llm.complete(prompt)\n",
    "\n",
    "    # Save with parent linkage (no direct sample contributions)\n",
    "    author_model_id = store.save_synthesis(\n",
    "        synthesis_type=synthesis_type,\n",
    "        output=response.content,\n",
    "        model=response.model,\n",
    "        sample_contributions=[],  # Inherits from parents\n",
    "        config=config,\n",
    "        parent_synthesis_id=implied_author_synthesis_id  # Link to one parent\n",
    "    )\n",
    "    print(f\"Author model definition saved: {author_model_id}\")\n",
    "\n",
    "# Display preview\n",
    "author_model = store.get_synthesis(author_model_id)\n",
    "print(f\"\\nTotal chars of Author Model: {len(author_model['output'])}\")\n",
    "print(f\"\\nAuthor Model Preview (first 800 chars):\\n{author_model['output'][:800]}...\")\n",
    "\n",
    "\n",
    "author_model_path = OUTPUT_DIR / f\"{author_model_id}_{FILE_APPENDIX}.txt\"\n",
    "store.export_synthesis(\n",
    "    synthesis_id=author_model_id,\n",
    "    output_path=author_model_path,\n",
    "    metadata_format='yaml'\n",
    ")\n",
    "print(f\"\\nAuthor model exported to: {author_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (russell_writes)",
   "language": "python",
   "name": "russell_writes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
