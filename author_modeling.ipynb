{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Modeling Pipeline\n",
    "\n",
    "This notebook implements a 5-stage pipeline for modeling an author's characteristic writing patterns through few-shot example curation.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "Rather than extracting explicit style rules, this approach models the author's **decision-making patterns** and **sensibility**, then curates exemplary passages for tacit transmission via few-shot learning.\n",
    "\n",
    "## Pipeline Stages\n",
    "\n",
    "1. **Stage 1: Analytical Mining** - Analyze sample texts through three lenses:\n",
    "   - Implied Author: Sensibility and stance\n",
    "   - Decision Patterns: Compositional choices\n",
    "   - Functional Texture: How surface features serve purpose\n",
    "\n",
    "2. **Stage 2: Cross-Text Synthesis** - Synthesize each dimension across multiple samples to identify stable patterns\n",
    "\n",
    "3. **Stage 3: Field Guide Construction** - Integrate all three syntheses into unified recognition criteria and density rubric\n",
    "\n",
    "4. **Stage 4: Passage Evaluation** - Evaluate passages from corpus using field guide (1-5 density rating)\n",
    "\n",
    "5. **Stage 5: Example Set Construction** - Curate 3-4 high-density passages that balance density, diversity, and complementarity\n",
    "\n",
    "## Note\n",
    "\n",
    "This pipeline is author-agnostic. The Russell corpus is used as a test case, but the same approach applies to any author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm>=1.80.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.80.0)\n",
      "Requirement already satisfied: pydantic==2.7.4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (2.7.4)\n",
      "Requirement already satisfied: jinja2>=3.1.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (4.13.2)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (3.10.11)\n",
      "Requirement already satisfied: click in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (8.5.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.99.5 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: tokenizers in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (0.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jinja2>=3.1.0->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: anyio in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (3.7.1)\n",
      "Requirement already satisfied: certifi in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: sniffio in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=6.8.0->litellm>=1.80.0->-r requirements.txt (line 1)) (3.20.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (5.10.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2023.12.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (0.20.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from openai>=1.99.5->litellm>=1.80.0->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from openai>=1.99.5->litellm>=1.80.0->-r requirements.txt (line 1)) (0.9.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from openai>=1.99.5->litellm>=1.80.0->-r requirements.txt (line 1)) (4.64.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from tiktoken>=0.7.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2022.4.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from tiktoken>=0.7.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2.27.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from anyio->httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.1.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2.0.12)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (0.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from belletrist import (\n",
    "    LLM,\n",
    "    LLMConfig,\n",
    "    PromptMaker,\n",
    "    DataSampler,\n",
    "    ResultStore,\n",
    "    # Stage 1 configs\n",
    "    ImpliedAuthorConfig,\n",
    "    DecisionPatternConfig,\n",
    "    FunctionalTextureConfig,\n",
    "    # Stage 2 configs\n",
    "    ImpliedAuthorSynthesisConfig,\n",
    "    DecisionPatternSynthesisConfig,\n",
    "    TexturalSynthesisConfig,\n",
    "    # Stage 3 config\n",
    "    AuthorModelDefinitionConfig,\n",
    "    FieldGuideConstructionConfig,\n",
    "    # Stage 4 config\n",
    "    PassageEvaluationConfig,\n",
    "    # Stage 5 config\n",
    "    ExampleSetConstructionConfig,\n",
    "    # Utilities\n",
    "    extract_paragraph_windows,\n",
    "    extract_logical_sections,\n",
    "    get_full_sample_as_passage,\n",
    "    parse_passage_evaluation,\n",
    "    parse_example_set_selection,\n",
    "    validate_passage_evaluation,\n",
    "    validate_example_set_selection,\n",
    ")\n",
    "\n",
    "print(\"Dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Base Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm_config = LLMConfig(\n",
    "    #model=\"mistral/mistral-large-2411\",  # Change as needed\n",
    "    model='together_ai/moonshotai/Kimi-K2-Instruct-0905',\n",
    "    api_key=os.environ.get('TOGETHER_AI_API_KEY'),\n",
    "    temperature=0.7\n",
    ")\n",
    "llm = LLM(llm_config)\n",
    "\n",
    "# Initialize prompt maker\n",
    "prompt_maker = PromptMaker()\n",
    "\n",
    "# Initialize data sampler (Russell corpus)\n",
    "data_dir = Path(\"data/russell\")\n",
    "sampler = DataSampler(data_dir)\n",
    "\n",
    "# Initialize result store\n",
    "store = ResultStore(\"russell_author_modeling_kimi.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store.reset('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration: Select Samples for Analysis\n",
    "\n",
    "For Stages 1-3, we'll analyze 3-5 samples to extract stable cross-text patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will analyze 5 samples through Stages 1-3\n"
     ]
    }
   ],
   "source": [
    "# Select samples for Stage 1-3 analysis\n",
    "# These should be diverse, substantial passages (500-800 words recommended)\n",
    "ANALYSIS_SAMPLES = [\n",
    "    \"sample_001\",\n",
    "    \"sample_002\",\n",
    "    \"sample_003\",\n",
    "    \"sample_004\",\n",
    "    \"sample_005\",\n",
    "    # Add more as needed for richer cross-text synthesis\n",
    "]\n",
    "\n",
    "# For this demo, we'll generate samples if they don't exist\n",
    "# In production, you might use specific pre-selected samples\n",
    "NUM_SAMPLES = 5\n",
    "SAMPLE_PARAGRAPH_LENGTH = 10\n",
    "\n",
    "print(f\"Will analyze {NUM_SAMPLES} samples through Stages 1-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stage 1: Analytical Mining\n",
    "\n",
    "Run three specialized analyses on each sample:\n",
    "- **Implied Author**: What sensibility emerges from the prose?\n",
    "- **Decision Patterns**: What compositional choices are made at key junctures?\n",
    "- **Functional Texture**: How do surface features serve purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate or Load Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sample_001\n",
      "Generated sample_002\n",
      "Generated sample_003\n",
      "Generated sample_004\n",
      "Generated sample_005\n",
      "\n",
      "Sample 001 preview:\n",
      "All names of places--London, England, Europe, the Earth, the Solar\n",
      "System--similarly involve, when used, descriptions which start from some\n",
      "one or more particulars with which we are acquainted. I suspect that\n",
      "even the Universe, as considered by metaphysics, involves such a\n",
      "connexion with particulars. In logic, on the contrary, where we are\n",
      "concerned not merely with what does exist, but with whatever might or\n",
      "could exist or be, no reference to actual particulars is involved.\n",
      "\n",
      "It would seem that, when we make a statement about something only known\n",
      "by description, we often _intend_ to make our statement, not in the form\n",
      "involving the description, but about the actual thing described. That\n",
      "is to say, when we say anything about Bismarck, we should like, if we\n",
      "could, to make the judgement which Bismarck alone can make, namely,\n",
      "the judgement of which he himself is a constituent. In this we are\n",
      "necessarily defeated, since the actual Bismarck is unknown to us. But\n",
      "we know that there is an object B, called Bismarck, and that B was an\n",
      "astute diplomatist. We can thus _describe_ the proposition we should\n",
      "like to affirm, namely, 'B was an astute diplomatist', where B is the\n",
      "object which was Bismarck. If we are describing Bismarck as 'the first\n",
      "Chancellor of the German Empire', the proposition we should like to\n",
      "affirm may be described as 'the proposition asserting, concerning the\n",
      "actual object which was the first Chancellor of the German Empire, that\n",
      "this object was an astute diplomatist'. What enables us to communicate\n",
      "in spite of the varying descriptions we employ is that we know there is\n",
      "a true proposition concerning the actual Bismarck, and that however we\n",
      "may vary the description (so long as the description is correct) the\n",
      "proposition described is still the same. This proposition, which is\n",
      "described and is known to be true, is what interests us; but we are not\n",
      "acquainted with the proposition itself, and do not know it, though we\n",
      "know it is true.\n",
      "\n",
      "It will be seen that there are various stages in the removal from\n",
      "acquaintance with particulars: there is Bismarck to people who knew him;\n",
      "Bismarck to those who only know of him through history; the man with\n",
      "the iron mask; the longest-lived of men. These are progressively further\n",
      "removed from acquaintance with particulars; the first comes as near to\n",
      "acquaintance as is possible in regard to another person; in the second,\n",
      "we shall still be said to know 'who Bismarck was'; in the third, we do\n",
      "not know who was the man with the iron mask, though we can know many\n",
      "propositions about him which are not logically deducible from the fact\n",
      "that he wore an iron mask; in the fourth, finally, we know nothing\n",
      "beyond what is logically deducible from the definition of the man. There\n",
      "is a similar hierarchy in the region of universals. Many universals,\n",
      "like many particulars, are only known to us by description. But here,\n",
      "as in the case of particulars, knowledge concerning what is known by\n",
      "description is ultimately reducible to knowledge concerning what is\n",
      "known by acquaintance.\n",
      "\n",
      "The fundamental principle in the analysis of propositions containing\n",
      "descriptions is this: _Every proposition which we can understand must be\n",
      "composed wholly of constituents with which we are acquainted_.\n",
      "\n",
      "We shall not at this stage attempt to answer all the objections which\n",
      "may be urged against this fundamental principle. For the present, we\n",
      "shall merely point out that, in some way or other, it must be possible\n",
      "to meet these objections, for it is scarcely conceivable that we can\n",
      "make a judgement or entertain a supposition without knowing what it is\n",
      "that we are judging or supposing about. We must attach _some_ meaning\n",
      "to the words we use, if we are to speak significantly and not utter mere\n",
      "noise; and the meaning we attach to our words must be something with\n",
      "which we are acquainted. Thus when, for example, we make a statement\n",
      "about Julius Caesar, it is plain that Julius Caesar himself is not\n",
      "before our minds, since we are not acquainted with him. We have in mind\n",
      "some description of Julius Caesar: 'the man who was assassinated on the\n",
      "Ides of March', 'the founder of the Roman Empire', or, perhaps, merely\n",
      "'the man whose name was _Julius Caesar_'. (In this last description,\n",
      "_Julius Caesar_ is a noise or shape with which we are acquainted.)\n",
      "Thus our statement does not mean quite what it seems to mean, but means\n",
      "something involving, instead of Julius Caesar, some description of him\n",
      "which is composed wholly of particulars and universals with which we are\n",
      "acquainted.\n",
      "\n",
      "The chief importance of knowledge by description is that it enables us\n",
      "to pass beyond the limits of our private experience. In spite of the\n",
      "fact that we can only know truths which are wholly composed of terms\n",
      "which we have experienced in acquaintance, we can yet have knowledge by\n",
      "description of things which we have never experienced. In view of the\n",
      "very narrow range of our immediate experience, this result is vital, and\n",
      "until it is understood, much of our knowledge must remain mysterious and\n",
      "therefore doubtful.\n",
      "\n",
      "CHAPTER VI. ON INDUCTION\n",
      "\n",
      "In almost all our previous discussions we have been concerned in\n",
      "the attempt to get clear as to our data in the way of knowledge of\n",
      "existence. What things are there in the universe whose existence is\n",
      "known to us owing to our being acquainted with them? So far, our answer\n",
      "has been that we are acquainted with our sense-data, and, probably,\n",
      "with ourselves. These we know to exist. And past sense-data which\n",
      "are remembered are known to have existed in the past. This knowledge\n",
      "supplies our data.\n",
      "\n",
      "But if we are to be able to draw inferences from these data--if we are\n",
      "to know of the existence of matter, of other people, of the past before\n",
      "our individual memory begins, or of the future, we must know general\n",
      "principles of some kind by means of which such inferences can be drawn.\n",
      "It must be known to us that the existence of some one sort of thing, A,\n",
      "is a sign of the existence of some other sort of thing, B, either at\n",
      "the same time as A or at some earlier or later time, as, for example,\n",
      "thunder is a sign of the earlier existence of lightning. If this were\n",
      "not known to us, we could never extend our knowledge beyond the\n",
      "sphere of our private experience; and this sphere, as we have seen, is\n",
      "exceedingly limited. The question we have now to consider is whether\n",
      "such an extension is possible, and if so, how it is effected.\n",
      "\n",
      "Let us take as an illustration a matter about which none of us, in fact,\n",
      "feel the slightest doubt. We are all convinced that the sun will rise\n",
      "to-morrow. Why? Is this belief a mere blind outcome of past experience,\n",
      "or can it be justified as a reasonable belief? It is not easy to find\n",
      "a test by which to judge whether a belief of this kind is reasonable or\n",
      "not, but we can at least ascertain what sort of general beliefs would\n",
      "suffice, if true, to justify the judgement that the sun will rise\n",
      "to-morrow, and the many other similar judgements upon which our actions\n",
      "are based....\n"
     ]
    }
   ],
   "source": [
    "# Generate samples if they don't exist\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    \n",
    "    # Skip if already saved\n",
    "    if store.get_sample(sample_id):\n",
    "        print(f\"✓ {sample_id} already gathered\")\n",
    "        continue\n",
    "        \n",
    "    # Generate new sample\n",
    "    segment = sampler.sample_segment(p_length=SAMPLE_PARAGRAPH_LENGTH)\n",
    "    store.save_segment(sample_id, segment)\n",
    "    print(f\"Generated {sample_id}\")\n",
    "\n",
    "# Display first sample for reference\n",
    "sample = store.get_sample(\"sample_001\")\n",
    "print(f\"\\nSample 001 preview:\\n{sample['text']}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Stage 1A: Implied Author Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_001: Running implied_author analysis...\n",
      "sample_001: implied_author analysis complete\n",
      "sample_002: Running implied_author analysis...\n",
      "sample_002: implied_author analysis complete\n",
      "sample_003: Running implied_author analysis...\n",
      "sample_003: implied_author analysis complete\n",
      "sample_004: Running implied_author analysis...\n",
      "sample_004: implied_author analysis complete\n",
      "sample_005: Running implied_author analysis...\n",
      "sample_005: implied_author analysis complete\n",
      "\n",
      "Stage 1A complete: All samples analyzed for implied author\n"
     ]
    }
   ],
   "source": [
    "# Analyze each sample for implied author\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    analyst_name = ImpliedAuthorConfig.analyst_name()\n",
    "    \n",
    "    # Check if analysis already exists (resume support)\n",
    "    if store.get_analysis(sample_id, analyst_name):\n",
    "        print(f\"{sample_id}: {analyst_name} analysis already complete\")\n",
    "        continue\n",
    "    \n",
    "    # Get sample text\n",
    "    sample = store.get_sample(sample_id)\n",
    "    \n",
    "    # Generate prompt\n",
    "    config = ImpliedAuthorConfig(text=sample['text'])\n",
    "    prompt = prompt_maker.render(config)\n",
    "    \n",
    "    # Run LLM\n",
    "    print(f\"{sample_id}: Running {analyst_name} analysis...\")\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    # Save analysis\n",
    "    store.save_analysis(\n",
    "        sample_id=sample_id,\n",
    "        analyst=analyst_name,\n",
    "        output=response.content,\n",
    "        model=response.model\n",
    "    )\n",
    "    print(f\"{sample_id}: {analyst_name} analysis complete\")\n",
    "\n",
    "print(\"\\nStage 1A complete: All samples analyzed for implied author\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Stage 1B: Decision Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_001: Running decision_pattern analysis...\n",
      "sample_001: decision_pattern analysis complete\n",
      "sample_002: Running decision_pattern analysis...\n",
      "sample_002: decision_pattern analysis complete\n",
      "sample_003: Running decision_pattern analysis...\n",
      "sample_003: decision_pattern analysis complete\n",
      "sample_004: Running decision_pattern analysis...\n",
      "sample_004: decision_pattern analysis complete\n",
      "sample_005: Running decision_pattern analysis...\n",
      "sample_005: decision_pattern analysis complete\n",
      "\n",
      "Stage 1B complete: All samples analyzed for decision patterns\n"
     ]
    }
   ],
   "source": [
    "# Analyze each sample for decision patterns\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    analyst_name = DecisionPatternConfig.analyst_name()\n",
    "    \n",
    "    if store.get_analysis(sample_id, analyst_name):\n",
    "        print(f\"{sample_id}: {analyst_name} analysis already complete\")\n",
    "        continue\n",
    "    \n",
    "    sample = store.get_sample(sample_id)\n",
    "    config = DecisionPatternConfig(text=sample['text'])\n",
    "    prompt = prompt_maker.render(config)\n",
    "    \n",
    "    print(f\"{sample_id}: Running {analyst_name} analysis...\")\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    store.save_analysis(\n",
    "        sample_id=sample_id,\n",
    "        analyst=analyst_name,\n",
    "        output=response.content,\n",
    "        model=response.model\n",
    "    )\n",
    "    print(f\"{sample_id}: {analyst_name} analysis complete\")\n",
    "\n",
    "print(\"\\nStage 1B complete: All samples analyzed for decision patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Stage 1C: Functional Texture Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_001: Running functional_texture analysis...\n",
      "sample_001: functional_texture analysis complete\n",
      "sample_002: Running functional_texture analysis...\n",
      "sample_002: functional_texture analysis complete\n",
      "sample_003: Running functional_texture analysis...\n",
      "sample_003: functional_texture analysis complete\n",
      "sample_004: Running functional_texture analysis...\n",
      "sample_004: functional_texture analysis complete\n",
      "sample_005: Running functional_texture analysis...\n",
      "sample_005: functional_texture analysis complete\n",
      "\n",
      "Stage 1C complete: All samples analyzed for functional texture\n"
     ]
    }
   ],
   "source": [
    "# Analyze each sample for functional texture\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    analyst_name = FunctionalTextureConfig.analyst_name()\n",
    "    \n",
    "    if store.get_analysis(sample_id, analyst_name):\n",
    "        print(f\"{sample_id}: {analyst_name} analysis already complete\")\n",
    "        continue\n",
    "    \n",
    "    sample = store.get_sample(sample_id)\n",
    "    config = FunctionalTextureConfig(text=sample['text'])\n",
    "    prompt = prompt_maker.render(config)\n",
    "    \n",
    "    print(f\"{sample_id}: Running {analyst_name} analysis...\")\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    store.save_analysis(\n",
    "        sample_id=sample_id,\n",
    "        analyst=analyst_name,\n",
    "        output=response.content,\n",
    "        model=response.model\n",
    "    )\n",
    "    print(f\"{sample_id}: {analyst_name} analysis complete\")\n",
    "\n",
    "print(\"\\nStage 1C complete: All samples analyzed for functional texture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Stage 1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_001: 3 analyses complete\n",
      "  - decision_pattern\n",
      "  - functional_texture\n",
      "  - implied_author\n",
      "sample_002: 3 analyses complete\n",
      "  - decision_pattern\n",
      "  - functional_texture\n",
      "  - implied_author\n",
      "sample_003: 3 analyses complete\n",
      "  - decision_pattern\n",
      "  - functional_texture\n",
      "  - implied_author\n",
      "sample_004: 3 analyses complete\n",
      "  - decision_pattern\n",
      "  - functional_texture\n",
      "  - implied_author\n",
      "sample_005: 3 analyses complete\n",
      "  - decision_pattern\n",
      "  - functional_texture\n",
      "  - implied_author\n",
      "\n",
      "--- Sample Implied Author Analysis (first 500 chars) ---\n",
      "Total chars: 6688\n",
      "PART 1: DIMENSIONAL ANALYSIS\n",
      "\n",
      "1. RELATIONSHIP TO MATERIAL  \n",
      "Observation: The writer treats the subject as something still in motion, holding it at arm’s length to watch it change shape.  They neither celebrate nor mourn; they test possibilities, keep score of counter-possibilities, and allow the picture to stay porous.\n",
      "\n",
      "Evidence  \n",
      "a) “There are signs that the paralysis is merely temporary.”  \n",
      "   – The clause “there are signs” keeps the verdict conditional; the writer reports symptoms, not fate.  \n",
      "\n",
      "b) “One might hope that this would not prove to be so in Russia … were it not that one discovers with a certain misgiving …”  \n",
      "   – The hypothetical “one might hope” is immediately checked by “were it not,” a syntactic see-saw that keeps the material open.\n",
      "\n",
      "c) “It may be that the machine will ultimately conquer the Communist faith … One would like to hope … But the practical difficulties are almost insuperable.”  \n",
      "   – Three successive hedges (“may be,” “would like to hope,” “almost insuperable”) show the writer suspending judgment above an unresolved process.\n",
      "\n",
      "These moments reveal a mind that refuses to arrest the phenomenon; it prefers to keep the future in the subjunctive mood.\n",
      "\n",
      "2. RELATIONSHIP TO READER  \n",
      "Observation: The implied reader is a traveling companion who can be trusted to look at the same concrete instances, enjoy a dry aside, and accept occasional Latin tags without footnotes.  The tone is conversational-academic: intimate enough for “I think,” roomy enough for historical parallels.\n",
      "\n",
      "Evidence  \n",
      "a) “I think that this movement towards the Church tradition may be unconscious …”  \n",
      "   – The “I think” invites the reader into a speculation rather than issuing a decree.  \n",
      "\n",
      "b) “Compare the modern motor car with the first of its species …”  \n",
      "   – An imperative directed at an imagined co-observer; the writer assumes the reader is willing to perform the comparison.  \n",
      "\n",
      "c) “I had the good fortune to witness one of each kind.”  \n",
      "   – The personal aside positions the reader as someone who will enjoy the anecdote without envy or suspicion.\n",
      "\n",
      "The prose never pauses to define “Entente,” “Rodin,” or “hipparion,” presuming a shared cultural pocket.\n",
      "\n",
      "3. RELATIONSHIP TO UNCERTAINTY  \n",
      "Observation: Certainty is rationed.  Large historical laws (“Industry is a new tool …”) are asserted, but whenever the argument approaches Russia’s near future it is cushioned in modality: “may,” “might,” “perhaps,” “one would like to hope.”\n",
      "\n",
      "Evidence  \n",
      "a) “Whether the flowering period will be long or short depends … chiefly on the rapidity of industrial development.”  \n",
      "   – The causal link is proposed, then left to the variable “rapidity,” openly named as unknown.  \n",
      "\n",
      "b) “Hence not only does it appear that the number of artists will grow less, but … is likely to be deplorably small.”  \n",
      "   – Double softener: “appear” and “likely” stack the probabilistic layers.  \n",
      "\n",
      "c) “Such at least is the reflection engendered by an inspection …”  \n",
      "   – The entire preceding paragraph is downgraded to “reflection,” a self-conscious shrinking of authority.\n",
      "\n",
      "The writer is most unqualified only when diagnosing the past or the very longue durée; the nearer the forecast, the thicker the hedges.\n",
      "\n",
      "4. RELATIONSHIP TO THE ACT OF WRITING  \n",
      "Observation: The prose visibly enjoys its own capacity for brisk analogy and quiet irony.  It will risk a Latinized label (“in the subjunctive mood” of history) or a sly poke at “grandiose bad Rodin statuary,” but it never lingers for applause.\n",
      "\n",
      "Evidence  \n",
      "a) “Lenin and Trotsky already figure in woodcuts as Moses and Aaron …”  \n",
      "   – The biblical echo is held just long enough for the reader to see the comic elevation.  \n",
      "\n",
      "b) “the rasping arid temperament of those to whom the industrial machine is an end in itself”  \n",
      "   – The alliterative rasp of “rasping arid” enacts the very sound it describes.  \n",
      "\n",
      "c) “the live little wooden lady who smiles beneath the glass case … and the soulless staring-eyed creature who is offered for sale”  \n",
      "   – The juxtaposition is miniature theater, the sentence itself performing the loss of life it laments.\n",
      "\n",
      "The writer’s pleasure is in precision, not ornament; even the jokes work by exact placement rather than flourish.\n",
      "\n",
      "PART 2: SIGNATURE MOMENTS\n",
      "\n",
      "1. “Russia is only now emerging from the middle ages, and the Church tradition in painting is passing with incredible smoothness into the service of Communist doctrine.”  \n",
      "   – The historical compression (“only now emerging … incredible smoothness”) carries the author’s trademark: a coolly ironic raised eyebrow at how quickly the sacred becomes the ideological.\n",
      "\n",
      "2. “One might hope … were it not that one discovers with a certain misgiving … the rasping arid temperament …”  \n",
      "   – The pivot from hope to misgiving in a single breath typifies the author’s habit of thinking in counter-weighted clauses, always reserving a seat for doubt.\n",
      "\n",
      "3. “Compare the modern motor car with the first of its species, or even … the prehistoric animal with its modern descendant … man carries it forward in the articles that he makes …”  \n",
      "   – The sweeping evolutionary analogy, delivered without swagger, shows the writer’s confidence in long-range pattern-making—the place where certainty is allowed.\n",
      "\n",
      "4. “the live little wooden lady … and the soulless staring-eyed creature …”  \n",
      "   – The miniature morality play enacted by two carved dolls condenses the author’s affection for concrete objects that betray larger historical forces.\n",
      "\n",
      "5. “the old father, constantly drunk on vodka, alternately maudlin and scolding … the comic character was Satan.”  \n",
      "   – The quick cinematic sketch plus the medieval echo lets us overhear the author’s private delight in seeing history repeat its staging conventions.\n",
      "\n",
      "PART 3: SYNTHETIC PORTRAIT\n",
      "\n",
      "The implied author is a traveler who keeps a pocket notebook instead of a banner.  Skeptical of dogma yet susceptible to craftsmanship, they move through factories, museums, and village pageants, pausing to note how the sacred icon becomes the propaganda poster, how the carved toy loses its smile once tradition is copied instead of inherited.  They address an equal who can be trusted with irony and with Latin tags, never bullying, never confessional.  Historical law is granted, present turbulence is watched with a cool eye, and the future is entertained only in the conditional mood.  The sentences balance hope against misgiving in almost musical counter-point; wit flashes but does not linger.  This is a mind that trusts the evidence of carved wood and amateur theater more than manifestos, that measures revolution by the small change in everyday objects, and that writes to keep the picture open long after the reader would like it closed.\n"
     ]
    }
   ],
   "source": [
    "# Display completion status\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    sample, analyses = store.get_sample_with_analyses(sample_id)\n",
    "    print(f\"{sample_id}: {len(analyses)} analyses complete\")\n",
    "    for analyst_name in analyses.keys():\n",
    "        print(f\"  - {analyst_name}\")\n",
    "\n",
    "# Optionally display one analysis\n",
    "print(\"\\n--- Sample Implied Author Analysis (first 500 chars) ---\")\n",
    "sample, analyses = store.get_sample_with_analyses(\"sample_005\")\n",
    "implied_author = analyses.get(ImpliedAuthorConfig.analyst_name(), \"Not found\")\n",
    "print(f\"Total chars: {len(implied_author)}\")\n",
    "print(implied_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stage 2: Cross-Text Synthesis\n",
    "\n",
    "Synthesize each analytical dimension across samples to identify stable patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2A: Implied Author Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running implied author synthesis...\n",
      "Synthesis saved: implied_author_synthesis_001\n",
      "\n",
      "Preview (first 400 chars):\n",
      "### PART 1: THE STABLE CORE  \n",
      "\n",
      "**Fundamental Stance Toward Ideas and Inquiry**  \n",
      "Across every text, the author treats knowledge as something that must be *shown being assembled*, not delivered pre-packaged. Whether the topic is sense-data, relativity, belief, education, or Russian art, the writer begins with the reader’s ordinary certainties, then slowly loosens the screws. The method is consisten...\n"
     ]
    }
   ],
   "source": [
    "# Collect all implied author analyses\n",
    "implied_author_analyses = {}\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    analysis = store.get_analysis(sample_id, ImpliedAuthorConfig.analyst_name())\n",
    "    if analysis:\n",
    "        implied_author_analyses[sample_id] = analysis\n",
    "\n",
    "# Check if synthesis already exists\n",
    "synthesis_type = ImpliedAuthorSynthesisConfig.synthesis_type()\n",
    "existing = store.list_syntheses(synthesis_type)\n",
    "\n",
    "if existing:\n",
    "    print(f\"Implied author synthesis already exists: {existing[0]}\")\n",
    "    implied_author_synthesis_id = existing[0]\n",
    "else:\n",
    "    # Generate synthesis prompt\n",
    "    config = ImpliedAuthorSynthesisConfig(\n",
    "        implied_author_analyses=implied_author_analyses\n",
    "    )\n",
    "    prompt = prompt_maker.render(config)\n",
    "    \n",
    "    # Run synthesis\n",
    "    print(\"Running implied author synthesis...\")\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    # Save synthesis\n",
    "    sample_contributions = [\n",
    "        (sample_id, ImpliedAuthorConfig.analyst_name())\n",
    "        for sample_id in implied_author_analyses.keys()\n",
    "    ]\n",
    "    \n",
    "    implied_author_synthesis_id = store.save_synthesis(\n",
    "        synthesis_type=synthesis_type,\n",
    "        output=response.content,\n",
    "        model=response.model,\n",
    "        sample_contributions=sample_contributions,\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"Synthesis saved: {implied_author_synthesis_id}\")\n",
    "\n",
    "# Display preview\n",
    "synth = store.get_synthesis(implied_author_synthesis_id)\n",
    "print(f\"\\nPreview (first 400 chars):\\n{synth['output'][:400]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2B: Decision Pattern Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running decision pattern synthesis...\n",
      "Synthesis saved: decision_pattern_synthesis_001\n",
      "\n",
      "Preview (first 400 chars):\n",
      "### PART 1: COMPOSITIONAL PROBLEM TAXONOMY\n",
      "\n",
      "1. **Opening Complex Abstract Claims** – How to begin discussions of dense philosophical or theoretical concepts without losing the reader immediately  \n",
      "2. **Bridging Concrete ↔ Abstract** – Moving between everyday experience and abstract principle without creating a jarring leap  \n",
      "3. **Staging Reader Resistance** – Anticipating and incorporating the rea...\n"
     ]
    }
   ],
   "source": [
    "# Collect all decision pattern analyses\n",
    "decision_pattern_analyses = {}\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    analysis = store.get_analysis(sample_id, DecisionPatternConfig.analyst_name())\n",
    "    if analysis:\n",
    "        decision_pattern_analyses[sample_id] = analysis\n",
    "\n",
    "# Check if synthesis already exists\n",
    "synthesis_type = DecisionPatternSynthesisConfig.synthesis_type()\n",
    "existing = store.list_syntheses(synthesis_type)\n",
    "\n",
    "if existing:\n",
    "    print(f\"Decision pattern synthesis already exists: {existing[0]}\")\n",
    "    decision_pattern_synthesis_id = existing[0]\n",
    "else:\n",
    "    config = DecisionPatternSynthesisConfig(\n",
    "        decision_pattern_analyses=decision_pattern_analyses\n",
    "    )\n",
    "    prompt = prompt_maker.render(config)\n",
    "    \n",
    "    print(\"Running decision pattern synthesis...\")\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    sample_contributions = [\n",
    "        (sample_id, DecisionPatternConfig.analyst_name())\n",
    "        for sample_id in decision_pattern_analyses.keys()\n",
    "    ]\n",
    "    \n",
    "    decision_pattern_synthesis_id = store.save_synthesis(\n",
    "        synthesis_type=synthesis_type,\n",
    "        output=response.content,\n",
    "        model=response.model,\n",
    "        sample_contributions=sample_contributions,\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"Synthesis saved: {decision_pattern_synthesis_id}\")\n",
    "\n",
    "synth = store.get_synthesis(decision_pattern_synthesis_id)\n",
    "print(f\"\\nPreview (first 400 chars):\\n{synth['output'][:400]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2C: Textural Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running textural synthesis...\n",
      "Synthesis saved: textural_synthesis_001\n",
      "\n",
      "Preview (first 400 chars):\n",
      "# PART 1: SENTENCE ARCHITECTURE\n",
      "\n",
      "This author's sentences feel like a hand reaching forward while the mind keeps catching the sleeve to add one more reservation. The characteristic shape is **back-loaded complexity**: a short, steady main clause arrives early, then a tail of qualifications, parenthetical hedges, and illustrative riders accumulates, each appendix testing whether the first statement ...\n"
     ]
    }
   ],
   "source": [
    "# Collect all functional texture analyses\n",
    "textural_analyses = {}\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample_id = f\"sample_{i+1:03d}\"\n",
    "    analysis = store.get_analysis(sample_id, FunctionalTextureConfig.analyst_name())\n",
    "    if analysis:\n",
    "        textural_analyses[sample_id] = analysis\n",
    "\n",
    "# Check if synthesis already exists\n",
    "synthesis_type = TexturalSynthesisConfig.synthesis_type()\n",
    "existing = store.list_syntheses(synthesis_type)\n",
    "\n",
    "if existing:\n",
    "    print(f\"Textural synthesis already exists: {existing[0]}\")\n",
    "    textural_synthesis_id = existing[0]\n",
    "else:\n",
    "    config = TexturalSynthesisConfig(\n",
    "        textural_analyses=textural_analyses\n",
    "    )\n",
    "    prompt = prompt_maker.render(config)\n",
    "    \n",
    "    print(\"Running textural synthesis...\")\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    sample_contributions = [\n",
    "        (sample_id, FunctionalTextureConfig.analyst_name())\n",
    "        for sample_id in textural_analyses.keys()\n",
    "    ]\n",
    "    \n",
    "    textural_synthesis_id = store.save_synthesis(\n",
    "        synthesis_type=synthesis_type,\n",
    "        output=response.content,\n",
    "        model=response.model,\n",
    "        sample_contributions=sample_contributions,\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"Synthesis saved: {textural_synthesis_id}\")\n",
    "\n",
    "synth = store.get_synthesis(textural_synthesis_id)\n",
    "print(f\"\\nPreview (first 400 chars):\\n{synth['output'][:400]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing author model definition...\n",
      "Author model definition saved: author_model_definition_001\n",
      "\n",
      "Total chars of Author Model: 8799\n",
      "\n",
      "Author Model Preview (first 800 chars):\n",
      "# AUTHOR MIND MODEL: BERTRAND RUSSELL  \n",
      "*(for LLM inhabitation)*\n",
      "\n",
      "---\n",
      "\n",
      "## PART 1: THE GENERATIVE STANCE  \n",
      "*(≈480 words, second-person)*\n",
      "\n",
      "You sit down to write convinced that the reader already possesses every tool needed to follow you—only the *order* of the tools is wrong. Your job is not to add new apparatus but to unscrew the hinges and lay them on the table so the mechanism can be watched in motion. You therefore begin with what “we all” grant: the sun will rise, the train is late, the child builds a sand-pie. These are not concessions to simplicity; they are the immovable fulcrums on which you will lever the whole world of abstraction. You *trust* the concrete moment more than the grand theory, because a theory can hide its cracks while a tiger in the street forces the reader’s body t...\n",
      "\n",
      "Author model exported to: outputs/author_modeling/author_model_definition_001.txt\n"
     ]
    }
   ],
   "source": [
    "implied_synth = store.get_synthesis(implied_author_synthesis_id)\n",
    "decision_synth = store.get_synthesis(decision_pattern_synthesis_id)\n",
    "textural_synth = store.get_synthesis(textural_synthesis_id)\n",
    "\n",
    "# Check if author model definition already exists\n",
    "synthesis_type = AuthorModelDefinitionConfig.synthesis_type()\n",
    "existing = store.list_syntheses(synthesis_type)\n",
    "\n",
    "if existing:\n",
    "    print(f\"Author model definition already exists: {existing[0]}\")\n",
    "    author_model_id = existing[0]\n",
    "else:\n",
    "    # Generate author model definition\n",
    "    config = AuthorModelDefinitionConfig(\n",
    "        implied_author_synthesis=implied_synth['output'],\n",
    "        decision_pattern_synthesis=decision_synth['output'],\n",
    "        textural_synthesis=textural_synth['output']\n",
    "    )\n",
    "    prompt = prompt_maker.render(config)\n",
    "\n",
    "    print(\"Constructing author model definition...\")\n",
    "    response = llm.complete(prompt)\n",
    "\n",
    "    # Save with parent linkage (no direct sample contributions)\n",
    "    author_model_id = store.save_synthesis(\n",
    "        synthesis_type=synthesis_type,\n",
    "        output=response.content,\n",
    "        model=response.model,\n",
    "        sample_contributions=[],  # Inherits from parents\n",
    "        config=config,\n",
    "        parent_synthesis_id=implied_author_synthesis_id  # Link to one parent\n",
    "    )\n",
    "    print(f\"Author model definition saved: {author_model_id}\")\n",
    "\n",
    "# Display preview\n",
    "author_model = store.get_synthesis(author_model_id)\n",
    "print(f\"\\nTotal chars of Author Model: {len(author_model['output'])}\")\n",
    "print(f\"\\nAuthor Model Preview (first 800 chars):\\n{author_model['output'][:800]}...\")\n",
    "\n",
    "# Export to filesystem for use in generation\n",
    "output_dir = Path(\"outputs/author_modeling\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "author_model_path = output_dir / f\"{author_model_id}.txt\"\n",
    "store.export_synthesis(\n",
    "    synthesis_id=author_model_id,\n",
    "    output_path=author_model_path,\n",
    "    metadata_format='yaml'\n",
    ")\n",
    "print(f\"\\nAuthor model exported to: {author_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (russell_writes)",
   "language": "python",
   "name": "russell_writes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
