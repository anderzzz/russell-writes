{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Instruction Evaluation Framework\n",
    "\n",
    "This notebook evaluates how well derived style instructions enable style replication, compared to alternative approaches.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "For each gold standard text:\n",
    "1. **Flatten**: Extract content while removing style\n",
    "2. **Reconstruct**: Generate text using 4 different methods (M stochastic runs each):\n",
    "   - Generic baseline\n",
    "   - Few-shot learning\n",
    "   - Author name prompting\n",
    "   - Derived style instructions\n",
    "3. **Judge (Blind Comparative)**: Judge ranks all 4 reconstructions from 1-4 based on similarity to original\n",
    "   - **Blind evaluation**: Judge sees only anonymous labels (Text A, B, C, D) - no method names\n",
    "   - **Ranking**: 1 = most similar, 2 = second, 3 = third, 4 = least similar\n",
    "   - **Order randomized**: Position of methods varies across samples to eliminate bias\n",
    "4. **Aggregate**: Analyze rankings to determine which method best captures style\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Crash resilient**: All LLM responses saved to SQLite immediately\n",
    "- **Resume support**: Can restart after failures, skips completed work\n",
    "- **Blind evaluation**: Eliminates judge bias by hiding method names\n",
    "- **Comparative ranking**: More informative than binary comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries and Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm>=1.80.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.80.7)\n",
      "Requirement already satisfied: pydantic==2.7.4 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.7.4)\n",
      "Requirement already satisfied: jinja2>=3.1.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (3.13.2)\n",
      "Requirement already satisfied: click in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (8.3.1)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: grpcio<1.68.0,>=1.62.3 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (1.67.1)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (8.7.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (4.25.1)\n",
      "Requirement already satisfied: openai>=2.8.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from litellm>=1.80.0->-r requirements.txt (line 1)) (0.22.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from jinja2>=3.1.0->-r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.80.0->-r requirements.txt (line 1)) (1.22.0)\n",
      "Requirement already satisfied: anyio in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.80.0->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm>=1.80.0->-r requirements.txt (line 1)) (3.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.80.0->-r requirements.txt (line 1)) (0.30.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from openai>=2.8.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from openai>=2.8.0->litellm>=1.80.0->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from openai>=2.8.0->litellm>=1.80.0->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from openai>=2.8.0->litellm>=1.80.0->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from tokenizers->litellm>=1.80.0->-r requirements.txt (line 1)) (1.1.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.80.0->-r requirements.txt (line 1)) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.80.0->-r requirements.txt (line 1)) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.80.0->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.80.0->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.80.0->-r requirements.txt (line 1)) (6.0.3)\n",
      "Requirement already satisfied: shellingham in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.80.0->-r requirements.txt (line 1)) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.80.0->-r requirements.txt (line 1)) (0.20.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.80.0->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/andersohrn/PycharmProjects/personal_github_website/venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.80.0->-r requirements.txt (line 1)) (2.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providers\n",
      "=========\n",
      "* openai\n",
      "* openai_like\n",
      "* bytez\n",
      "* xai\n",
      "* custom_openai\n",
      "* text-completion-openai\n",
      "* cohere\n",
      "* cohere_chat\n",
      "* clarifai\n",
      "* anthropic\n",
      "* anthropic_text\n",
      "* replicate\n",
      "* huggingface\n",
      "* together_ai\n",
      "* datarobot\n",
      "* openrouter\n",
      "* cometapi\n",
      "* vertex_ai\n",
      "* vertex_ai_beta\n",
      "* gemini\n",
      "* ai21\n",
      "* baseten\n",
      "* azure\n",
      "* azure_text\n",
      "* azure_ai\n",
      "* sagemaker\n",
      "* sagemaker_chat\n",
      "* bedrock\n",
      "* vllm\n",
      "* nlp_cloud\n",
      "* petals\n",
      "* oobabooga\n",
      "* ollama\n",
      "* ollama_chat\n",
      "* deepinfra\n",
      "* perplexity\n",
      "* mistral\n",
      "* groq\n",
      "* nvidia_nim\n",
      "* cerebras\n",
      "* baseten\n",
      "* ai21_chat\n",
      "* volcengine\n",
      "* codestral\n",
      "* text-completion-codestral\n",
      "* deepseek\n",
      "* sambanova\n",
      "* maritalk\n",
      "* cloudflare\n",
      "* fireworks_ai\n",
      "* friendliai\n",
      "* watsonx\n",
      "* watsonx_text\n",
      "* triton\n",
      "* predibase\n",
      "* databricks\n",
      "* empower\n",
      "* github\n",
      "* custom\n",
      "* litellm_proxy\n",
      "* hosted_vllm\n",
      "* llamafile\n",
      "* lm_studio\n",
      "* galadriel\n",
      "* gradient_ai\n",
      "* github_copilot\n",
      "* novita\n",
      "* meta_llama\n",
      "* featherless_ai\n",
      "* nscale\n",
      "* nebius\n",
      "* dashscope\n",
      "* moonshot\n",
      "* v0\n",
      "* heroku\n",
      "* oci\n",
      "* morph\n",
      "* lambda_ai\n",
      "* vercel_ai_gateway\n",
      "* wandb\n",
      "* ovhcloud\n",
      "* lemonade\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import litellm\n",
    "    print('Providers\\n=========')\n",
    "    print('* ' + '\\n* '.join(litellm.LITELLM_CHAT_PROVIDERS))\n",
    "    litellm.drop_params = True\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Cannot import litellm: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Base Objects\n",
    "The base objects part of the current project library (`belletrist`) are initialized. They are:\n",
    "* `LLM`: the LLM object.\n",
    "* `LLMConfig`: the configuration of the LLM object, such as what model to use.\n",
    "* `PromptMaker`: generates prompts from templates and variables\n",
    "* `DataSampler`: retrieves and samples text at a source directory\n",
    "\n",
    "These will implement text transformations by LLMs part of the evaluation process. They build on the third-party LLMs, which we furthermore split into LLMs for text reconstruction and text judging, the key parameters for which are set below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_reconstruction_string = 'together_ai/Qwen/Qwen3-235B-A22B-Instruct-2507-tput'\n",
    "#model_reconstruction_api_key_env_var = 'TOGETHER_AI_API_KEY'\n",
    "#model_reconstruction_string = 'anthropic/claude-sonnet-4-5-20250929'\n",
    "#model_reconstruction_api_key_env_var = 'ANTHROPIC_API_KEY'\n",
    "#model_reconstruction_string = 'openai/gpt-5.1-2025-11-13'\n",
    "#model_reconstruction_api_key_env_var = 'OPENAI_API_KEY'\n",
    "#model_reconstruction_string = 'together_ai/moonshotai/Kimi-K2-Instruct'\n",
    "#model_reconstruction_api_key_env_var = 'TOGETHER_AI_API_KEY'\n",
    "model_reconstruction_string = 'mistral/mistral-large-2512'\n",
    "model_reconstruction_api_key_env_var = 'MISTRAL_API_KEY'\n",
    "model_judge_string = 'anthropic/claude-sonnet-4-5-20250929'\n",
    "model_judge_api_key_env_var = 'ANTHROPIC_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from belletrist import PromptMaker, DataSampler, StyleEvaluationStore\n",
    "\n",
    "prompt_maker = PromptMaker()\n",
    "sampler = DataSampler(\n",
    "    data_path=(Path(os.getcwd()) / \"data\" / \"russell\").resolve()\n",
    ")\n",
    "store = StyleEvaluationStore(Path(\"style_evaluation_results_author_sonnet_write_mistral_judge_sonnet.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.reset('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from belletrist import LLM, LLMConfig\n",
    "\n",
    "reconstruction_llm = LLM(LLMConfig(\n",
    "    model=model_reconstruction_string,\n",
    "    api_key=os.environ.get(model_reconstruction_api_key_env_var)\n",
    "))\n",
    "judge_llm = LLM(LLMConfig(\n",
    "    model=model_judge_string,\n",
    "    api_key=os.environ.get(model_judge_api_key_env_var)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Test Data and Few-Shot Data\n",
    "The reconstruction method tests build on gold standard texts. The test also includes few-shot prompting with the gold standard texts. In order to not skew the tests, no few-shot examples can overlap with the test texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 5\n",
    "m_paragraphs_per_sample = 5\n",
    "n_few_shot_sample = 5\n",
    "\n",
    "test_texts = []\n",
    "for _ in range(n_sample):\n",
    "    test_texts.append(sampler.sample_segment(p_length=m_paragraphs_per_sample))\n",
    "\n",
    "few_shot_texts = []\n",
    "while len(few_shot_texts) < n_few_shot_sample:\n",
    "    p = sampler.sample_segment(p_length=m_paragraphs_per_sample)\n",
    "\n",
    "    # Check if p overlaps with any test text\n",
    "    # Two segments overlap if they're from the same file AND their paragraph ranges overlap\n",
    "    # Ranges [a, b) and [c, d) overlap if: a < d AND c < b\n",
    "    has_overlap = any(\n",
    "        p.file_index == test_seg.file_index and\n",
    "        p.paragraph_start < test_seg.paragraph_end and\n",
    "        test_seg.paragraph_start < p.paragraph_end\n",
    "        for test_seg in test_texts\n",
    "    )\n",
    "\n",
    "    if not has_overlap:\n",
    "        few_shot_texts.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Test Transformation Objects\n",
    "The combination of prompt and LLM leads to the following operators in the test chain:\n",
    "* **Style Flattener**, which given a text compresses it into its content bare bones.\n",
    "* **Reconstructor, LLM House Style**, which given a compressed content expands it into a complete text with the \"house style\" of the LLM employed for the reconstruction.\n",
    "* **Reconstructor, Few Shot**, which given a compressed content expands it into a complete text with a few text excerpts on unrelated topics as style guide.\n",
    "* **Reconstructor, LLM Author Model**, which given a compressed content expands it into a complete text with the named author's style as the LLM conceives it without any other guidance.\n",
    "* **Reconstructor, Style Instruction**, which given a compressed content expands it into a complete text following the detailed style instruction, as derived from previous analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded style instructions (20519 chars)\n",
      "\n",
      "First 200 chars:\n",
      "---\n",
      "synthesis_id: author_model_definition_001\n",
      "synthesis_type: author_model_definition\n",
      "model: claude-sonnet-4-5-20250929\n",
      "created_at: 2025-12-02T12:29:47.382030\n",
      "parent_synthesis_id: implied_author_synthesis_001\n",
      "num_samples: 5\n",
      "sample_ids:\n",
      "  - sample_005\n",
      "  - sample_003\n",
      "  - sample_002\n",
      "  - sample_004\n",
      "  - sample_001\n",
      "is_homogeneous_model: true\n",
      "models_used:\n",
      "  - claude-sonnet-4-5-20250929\n",
      "---\n",
      "\n",
      "## PART 1: THE GENERATIVE STANCE\n",
      "\n",
      "When you write as this author, you inhabit a position of **clarity achieved and...\n"
     ]
    }
   ],
   "source": [
    "style_instructions_path = Path(\"outputs/author_modeling/author_model_definition_001_sonnet.txt\")\n",
    "\n",
    "if style_instructions_path.exists():\n",
    "    style_instructions = style_instructions_path.read_text()\n",
    "    print(f\"✓ Loaded style instructions ({len(style_instructions)} chars)\")\n",
    "    print(f\"\\nFirst 200 chars:\\n{style_instructions[:500]}...\")\n",
    "else:\n",
    "    print(\"⚠ Style instructions file not found. Please provide path.\")\n",
    "    style_instructions = \"\"  # Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Store initialized at style_evaluation_results_author_sonnet_write_mistral_judge_sonnet.db\n",
      "✓ Configuration: 3 runs per sample, 4 reconstruction methods\n"
     ]
    }
   ],
   "source": [
    "from belletrist.models import (\n",
    "    StyleFlatteningConfig,\n",
    "    StyleReconstructionGenericConfig,\n",
    "    StyleReconstructionFewShotConfig,\n",
    "    StyleReconstructionAuthorConfig,\n",
    "    StyleReconstructionInstructionsConfig,\n",
    "    MethodMapping,\n",
    "    StyleJudgeComparativeConfig\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "n_runs = 3\n",
    "AUTHOR_NAME = \"Bertrand Russell\"\n",
    "\n",
    "# Reconstructor configs\n",
    "RECONSTRUCTORS_CFGS = {\n",
    "    'generic': StyleReconstructionGenericConfig,\n",
    "    'fewshot': StyleReconstructionFewShotConfig,\n",
    "    'author': StyleReconstructionAuthorConfig,\n",
    "    'instructions': StyleReconstructionInstructionsConfig\n",
    "}\n",
    "\n",
    "# Reconstructor kwargs\n",
    "RECONSTRUCTORS_KWARGS = {\n",
    "    'generic': {},\n",
    "    'fewshot': {'few_shot_examples': [seg.text for seg in few_shot_texts]},\n",
    "    'author': {'author_name': AUTHOR_NAME},\n",
    "    'instructions': {'style_instructions': style_instructions}\n",
    "}\n",
    "\n",
    "print(f\"✓ Store initialized at {store.filepath}\")\n",
    "print(f\"✓ Configuration: {n_runs} runs per sample, 4 reconstruction methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Content Flattening\n",
    "\n",
    "Extract content from each test sample, removing stylistic elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: Flattening and Saving Samples ===\n",
      "\n",
      "Flattening sample_000... ✓ (4941 chars)\n",
      "Flattening sample_001... ✓ (8205 chars)\n",
      "Flattening sample_002... ✓ (2483 chars)\n",
      "Flattening sample_003... ✓ (3633 chars)\n",
      "Flattening sample_004... ✓ (4892 chars)\n",
      "\n",
      "✓ All samples flattened and saved to store\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Save samples and flatten content\n",
    "print(\"=== Step 1: Flattening and Saving Samples ===\\n\")\n",
    "\n",
    "for k_text, test_sample in enumerate(test_texts):\n",
    "    sample_id = f\"sample_{k_text:03d}\"\n",
    "    \n",
    "    # Skip if already saved\n",
    "    if store.get_sample(sample_id):\n",
    "        print(f\"✓ {sample_id} already flattened (skipping)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Flattening {sample_id}...\", end=\" \")\n",
    "    \n",
    "    # Flatten content\n",
    "    flatten_prompt = prompt_maker.render(\n",
    "        StyleFlatteningConfig(text=test_sample.text)\n",
    "    )\n",
    "    flattened = reconstruction_llm.complete(flatten_prompt)\n",
    "    \n",
    "    # Save to store with provenance\n",
    "    source_info = f\"File {test_sample.file_index}, para {test_sample.paragraph_start}-{test_sample.paragraph_end}\"\n",
    "    store.save_sample(\n",
    "        sample_id=sample_id,\n",
    "        original_text=test_sample.text,\n",
    "        flattened_content=flattened.content,\n",
    "        flattening_model=flattened.model,\n",
    "        source_info=source_info\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ ({len(flattened.content)} chars)\")\n",
    "\n",
    "print(f\"\\n✓ All samples flattened and saved to store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResponse(content='### **Summary of Informational and Argumentative Content**\\n\\n#### **1. Position and Influence of the Chinese Intelligentsia**\\n- **Historical Context:**\\n  - China has lacked a hereditary aristocracy for ~2,000 years.\\n  - Governance has long been based on competitive examinations, granting the educated a prestige comparable to that of a governing aristocracy in other societies.\\n- **Current Status:**\\n  - Traditional education is declining, replaced by modern subjects.\\n  - The prestige of education persists; public opinion remains influenced by intellectuals.\\n  - Warlords (*Tuchuns*), often uneducated (e.g., former brigands like Chang-tso-lin), lack this respect, making their rule weak and unstable.\\n- **Role of \"Young China\":**\\n  - Refers to those educated abroad or in modern domestic institutions.\\n  - Their influence is disproportionately strong due to China’s historical respect for learning.\\n  - Their numbers are rapidly increasing; their outlook and goals are positive.\\n  - In ~10 years, they may be capable of regenerating China—**if foreign powers refrain from drastic intervention**.\\n\\n#### **2. Outlook and Potential of \"Young China\"**\\n- **Two Generations of Modern Intellectuals:**\\n  - **Older Generation (30–50 years old):**\\n    - Faced immense difficulty breaking from Confucian traditions.\\n    - Underwent a mental revolution akin to Western rationalists (e.g., Darwin, Mill).\\n    - Struggled to abandon ingrained beliefs and adopt modern science and ethics.\\n    - Some are exhausted from this effort; their creativity may be diminished.\\n  - **Younger Generation (under 30):**\\n    - Encountered modern ideas earlier, often without severe conflict.\\n    - Learned Western knowledge from Chinese teachers, easing assimilation.\\n    - Retain the honesty and candor of the older generation but with greater energy and social determination.\\n    - Better equipped to resist family pressures and question excessive reverence for tradition.\\n    - Seen as the hope for China’s future; with experience, they may lead effectively.\\n\\n- **Cultural Assimilation Without Imitation:**\\n  - **Not purely imitative:**\\n    - Second-rate Chinese (especially converts to Christianity) may adopt Western culture superficially.\\n    - The best intellectuals remain distinctly Chinese, even when critical of European civilization.\\n  - **Key Traits:**\\n    - Retain moral idealism and belief in the power of ethical persuasion.\\n    - Unaffected by industrialization’s cynicism; opinions are argued on merit, not marketed.\\n    - Reject ruthlessness and purposeless activity.\\n    - Having discarded old prejudices, they avoid adopting new dogmas, maintaining intellectual freedom.\\n\\n#### **3. Persistent Traditional Beliefs and Their Limitations**\\n- **Ethics Over Technical Knowledge:**\\n  - Confucian tradition prioritizes correct ethical sentiments over detailed scientific or practical knowledge.\\n  - This view was common in pre-industrial societies (e.g., Rousseau, Dr. Johnson).\\n  - **Western Contrast:**\\n    - Modern West overcorrects, valuing technical efficiency above moral purpose (e.g., military technology like poison gas).\\n    - Chinese intellectuals avoid this extreme but err in believing good intentions alone suffice.\\n  - **Example:**\\n    - Forestry in China:\\n      - Evidence (e.g., Forsythe Sherfesee’s 1919 address) shows afforestation could prevent floods, reduce timber imports, and reclaim wasteland.\\n      - Reformist Chinese often dismiss practical issues (e.g., forestry) as unworthy of ethical enthusiasm.\\n      - Trees are planted only for Confucian rituals (e.g., graves); if Confucianism declines, even these may disappear.\\n      - Prefer abstract political theory (e.g., Western parliamentary models) over practical studies (e.g., forestry, industrial processes).\\n      - Political theories are context-dependent (applicable only in the West), while practical knowledge (e.g., forestry) is universally valid.\\n  - **Recent Improvements:**\\n    - Growing recognition of the need for practical, technical knowledge alongside ethical concerns.\\n\\n#### **4. Logical Structure and Emphases**\\n- **Contrasts Highlighted:**\\n  - Traditional vs. modern education.\\n  - Older vs. younger generations of intellectuals.\\n  - Chinese vs. Western attitudes toward knowledge (ethics vs. technical efficiency).\\n  - Abstract theory vs. practical application.\\n- **Qualifications:**\\n  - The influence of Young China is contingent on foreign powers not intervening.\\n  - The older generation’s exhaustion is understandable given their struggles.\\n  - The younger generation’s advantages may partly reflect youthful energy, but are also due to easier access to modern education.\\n- **Emphases:**\\n  - The unique historical role of education in China.\\n  - The potential of the younger generation to lead reform.\\n  - The danger of overvaluing either ethics or technical efficiency to the exclusion of the other.', tool_calls=None, finish_reason='stop', model='mistral-large-2512', usage={'prompt_tokens': 1946, 'completion_tokens': 1028, 'total_tokens': 2974}, raw_response=ModelResponse(id='c344252103474c7ea2a42f8602b0e2c1', created=1764693505, model='mistral-large-2512', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='### **Summary of Informational and Argumentative Content**\\n\\n#### **1. Position and Influence of the Chinese Intelligentsia**\\n- **Historical Context:**\\n  - China has lacked a hereditary aristocracy for ~2,000 years.\\n  - Governance has long been based on competitive examinations, granting the educated a prestige comparable to that of a governing aristocracy in other societies.\\n- **Current Status:**\\n  - Traditional education is declining, replaced by modern subjects.\\n  - The prestige of education persists; public opinion remains influenced by intellectuals.\\n  - Warlords (*Tuchuns*), often uneducated (e.g., former brigands like Chang-tso-lin), lack this respect, making their rule weak and unstable.\\n- **Role of \"Young China\":**\\n  - Refers to those educated abroad or in modern domestic institutions.\\n  - Their influence is disproportionately strong due to China’s historical respect for learning.\\n  - Their numbers are rapidly increasing; their outlook and goals are positive.\\n  - In ~10 years, they may be capable of regenerating China—**if foreign powers refrain from drastic intervention**.\\n\\n#### **2. Outlook and Potential of \"Young China\"**\\n- **Two Generations of Modern Intellectuals:**\\n  - **Older Generation (30–50 years old):**\\n    - Faced immense difficulty breaking from Confucian traditions.\\n    - Underwent a mental revolution akin to Western rationalists (e.g., Darwin, Mill).\\n    - Struggled to abandon ingrained beliefs and adopt modern science and ethics.\\n    - Some are exhausted from this effort; their creativity may be diminished.\\n  - **Younger Generation (under 30):**\\n    - Encountered modern ideas earlier, often without severe conflict.\\n    - Learned Western knowledge from Chinese teachers, easing assimilation.\\n    - Retain the honesty and candor of the older generation but with greater energy and social determination.\\n    - Better equipped to resist family pressures and question excessive reverence for tradition.\\n    - Seen as the hope for China’s future; with experience, they may lead effectively.\\n\\n- **Cultural Assimilation Without Imitation:**\\n  - **Not purely imitative:**\\n    - Second-rate Chinese (especially converts to Christianity) may adopt Western culture superficially.\\n    - The best intellectuals remain distinctly Chinese, even when critical of European civilization.\\n  - **Key Traits:**\\n    - Retain moral idealism and belief in the power of ethical persuasion.\\n    - Unaffected by industrialization’s cynicism; opinions are argued on merit, not marketed.\\n    - Reject ruthlessness and purposeless activity.\\n    - Having discarded old prejudices, they avoid adopting new dogmas, maintaining intellectual freedom.\\n\\n#### **3. Persistent Traditional Beliefs and Their Limitations**\\n- **Ethics Over Technical Knowledge:**\\n  - Confucian tradition prioritizes correct ethical sentiments over detailed scientific or practical knowledge.\\n  - This view was common in pre-industrial societies (e.g., Rousseau, Dr. Johnson).\\n  - **Western Contrast:**\\n    - Modern West overcorrects, valuing technical efficiency above moral purpose (e.g., military technology like poison gas).\\n    - Chinese intellectuals avoid this extreme but err in believing good intentions alone suffice.\\n  - **Example:**\\n    - Forestry in China:\\n      - Evidence (e.g., Forsythe Sherfesee’s 1919 address) shows afforestation could prevent floods, reduce timber imports, and reclaim wasteland.\\n      - Reformist Chinese often dismiss practical issues (e.g., forestry) as unworthy of ethical enthusiasm.\\n      - Trees are planted only for Confucian rituals (e.g., graves); if Confucianism declines, even these may disappear.\\n      - Prefer abstract political theory (e.g., Western parliamentary models) over practical studies (e.g., forestry, industrial processes).\\n      - Political theories are context-dependent (applicable only in the West), while practical knowledge (e.g., forestry) is universally valid.\\n  - **Recent Improvements:**\\n    - Growing recognition of the need for practical, technical knowledge alongside ethical concerns.\\n\\n#### **4. Logical Structure and Emphases**\\n- **Contrasts Highlighted:**\\n  - Traditional vs. modern education.\\n  - Older vs. younger generations of intellectuals.\\n  - Chinese vs. Western attitudes toward knowledge (ethics vs. technical efficiency).\\n  - Abstract theory vs. practical application.\\n- **Qualifications:**\\n  - The influence of Young China is contingent on foreign powers not intervening.\\n  - The older generation’s exhaustion is understandable given their struggles.\\n  - The younger generation’s advantages may partly reflect youthful energy, but are also due to easier access to modern education.\\n- **Emphases:**\\n  - The unique historical role of education in China.\\n  - The potential of the younger generation to lead reform.\\n  - The danger of overvaluing either ethics or technical efficiency to the exclusion of the other.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None), provider_specific_fields={})], usage=Usage(completion_tokens=1028, prompt_tokens=1946, total_tokens=2974, completion_tokens_details=None, prompt_tokens_details=None)))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====ORIGINAL===\n",
      "The world may be conceived as consisting of a multitude of entities\n",
      "arranged in a certain pattern. The entities which are arranged I shall\n",
      "call \"particulars.\" The arrangement or pattern results from relations\n",
      "among particulars. Classes or series of particulars, collected\n",
      "together on account of some property which makes it convenient to be\n",
      "able to speak of them as wholes, are what I call logical constructions\n",
      "or symbolic fictions. The particulars are to be conceived, not on the\n",
      "analogy of bricks in a building, but rather on the analogy of notes\n",
      "in a symphony. The ultimate constituents of a symphony (apart from\n",
      "relations) are the notes, each of which lasts only for a very short\n",
      "time. We may collect together all the notes played by one instrument:\n",
      "these may be regarded as the analogues of the successive particulars\n",
      "which common sense would regard as successive states of one \"thing.\"\n",
      "But the \"thing\" ought to be regarded as no more \"real\" or\n",
      "\"substantial\" than, for example, the rôle of the trombone. As soon as\n",
      "\"things\" are conceived in this manner it will be found that the\n",
      "difficulties in the way of regarding immediate objects of sense as\n",
      "physical have largely disappeared.\n",
      "\n",
      "When people ask, \"Is the object of sense mental or physical?\" they\n",
      "seldom have any clear idea either what is meant by \"mental\" or\n",
      "\"physical,\" or what criteria are to be applied for deciding whether a\n",
      "given entity belongs to one class or the other. I do not know how to\n",
      "give a sharp definition of the word \"mental,\" but something may be\n",
      "done by enumerating occurrences which are indubitably mental:\n",
      "believing, doubting, wishing, willing, being pleased or pained, are\n",
      "certainly mental occurrences; so are what we may call experiences,\n",
      "seeing, hearing, smelling, perceiving generally. But it does not\n",
      "follow from this that what is seen, what is heard, what is smelt, what\n",
      "is perceived, must be mental. When I see a flash of lightning, my\n",
      "seeing of it is mental, but what I see, although it is not quite the\n",
      "same as what anybody else sees at the same moment, and although it\n",
      "seems very unlike what the physicist would describe as a flash of\n",
      "lightning, is not mental. I maintain, in fact, that if the physicist\n",
      "could describe truly and fully all that occurs in the physical world\n",
      "when there is a flash of lightning, it would contain as a constituent\n",
      "what I see, and also what is seen by anybody else who would commonly\n",
      "be said to see the same flash. What I mean may perhaps be made plainer\n",
      "by saying that if my body could remain in exactly the same state in\n",
      "which it is, although my mind had ceased to exist, precisely that\n",
      "object which I now see when I see the flash would exist, although of\n",
      "course I should not see it, since my seeing is mental. The principal\n",
      "reasons which have led people to reject this view have, I think, been\n",
      "two: first, that they did not adequately distinguish between my seeing\n",
      "and what I see; secondly, that the causal dependence of what I see\n",
      "upon my body has made people suppose that what I see cannot be\n",
      "\"outside\" me. The first of these reasons need not detain us, since the\n",
      "confusion only needs to be pointed out in order to be obviated; but\n",
      "the second requires some discussion, since it can only be answered by\n",
      "removing current misconceptions, on the one hand as to the nature of\n",
      "space, and on the other, as to the meaning of causal dependence.\n",
      "\n",
      "When people ask whether colours, for example, or other secondary\n",
      "qualities are inside or outside the mind, they seem to suppose that\n",
      "their meaning must be clear, and that it ought to be possible to say\n",
      "yes or no without any further discussion of the terms involved. In\n",
      "fact, however, such terms as \"inside\" or \"outside\" are very ambiguous.\n",
      "What is meant by asking whether this or that is \"in\" the mind? The\n",
      "mind is not like a bag or a pie; it does not occupy a certain region\n",
      "in space, or, if (in a sense) it does, what is in that region is\n",
      "presumably part of the brain, which would not be said to be in the\n",
      "mind. When people say that sensible qualities are in the mind, they do\n",
      "not mean \"spatially contained in\" in the sense in which the blackbirds\n",
      "were in the pie. We might regard the mind as an assemblage of\n",
      "particulars, namely, what would be called \"states of mind,\" which\n",
      "would belong together in virtue of some specific common quality. The\n",
      "common quality of all states of mind would be the quality designated\n",
      "by the word \"mental\"; and besides this we should have to suppose that\n",
      "each separate person's states of mind have some common characteristic\n",
      "distinguishing them from the states of mind of other people. Ignoring\n",
      "this latter point, let us ask ourselves whether the quality designated\n",
      "by the word \"mental\" does, as a matter of observation, actually belong\n",
      "to objects of sense, such as colours or noises. I think any candid\n",
      "person must reply that, however difficult it may be to know what we\n",
      "mean by \"mental,\" it is not difficult to see that colours and noises\n",
      "are not mental in the sense of having that intrinsic peculiarity which\n",
      "belongs to beliefs and wishes and volitions, but not to the physical\n",
      "world. Berkeley advances on this subject a plausible argument[26]\n",
      "which seems to me to rest upon an ambiguity in the word \"pain.\" He\n",
      "argues that the realist supposes the heat which he feels in\n",
      "approaching a fire to be something outside his mind, but that as he\n",
      "approaches nearer and nearer to the fire the sensation of heat passes\n",
      "imperceptibly into pain, and that no one could regard pain as\n",
      "something outside the mind. In reply to this argument, it should be\n",
      "observed in the first place that the heat of which we are immediately\n",
      "aware is not in the fire but in our own body. It is only by inference\n",
      "that the fire is judged to be the cause of the heat which we feel in\n",
      "our body. In the second place (and this is the more important point),\n",
      "when we speak of pain we may mean one of two things: we may mean the\n",
      "object of the sensation or other experience which has the quality of\n",
      "being painful, or we may mean the quality of painfulness itself. When\n",
      "a man says he has a pain in his great toe, what he means is that he\n",
      "has a sensation associated with his great toe and having the quality\n",
      "of painfulness. The sensation itself, like every sensation, consists\n",
      "in experiencing a sensible object, and the experiencing has that\n",
      "quality of painfulness which only mental occurrences can have, but\n",
      "which may belong to thoughts or desires, as well as to sensations. But\n",
      "in common language we speak of the sensible object experienced in a\n",
      "painful sensation as a pain, and it is this way of speaking which\n",
      "causes the confusion upon which the plausibility of Berkeley's\n",
      "argument depends. It would be absurd to attribute the quality of\n",
      "painfulness to anything non-mental, and hence it comes to be thought\n",
      "that what we call a pain in the toe must be mental. In fact, however,\n",
      "it is not the sensible object in such a case which is painful, but the\n",
      "sensation, that is to say, the experience of the sensible object. As\n",
      "the heat which we experience from the fire grows greater, the\n",
      "experience passes gradually from being pleasant to being painful, but\n",
      "neither the pleasure nor the pain is a quality of the object\n",
      "experienced as opposed to the experience, and it is therefore a\n",
      "fallacy to argue that this object must be mental on the ground that\n",
      "painfulness can only be attributed to what is mental.\n",
      "\n",
      "If, then, when we say that something is in the mind we mean that it\n",
      "has a certain recognisable intrinsic characteristic such as belongs to\n",
      "thoughts and desires, it must be maintained on grounds of immediate\n",
      "inspection that objects of sense are not in any mind.\n",
      "\n",
      "A different meaning of \"in the mind\" is, however, to be inferred from\n",
      "the arguments advanced by those who regard sensible objects as being\n",
      "in the mind. The arguments used are, in the main, such as would prove\n",
      "the causal dependence of objects of sense upon the percipient. Now\n",
      "the notion of causal dependence is very obscure and difficult, much\n",
      "more so in fact than is generally realised by philosophers. I shall\n",
      "return to this point in a moment. For the present, however, accepting\n",
      "the notion of causal dependence without criticism, I wish to urge that\n",
      "the dependence in question is rather upon our bodies than upon our\n",
      "minds. The visual appearance of an object is altered if we shut one\n",
      "eye, or squint, or look previously at something dazzling; but all\n",
      "these are bodily acts, and the alterations which they effect are to be\n",
      "explained by physiology and optics, not by psychology.[27] They are in\n",
      "fact of exactly the same kind as the alterations effected by\n",
      "spectacles or a microscope. They belong therefore to the theory of the\n",
      "physical world, and can have no bearing upon the question whether what\n",
      "we see is causally dependent upon the mind. What they do tend to\n",
      "prove, and what I for my part have no wish to deny, is that what we\n",
      "see is causally dependent upon our body and is not, as crude common\n",
      "sense would suppose, something which would exist equally if our eyes\n",
      "and nerves and brain were absent, any more than the visual appearance\n",
      "presented by an object seen through a microscope would remain if the\n",
      "microscope were removed. So long as it is supposed that the physical\n",
      "world is composed of stable and more or less permanent constituents,\n",
      "the fact that what we see is changed by changes in our body appears to\n",
      "afford reason for regarding what we see as not an ultimate constituent\n",
      "of matter. But if it is recognised that the ultimate constituents of\n",
      "matter are as circumscribed in duration as in spatial extent, the\n",
      "whole of this difficulty vanishes.\n",
      "\n",
      "\n",
      "====FLATTENED====\n",
      "### **Summary of Informational and Argumentative Content**\n",
      "\n",
      "---\n",
      "\n",
      "#### **1. Ontological Framework: Particulars and Logical Constructions**\n",
      "- The world consists of **entities (\"particulars\")** arranged in a **pattern defined by relations** among them.\n",
      "- **Particulars** are the fundamental constituents, analogous to **notes in a symphony** (each brief in duration).\n",
      "  - **Classes or series of particulars** grouped by shared properties are **\"logical constructions\" or \"symbolic fictions\"** (e.g., \"things\" in common sense).\n",
      "    - Example: All notes played by one instrument in a symphony are analogous to successive states of a \"thing.\"\n",
      "    - **\"Things\" are not more \"real\" or \"substantial\" than the role of an instrument** (e.g., a trombone).\n",
      "- **Implication**: If \"things\" are understood this way, difficulties in treating **immediate objects of sense as physical** largely disappear.\n",
      "\n",
      "---\n",
      "\n",
      "#### **2. The Mental vs. Physical Distinction: Clarifying the Question**\n",
      "- The question **\"Is the object of sense mental or physical?\"** is often asked without clear definitions of \"mental\" or \"physical,\" or criteria for classification.\n",
      "- **No sharp definition of \"mental\" is provided**, but **indubitable mental occurrences** include:\n",
      "  - Cognitive/affective states: believing, doubting, wishing, willing, being pleased/pained.\n",
      "  - Perceptual experiences: seeing, hearing, smelling, perceiving generally.\n",
      "- **Key claim**: The **act of perceiving** (e.g., seeing) is mental, but **what is perceived** (e.g., the flash of lightning) is **not necessarily mental**.\n",
      "  - **Evidence/argument**:\n",
      "    1. **Divergence in perception**: What one person sees in a flash of lightning differs from what another sees or from the physicist’s description.\n",
      "    2. **Independence from the perceiver’s mind**: If the perceiver’s body remained in the same state but their mind ceased to exist, **the object perceived (e.g., the flash) would still exist**, though it would not be seen.\n",
      "  - **Reasons for rejecting this view**:\n",
      "    1. **Failure to distinguish between the act of perception and the object perceived** (resolved by clarification).\n",
      "    2. **Causal dependence of perception on the body**, leading to the assumption that the perceived object must be \"inside\" the perceiver.\n",
      "      - This requires addressing **misconceptions about space and causality**.\n",
      "\n",
      "---\n",
      "\n",
      "#### **3. The Ambiguity of \"Inside\" and \"Outside\" the Mind**\n",
      "- Terms like **\"inside\" or \"outside\" the mind** are **ambiguous** and require clarification.\n",
      "- **Possible meanings of \"in the mind\"**:\n",
      "  1. **Spatial containment** (e.g., like objects in a bag):\n",
      "     - **Rejected**: The mind does not occupy a spatial region in the way a bag does.\n",
      "     - Even if the mind were spatially located (e.g., in the brain), the brain is not \"in the mind\" in the relevant sense.\n",
      "  2. **Possession of a \"mental\" intrinsic quality**:\n",
      "     - The mind may be conceived as an **assemblage of \"states of mind\"** (particulars) sharing a common \"mental\" quality.\n",
      "     - **Each person’s states of mind** may have additional distinguishing characteristics.\n",
      "     - **Key question**: Do **objects of sense (e.g., colors, noises)** possess the intrinsic quality of \"mental\"?\n",
      "       - **Claim**: **No**, based on **immediate inspection**.\n",
      "         - **Beliefs, wishes, and volitions** have a **recognizable \"mental\" quality**, but **sensible objects (e.g., colors, noises) do not**.\n",
      "         - **Berkeley’s argument** (used to support the mental status of sensible objects) is **flawed due to ambiguity in \"pain.\"**\n",
      "           - **Berkeley’s argument**:\n",
      "             - Heat felt near a fire is initially perceived as external.\n",
      "             - As heat intensifies, it becomes painful, and pain is indisputably mental.\n",
      "             - Therefore, heat (and by extension, other sensible qualities) must be mental.\n",
      "           - **Rebuttal**:\n",
      "             1. The **heat immediately perceived is in the body**, not the fire (the fire is inferred as the cause).\n",
      "             2. **\"Pain\" is ambiguous**:\n",
      "                - **Sensation of pain**: The **experience** of a sensible object (e.g., heat) with the **quality of painfulness** (which is mental).\n",
      "                - **Object of pain**: The **sensible object itself** (e.g., the heat in the toe), which is **not painful in itself**—only the **experience** is.\n",
      "             - **Fallacy**: Painfulness is a **quality of the experience**, not the object. Thus, the object (e.g., heat) need not be mental.\n",
      "             - **Transition from pleasure to pain**: As heat increases, the **experience** changes from pleasant to painful, but the **object experienced remains non-mental**.\n",
      "\n",
      "---\n",
      "\n",
      "#### **4. Causal Dependence and the Mind-Body Distinction**\n",
      "- **Alternative meaning of \"in the mind\"**: **Causal dependence of sensible objects on the perceiver**.\n",
      "  - **Claim**: The **dependence is on the body, not the mind**.\n",
      "    - **Evidence**:\n",
      "      1. **Visual perception changes** with bodily actions (e.g., shutting one eye, squinting, prior exposure to dazzling light).\n",
      "         - These changes are **explained by physiology and optics**, not psychology.\n",
      "         - They are **analogous to changes caused by instruments** (e.g., spectacles, microscopes).\n",
      "      2. **Implication**: The dependence is **physical**, not mental.\n",
      "         - What we see is **causally dependent on the body** (e.g., eyes, nerves, brain), not the mind.\n",
      "         - **Crude common sense** assumes objects would exist unchanged without the perceiver’s body, but this is **false** (e.g., removing a microscope alters the visual appearance).\n",
      "  - **Problem with traditional views**:\n",
      "    - If the physical world is assumed to consist of **stable, permanent constituents**, the **dependence of perception on the body** suggests sensible objects are **not ultimate constituents of matter**.\n",
      "    - **Solution**: If **ultimate constituents of matter are brief in duration** (like particulars), this difficulty disappears.\n",
      "\n",
      "---\n",
      "\n",
      "#### **5. Summary of Key Claims and Logical Structure**\n",
      "1. **Ontology**:\n",
      "   - The world is composed of **particulars (brief, fundamental entities)** and **relations** forming patterns.\n",
      "   - **\"Things\" are logical constructions**, not more real than other groupings (e.g., roles in a symphony).\n",
      "\n",
      "2. **Perception and the Mental/Physical Distinction**:\n",
      "   - **Acts of perception (e.g., seeing) are mental**; **objects perceived (e.g., lightning) are not necessarily mental**.\n",
      "   - **Evidence**: Objects perceived would exist even if the perceiver’s mind did not (only the act of perception would cease).\n",
      "   - **Objections addressed**:\n",
      "     - **Confusion between act and object** (resolved by distinction).\n",
      "     - **Causal dependence on the body** (not the mind) explains perceptual variation.\n",
      "\n",
      "3. **Meanings of \"In the Mind\"**:\n",
      "   - **Spatial containment**: Irrelevant (mind is not a container).\n",
      "   - **Intrinsic \"mental\" quality**: Objects of sense **lack this quality** (unlike beliefs or desires).\n",
      "     - **Berkeley’s argument fails** due to ambiguity in \"pain\" (painfulness is a quality of the experience, not the object).\n",
      "   - **Causal dependence**: Sensible objects depend on the **body**, not the mind.\n",
      "\n",
      "4. **Resolution of Traditional Problems**:\n",
      "   - The **dependence of perception on the body** is unproblematic if **matter’s constituents are brief in duration** (like particulars).\n",
      "   - **No need to classify sensible objects as mental** to explain their dependence on perception.\n",
      "\n",
      "---\n",
      "\n",
      "#### **6. Emphases, Qualifications, and Contrasts**\n",
      "- **Emphasis on distinction**:\n",
      "  - Between **act of perception** and **object perceived**.\n",
      "  - Between **causal dependence on the body** vs. **dependence on the mind**.\n",
      "- **Qualifications**:\n",
      "  - \"Mental\" is not sharply defined but **enumerated by indubitable examples**.\n",
      "  - \"Inside/outside\" the mind is **ambiguous** and requires disambiguation.\n",
      "  - **Causal dependence is obscure** and requires further analysis (though not fully addressed here).\n",
      "- **Contrasts**:\n",
      "  - **Common sense view** (stable, permanent physical objects) vs. **proposed view** (brief, relational particulars).\n",
      "  - **Berkeley’s argument** (sensible objects are mental) vs. **rebuttal** (objects are not mental; only experiences can be painful).\n"
     ]
    }
   ],
   "source": [
    "print('====ORIGINAL===')\n",
    "print(store.get_sample('sample_001')['original_text'])\n",
    "print('\\n\\n====FLATTENED====')\n",
    "print(store.get_sample('sample_001')['flattened_content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reconstruction\n",
    "\n",
    "Generate reconstructions using all 4 methods, with M stochastic runs each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 2: Generating Reconstructions ===\n",
      "\n",
      "\n",
      "sample_000:\n",
      "  Run 0:\n",
      "    ✓ generic      (11067 chars)\n",
      "    ✓ fewshot      (6822 chars)\n",
      "    ✓ author       (6193 chars)\n",
      "    ✓ instructions (8052 chars)\n",
      "  Run 1:\n",
      "    ✓ generic      (7817 chars)\n",
      "    ✓ fewshot      (6165 chars)\n",
      "    ✓ author       (7149 chars)\n",
      "    ✓ instructions (8397 chars)\n",
      "  Run 2:\n",
      "    ✓ generic      (10382 chars)\n",
      "    ✓ fewshot      (9859 chars)\n",
      "    ✓ author       (6550 chars)\n",
      "    ✓ instructions (11200 chars)\n",
      "\n",
      "sample_001:\n",
      "  Run 0:\n",
      "    ✓ generic      (8577 chars)\n",
      "    ✓ fewshot      (9003 chars)\n",
      "    ✓ author       (9829 chars)\n",
      "    ✓ instructions (9240 chars)\n",
      "  Run 1:\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate reconstructions (with crash resume)\n",
    "print(\"=== Step 2: Generating Reconstructions ===\\n\")\n",
    "\n",
    "for sample_id in store.list_samples():\n",
    "    sample = store.get_sample(sample_id)\n",
    "    print(f\"\\n{sample_id}:\")\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        print(f\"  Run {run}:\")\n",
    "        \n",
    "        # Check which methods need reconstruction\n",
    "        for method in ['generic', 'fewshot', 'author', 'instructions']:\n",
    "            if store.has_reconstruction(sample_id, run, method):\n",
    "                print(f\"    ✓ {method:12s} (already done)\")\n",
    "                continue\n",
    "            \n",
    "            # Generate reconstruction\n",
    "            config = RECONSTRUCTORS_CFGS[method](\n",
    "                content_summary=sample['flattened_content'],\n",
    "                **RECONSTRUCTORS_KWARGS[method]\n",
    "            )\n",
    "            prompt = prompt_maker.render(config)\n",
    "            response = reconstruction_llm.complete(prompt)\n",
    "            \n",
    "            # Save immediately (crash resilient!)\n",
    "            store.save_reconstruction(\n",
    "                sample_id=sample_id,\n",
    "                run=run,\n",
    "                method=method,\n",
    "                reconstructed_text=response.content,\n",
    "                model=response.model\n",
    "            )\n",
    "            print(f\"    ✓ {method:12s} ({len(response.content)} chars)\")\n",
    "\n",
    "stats = store.get_stats()\n",
    "print(f\"\\n✓ Generated {stats['n_reconstructions']} total reconstructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RECONSTRUCTORS_CFGS['instructions'](\n",
    "                content_summary=sample['flattened_content'],\n",
    "                **RECONSTRUCTORS_KWARGS['instructions']\n",
    "            )\n",
    "prompt = prompt_maker.render(config)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = store.get_reconstructions('sample_001', 1)\n",
    "for reconstructor in reconstructions.keys():\n",
    "    print(f\"{reconstructor.upper()}\\n===================\")\n",
    "    print(f\"\\n{reconstructions.get(reconstructor)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Judging\n",
    "\n",
    "Compare each reconstruction against the original using the judge LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 3: Comparative Blind Judging ===\n",
      "\n",
      "\n",
      "sample_000:\n",
      "  Run 0: Judging... ✓ (confidence: high)\n",
      "  Run 1: Judging... ✓ (confidence: high)\n",
      "  Run 2: Judging... ✓ (confidence: high)\n",
      "\n",
      "sample_001:\n",
      "  Run 0: Judging... ✓ (confidence: high)\n",
      "  Run 1: Judging... ✓ (confidence: high)\n",
      "  Run 2: Judging... ✓ (confidence: high)\n",
      "\n",
      "sample_002:\n",
      "  Run 0: Judging... ✓ (confidence: high)\n",
      "  Run 1: Judging... ✓ (confidence: high)\n",
      "  Run 2: Judging... ✓ (confidence: high)\n",
      "\n",
      "sample_003:\n",
      "  Run 0: Judging... ✓ (confidence: high)\n",
      "  Run 1: Judging... ✓ (confidence: high)\n",
      "  Run 2: Judging... ✓ (confidence: high)\n",
      "\n",
      "sample_004:\n",
      "  Run 0: Judging... ✓ (confidence: high)\n",
      "  Run 1: Judging... ✓ (confidence: high)\n",
      "  Run 2: Judging... ✓ (confidence: medium)\n",
      "\n",
      "✓ Completed 15 judgments\n"
     ]
    }
   ],
   "source": [
    "from belletrist.models import StyleJudgeComparativeConfig, StyleJudgmentComparative\n",
    "# Step 3: Comparative blind judging (with crash resume)\n",
    "print(\"=== Step 3: Comparative Blind Judging ===\\n\")\n",
    "\n",
    "for sample_id in store.list_samples():\n",
    "    sample = store.get_sample(sample_id)\n",
    "    print(f\"\\n{sample_id}:\")\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        if store.has_judgment(sample_id, run):\n",
    "            print(f\"  Run {run}: ✓ Already judged (skipping)\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Run {run}: Judging...\", end=\" \")\n",
    "        \n",
    "        # Get all 4 reconstructions\n",
    "        reconstructions = store.get_reconstructions(sample_id, run)\n",
    "        if len(reconstructions) != 4:\n",
    "            print(f\"✗ Missing reconstructions (found {len(reconstructions)}/4)\")\n",
    "            continue\n",
    "        \n",
    "        # Create randomized mapping for blind evaluation\n",
    "        # Using deterministic seed per (sample, run) for reproducibility\n",
    "        mapping = store.create_random_mapping(seed=hash(f\"{sample_id}_{run}\"))\n",
    "        \n",
    "        # Build prompt with anonymous labels (BLIND EVALUATION)\n",
    "        judge_config = StyleJudgeComparativeConfig(\n",
    "            original_text=sample['original_text'],\n",
    "            reconstruction_text_a=reconstructions[mapping.text_a],\n",
    "            reconstruction_text_b=reconstructions[mapping.text_b],\n",
    "            reconstruction_text_c=reconstructions[mapping.text_c],\n",
    "            reconstruction_text_d=reconstructions[mapping.text_d]\n",
    "        )\n",
    "        judge_prompt = prompt_maker.render(judge_config)\n",
    "        \n",
    "        # Get structured JSON judgment\n",
    "        try:\n",
    "            response = judge_llm.complete_json(judge_prompt)\n",
    "            judgment_data = json.loads(response.content)\n",
    "            judgment = StyleJudgmentComparative(**judgment_data)\n",
    "            \n",
    "            # Save judgment with mapping (crash resilient!)\n",
    "            store.save_judgment(sample_id, run, judgment, mapping, response.model)\n",
    "            print(f\"✓ (confidence: {judgment.confidence})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error: {e}\")\n",
    "\n",
    "stats = store.get_stats()\n",
    "print(f\"\\n✓ Completed {stats['n_judgments']} judgments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Exporting Results ===\n",
      "\n",
      "Total judgments: 15\n",
      "Samples: 5\n",
      "Runs per sample: 3.0\n",
      "\n",
      "=== Sample Results ===\n",
      "\n",
      "     sample_id  run  ranking_generic  ranking_fewshot  ranking_author  \\\n",
      "0   sample_000    0                3                2               4   \n",
      "1   sample_000    1                3                2               4   \n",
      "2   sample_000    2                3                2               1   \n",
      "3   sample_001    0                2                1               4   \n",
      "4   sample_001    1                3                1               4   \n",
      "5   sample_001    2                4                2               1   \n",
      "6   sample_002    0                2                1               4   \n",
      "7   sample_002    1                3                2               1   \n",
      "8   sample_002    2                4                1               3   \n",
      "9   sample_003    0                3                4               1   \n",
      "10  sample_003    1                2                1               4   \n",
      "11  sample_003    2                4                1               3   \n",
      "12  sample_004    0                2                1               4   \n",
      "13  sample_004    1                3                1               4   \n",
      "14  sample_004    2                4                2               1   \n",
      "\n",
      "    ranking_instructions confidence  \n",
      "0                      1       high  \n",
      "1                      1       high  \n",
      "2                      4       high  \n",
      "3                      3       high  \n",
      "4                      2       high  \n",
      "5                      3       high  \n",
      "6                      3       high  \n",
      "7                      4       high  \n",
      "8                      2       high  \n",
      "9                      2       high  \n",
      "10                     3       high  \n",
      "11                     2       high  \n",
      "12                     3       high  \n",
      "13                     2       high  \n",
      "14                     3     medium  \n",
      "\n",
      "✓ Results saved to style_eval_20251202_172015.csv\n"
     ]
    }
   ],
   "source": [
    "# Export results to DataFrame\n",
    "print(\"=== Exporting Results ===\\n\")\n",
    "\n",
    "# Export from store (resolves anonymous rankings to methods)\n",
    "df = store.to_dataframe()\n",
    "\n",
    "print(f\"Total judgments: {len(df)}\")\n",
    "print(f\"Samples: {df['sample_id'].nunique()}\")\n",
    "print(f\"Runs per sample: {df.groupby('sample_id')['run'].nunique().mean():.1f}\")\n",
    "\n",
    "# Show first few rows\n",
    "print(f\"\\n=== Sample Results ===\\n\")\n",
    "display_cols = ['sample_id', 'run', 'ranking_generic', 'ranking_fewshot', \n",
    "                'ranking_author', 'ranking_instructions', 'confidence']\n",
    "print(df[display_cols].head(15))\n",
    "\n",
    "# Export to CSV\n",
    "output_file = f\"style_eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✓ Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me carefully analyze the distinctive voice of the original and compare it to each reconstruction.\n",
      "\n",
      "**The Original's Voice:**\n",
      "\n",
      "The original has a very specific character:\n",
      "- Precise, analytical philosophical prose with clear logical structure\n",
      "- Direct, matter-of-fact tone without literary flourishes\n",
      "- Uses simple metaphors sparingly and functionally (\"cross-section\")\n",
      "- Builds arguments through straightforward exposition\n",
      "- Citations are integrated naturally (James, \"Psychology\")\n",
      "- Transitions are clean and functional (\"With this conclusion we may leave...\")\n",
      "- Sentence structure is varied but never ornate\n",
      "- The voice is that of a lecturer explaining complex ideas clearly, not a stylist displaying virtuosity\n",
      "\n",
      "**Text A Analysis:**\n",
      "\n",
      "Text A immediately strikes a very different tone. Opening with \"we are often tempted to think\" and the elaborate snapshot/galloping horse metaphor shows literary ambition. Phrases like \"temporal loaf,\" \"the cupboard is bare,\" \"no occult 'emotion-stuff' remains to be discovered\" are vivid but feel more writerly than the original's austere precision. The voice actively performs its intelligence rather than simply presenting it. The metaphors pile up: \"frozen cross-section of motion,\" \"continuous reel,\" \"frame extracted,\" \"thicker temporal loaf,\" \"dynamic heart of the matter,\" \"ghostly add-ons,\" \"publicly describable streams,\" \"next eddy in the current.\" This is elegant writing, but it's too self-consciously literary for the original's straightforward philosophical exposition.\n",
      "\n",
      "**Text B Analysis:**\n",
      "\n",
      "Text B opens with \"The common view treats emotions as states we passively undergo—fear washes over us, anger seizes control, joy descends unbidden.\" This has some metaphorical color but quickly settles into more analytical prose. The structure is methodical: \"Consider the difference between seeing red and being enraged...\" The tone is explanatory and careful. Phrases like \"This becomes clearer when we examine\" and \"This analysis of emotion as process rather than state prepares us\" show the same pedagogical clarity as the original. The sentence rhythms feel more natural to philosophical exposition. However, it's somewhat more expansive and discursive than the original's tighter construction. The transitions are smoother and more elaborate than the original's efficient \"With this conclusion we may leave the emotions.\"\n",
      "\n",
      "**Text C Analysis:**\n",
      "\n",
      "Text C opens with \"It is customary, among those who discourse upon the passions, to treat them as though they were small, coloured tiles...\" This is immediately recognizable as a different voice—more ornate, more Victorian or Edwardian in its elaborate constructions. \"This procedure, though convenient, is radically misleading\" has a rhetorical flourish. The metaphors are extended and literary: \"cinematograph-frame,\" \"melody,\" \"currants in a pudding,\" \"swatting ghostly mosquitoes,\" \"corridor,\" \"ocean liner.\" Phrases like \"if we may pursue the metaphor\" and \"I confess that this account\" create a more personal, conversational relationship with the reader that feels unlike the original's impersonal exposition. The voice is witty and self-aware in a way the original never is.\n",
      "\n",
      "**Text D Analysis:**\n",
      "\n",
      "Text D begins: \"An emotion, if we are to speak precisely, is never a thing that one can point to at an instant; it is a history, a drama in miniature...\" This has some metaphorical elaboration but the structure is familiar. The phrase \"if we are to speak precisely\" echoes the original's careful qualifications. The transition \"When this much is granted, the road is clear to the topic of will\" is very close to the original's \"With this conclusion we may leave the emotions and pass to the consideration of the will.\" The treatment of James is similar: direct reference, followed by paraphrase and evaluation. The phrase \"I see no reason to quarrel with the account\" closely parallels the original's \"I see no reason to doubt the correctness of this view.\" The sentence structure and rhythm feel most similar to the original—varied but not ornate, precise but not flowery. While there are some literary touches (\"drama in miniature,\" \"currants in a cake\"), they're used more sparingly and functionally than in the other texts.\n",
      "\n",
      "**Comparative Ranking:**\n",
      "\n",
      "Text D captures the original's voice most faithfully—its directness, its functional use of metaphor, its logical structure, and especially its characteristic phrases and transitions. The similarities in phrasing (\"I see no reason to...\") and structural moves are striking.\n",
      "\n",
      "Text B is second—it has the right analytical, explanatory tone and avoids excessive literary flourish, though it's somewhat more expansive than the original.\n",
      "\n",
      "Text C, while beautifully written, is too ornate and self-consciously literary. The Victorian-tinged rhetoric and extended metaphors create a very different authorial presence.\n",
      "\n",
      "Text A, despite its intelligence and clarity, is too literarily ambitious, with its piling up of vivid metaphors and self-conscious writerly touches that feel unlike the original's straightforward exposition.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[4,'reasoning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ranking Distribution by Method ===\n",
      "\n",
      "\n",
      "GENERIC:\n",
      "  Rank 1:   0 (  0.0%)\n",
      "  Rank 2:   4 ( 26.7%)\n",
      "  Rank 3:   7 ( 46.7%)\n",
      "  Rank 4:   4 ( 26.7%)\n",
      "\n",
      "FEWSHOT:\n",
      "  Rank 1:   8 ( 53.3%)\n",
      "  Rank 2:   6 ( 40.0%)\n",
      "  Rank 3:   0 (  0.0%)\n",
      "  Rank 4:   1 (  6.7%)\n",
      "\n",
      "AUTHOR:\n",
      "  Rank 1:   5 ( 33.3%)\n",
      "  Rank 2:   0 (  0.0%)\n",
      "  Rank 3:   2 ( 13.3%)\n",
      "  Rank 4:   8 ( 53.3%)\n",
      "\n",
      "INSTRUCTIONS:\n",
      "  Rank 1:   2 ( 13.3%)\n",
      "  Rank 2:   5 ( 33.3%)\n",
      "  Rank 3:   6 ( 40.0%)\n",
      "  Rank 4:   2 ( 13.3%)\n",
      "\n",
      "=== Confidence Distribution ===\n",
      "\n",
      "confidence\n",
      "high      14\n",
      "medium     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analyze ranking distributions\n",
    "print(\"=== Ranking Distribution by Method ===\\n\")\n",
    "\n",
    "for method in ['generic', 'fewshot', 'author', 'instructions']:\n",
    "    col = f'ranking_{method}'\n",
    "    print(f\"\\n{method.upper()}:\")\n",
    "    ranking_counts = df[col].value_counts().sort_index()\n",
    "    for rank in [1, 2, 3, 4]:\n",
    "        count = ranking_counts.get(rank, 0)\n",
    "        pct = (count / len(df) * 100) if len(df) > 0 else 0\n",
    "        print(f\"  Rank {rank}: {count:3d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n=== Confidence Distribution ===\\n\")\n",
    "print(df['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Method Performance Metrics ===\n",
      "\n",
      "Average Ranking (lower is better):\n",
      "1. fewshot     : 1.60 (1st place: 8/15 = 53.3%)\n",
      "2. instructions: 2.53 (1st place: 2/15 = 13.3%)\n",
      "3. author      : 2.87 (1st place: 5/15 = 33.3%)\n",
      "4. generic     : 3.00 (1st place: 0/15 = 0.0%)\n",
      "\n",
      "Top-2 Rate (ranked 1st or 2nd):\n",
      "  generic     : 4/15 = 26.7%\n",
      "  fewshot     : 14/15 = 93.3%\n",
      "  author      : 5/15 = 33.3%\n",
      "  instructions: 7/15 = 46.7%\n"
     ]
    }
   ],
   "source": [
    "# Calculate method performance metrics\n",
    "print(\"=== Method Performance Metrics ===\\n\")\n",
    "\n",
    "# Calculate mean ranking for each method (lower is better: 1 = best, 4 = worst)\n",
    "mean_rankings = {}\n",
    "for method in ['generic', 'fewshot', 'author', 'instructions']:\n",
    "    col = f'ranking_{method}'\n",
    "    mean_rankings[method] = df[col].mean()\n",
    "\n",
    "# Sort by mean ranking (best first)\n",
    "sorted_methods = sorted(mean_rankings.items(), key=lambda x: x[1])\n",
    "\n",
    "print(\"Average Ranking (lower is better):\")\n",
    "for i, (method, mean_rank) in enumerate(sorted_methods, 1):\n",
    "    # Count how often this method ranked 1st\n",
    "    first_place = (df[f'ranking_{method}'] == 1).sum()\n",
    "    first_place_pct = (first_place / len(df) * 100) if len(df) > 0 else 0\n",
    "    \n",
    "    print(f\"{i}. {method:12s}: {mean_rank:.2f} (1st place: {first_place}/{len(df)} = {first_place_pct:.1f}%)\")\n",
    "\n",
    "# Win rate (percentage of times ranked 1st or 2nd)\n",
    "print(\"\\nTop-2 Rate (ranked 1st or 2nd):\")\n",
    "for method in ['generic', 'fewshot', 'author', 'instructions']:\n",
    "    col = f'ranking_{method}'\n",
    "    top2 = ((df[col] == 1) | (df[col] == 2)).sum()\n",
    "    top2_pct = (top2 / len(df) * 100) if len(df) > 0 else 0\n",
    "    print(f\"  {method:12s}: {top2}/{len(df)} = {top2_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Results saved to style_evaluation_results_20251202_164845.csv\n"
     ]
    }
   ],
   "source": [
    "# Export results\n",
    "output_file = f\"style_evaluation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✓ Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "TODO: Add analysis cells for:\n",
    "- Statistical significance testing\n",
    "- Visualization of results\n",
    "- Sample-by-sample breakdown\n",
    "- Confidence level analysis\n",
    "- Qualitative review of reasoning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (russell_writes)",
   "language": "python",
   "name": "russell_writes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
