{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Instruction Evaluation Framework\n",
    "\n",
    "This notebook evaluates how well derived style instructions enable style replication, compared to alternative approaches.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "For each gold standard text:\n",
    "1. **Flatten**: Extract content while removing style\n",
    "2. **Reconstruct**: Generate text using 4 different methods (M stochastic runs each):\n",
    "   - Generic baseline\n",
    "   - Few-shot learning\n",
    "   - Author name prompting\n",
    "   - Derived style instructions\n",
    "3. **Judge (Blind Comparative)**: Judge ranks all 4 reconstructions from 1-4 based on similarity to original\n",
    "   - **Blind evaluation**: Judge sees only anonymous labels (Text A, B, C, D) - no method names\n",
    "   - **Ranking**: 1 = most similar, 2 = second, 3 = third, 4 = least similar\n",
    "   - **Order randomized**: Position of methods varies across samples to eliminate bias\n",
    "4. **Aggregate**: Analyze rankings to determine which method best captures style\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Crash resilient**: All LLM responses saved to SQLite immediately\n",
    "- **Resume support**: Can restart after failures, skips completed work\n",
    "- **Blind evaluation**: Eliminates judge bias by hiding method names\n",
    "- **Comparative ranking**: More informative than binary comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries and Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm==1.79.3 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.79.3)\n",
      "Requirement already satisfied: pydantic==2.7.4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (2.7.4)\n",
      "Requirement already satisfied: jinja2>=3.1.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (3.10.11)\n",
      "Requirement already satisfied: click in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (8.5.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.99.5 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: tokenizers in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from litellm==1.79.3->-r requirements.txt (line 1)) (0.9.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from pydantic==2.7.4->-r requirements.txt (line 2)) (4.13.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jinja2>=3.1.0->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: anyio in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.7.1)\n",
      "Requirement already satisfied: certifi in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: sniffio in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=6.8.0->litellm==1.79.3->-r requirements.txt (line 1)) (3.20.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (5.10.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (2023.12.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.79.3->-r requirements.txt (line 1)) (0.20.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (0.9.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from openai>=1.99.5->litellm==1.79.3->-r requirements.txt (line 1)) (4.64.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2022.4.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2.27.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from anyio->httpx>=0.23.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.1.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.79.3->-r requirements.txt (line 1)) (2.0.12)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/andersohrn/opt/anaconda3/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp>=3.10->litellm==1.79.3->-r requirements.txt (line 1)) (0.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providers\n",
      "=========\n",
      "* openai\n",
      "* openai_like\n",
      "* bytez\n",
      "* xai\n",
      "* custom_openai\n",
      "* text-completion-openai\n",
      "* cohere\n",
      "* cohere_chat\n",
      "* clarifai\n",
      "* anthropic\n",
      "* anthropic_text\n",
      "* replicate\n",
      "* huggingface\n",
      "* together_ai\n",
      "* datarobot\n",
      "* openrouter\n",
      "* cometapi\n",
      "* vertex_ai\n",
      "* vertex_ai_beta\n",
      "* gemini\n",
      "* ai21\n",
      "* baseten\n",
      "* azure\n",
      "* azure_text\n",
      "* azure_ai\n",
      "* sagemaker\n",
      "* sagemaker_chat\n",
      "* bedrock\n",
      "* vllm\n",
      "* nlp_cloud\n",
      "* petals\n",
      "* oobabooga\n",
      "* ollama\n",
      "* ollama_chat\n",
      "* deepinfra\n",
      "* perplexity\n",
      "* mistral\n",
      "* groq\n",
      "* nvidia_nim\n",
      "* cerebras\n",
      "* baseten\n",
      "* ai21_chat\n",
      "* volcengine\n",
      "* codestral\n",
      "* text-completion-codestral\n",
      "* deepseek\n",
      "* sambanova\n",
      "* maritalk\n",
      "* cloudflare\n",
      "* fireworks_ai\n",
      "* friendliai\n",
      "* watsonx\n",
      "* watsonx_text\n",
      "* triton\n",
      "* predibase\n",
      "* databricks\n",
      "* empower\n",
      "* github\n",
      "* custom\n",
      "* litellm_proxy\n",
      "* hosted_vllm\n",
      "* llamafile\n",
      "* lm_studio\n",
      "* galadriel\n",
      "* gradient_ai\n",
      "* github_copilot\n",
      "* novita\n",
      "* meta_llama\n",
      "* featherless_ai\n",
      "* nscale\n",
      "* nebius\n",
      "* dashscope\n",
      "* moonshot\n",
      "* v0\n",
      "* heroku\n",
      "* oci\n",
      "* morph\n",
      "* lambda_ai\n",
      "* vercel_ai_gateway\n",
      "* wandb\n",
      "* ovhcloud\n",
      "* lemonade\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import litellm\n",
    "    print('Providers\\n=========')\n",
    "    print('* ' + '\\n* '.join(litellm.LITELLM_CHAT_PROVIDERS))\n",
    "except ImportError as e:\n",
    "    print(f\"\u2717 Cannot import litellm: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Base Objects\n",
    "The base objects part of the current project library (`belletrist`) are initialized. They are:\n",
    "* `LLM`: the LLM object.\n",
    "* `LLMConfig`: the configuration of the LLM object, such as what model to use.\n",
    "* `PromptMaker`: generates prompts from templates and variables\n",
    "* `DataSampler`: retrieves and samples text at a source directory\n",
    "\n",
    "These will implement text transformations by LLMs part of the evaluation process. They build on the third-party LLMs, which we furthermore split into LLMs for text reconstruction and text judging, the key parameters for which are set below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reconstruction_string = 'anthropic/claude-sonnet-4-5-20250929'\n",
    "model_reconstruction_api_key_env_var = 'ANTHROPIC_API_KEY'\n",
    "model_judge_string = 'anthropic/claude-sonnet-4-5-20250929'\n",
    "model_judge_api_key_env_var = 'ANTHROPIC_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from belletrist import PromptMaker, DataSampler, StyleEvaluationStore\n",
    "\n",
    "prompt_maker = PromptMaker()\n",
    "sampler = DataSampler(\n",
    "    data_path=(Path(os.getcwd()) / \"data\" / \"russell\").resolve()\n",
    ")\n",
    "store = StyleEvaluationStore(Path(\"style_evaluation_results_sonnet_sonnet.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.reset('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from belletrist import LLM, LLMConfig\n",
    "\n",
    "reconstruction_llm = LLM(LLMConfig(\n",
    "    model=model_reconstruction_string,\n",
    "    api_key=os.environ.get(model_reconstruction_api_key_env_var)\n",
    "))\n",
    "judge_llm = LLM(LLMConfig(\n",
    "    model=model_judge_string,\n",
    "    api_key=os.environ.get(model_judge_api_key_env_var)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Test Data and Few-Shot Data\n",
    "The reconstruction method tests build on gold standard texts. The test also includes few-shot prompting with the gold standard texts. In order to not skew the tests, no few-shot examples can overlap with the test texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 5\n",
    "m_paragraphs_per_sample = 5\n",
    "n_few_shot_sample = 5\n",
    "\n",
    "test_texts = []\n",
    "for _ in range(n_sample):\n",
    "    test_texts.append(sampler.sample_segment(p_length=m_paragraphs_per_sample))\n",
    "\n",
    "few_shot_texts = []\n",
    "while len(few_shot_texts) < n_few_shot_sample:\n",
    "    p = sampler.sample_segment(p_length=m_paragraphs_per_sample)\n",
    "\n",
    "    # Check if p overlaps with any test text\n",
    "    # Two segments overlap if they're from the same file AND their paragraph ranges overlap\n",
    "    # Ranges [a, b) and [c, d) overlap if: a < d AND c < b\n",
    "    has_overlap = any(\n",
    "        p.file_index == test_seg.file_index and\n",
    "        p.paragraph_start < test_seg.paragraph_end and\n",
    "        test_seg.paragraph_start < p.paragraph_end\n",
    "        for test_seg in test_texts\n",
    "    )\n",
    "\n",
    "    if not has_overlap:\n",
    "        few_shot_texts.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Test Transformation Objects\n",
    "The combination of prompt and LLM leads to the following operators in the test chain:\n",
    "* **Style Flattener**, which given a text compresses it into its content bare bones.\n",
    "* **Reconstructor, LLM House Style**, which given a compressed content expands it into a complete text with the \"house style\" of the LLM employed for the reconstruction.\n",
    "* **Reconstructor, Few Shot**, which given a compressed content expands it into a complete text with a few text excerpts on unrelated topics as style guide.\n",
    "* **Reconstructor, LLM Author Model**, which given a compressed content expands it into a complete text with the named author's style as the LLM conceives it without any other guidance.\n",
    "* **Reconstructor, Style Instruction**, which given a compressed content expands it into a complete text following the detailed style instruction, as derived from previous analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Loaded style instructions (23968 chars)\n",
      "\n",
      "First 200 chars:\n",
      "---\n",
      "synthesis_id: principles_guide_001\n",
      "synthesis_type: principles_guide\n",
      "model: mistral-large-2411\n",
      "created_at: 2025-11-25T16:33:20.019525\n",
      "parent_synthesis_id: cross_text_synthesis_002\n",
      "num_samples: 5\n",
      "sample_ids:\n",
      "  - sample_005\n",
      "  - sample_003\n",
      "  - sample_001\n",
      "  - sample_002\n",
      "  - sample_004\n",
      "is_homogeneous_model: true\n",
      "models_used:\n",
      "  - mistral-large-2411\n",
      "---\n",
      "\n",
      "# A GUIDE TO CLEAR AND ENGAGING PROSE\n",
      "## Principles Extracted from Pattern Analysis\n",
      "\n",
      "### PART I: FOUNDATIONS\n",
      "## Core Principles\n",
      "\n",
      "### 1. Subordinate...\n"
     ]
    }
   ],
   "source": [
    "style_instructions_path = Path(\"outputs/derived_style_instructions_1125_000.txt\")\n",
    "\n",
    "if style_instructions_path.exists():\n",
    "    style_instructions = style_instructions_path.read_text()\n",
    "    print(f\"\u2713 Loaded style instructions ({len(style_instructions)} chars)\")\n",
    "    print(f\"\\nFirst 200 chars:\\n{style_instructions[:500]}...\")\n",
    "else:\n",
    "    print(\"\u26a0 Style instructions file not found. Please provide path.\")\n",
    "    style_instructions = \"\"  # Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Store initialized at style_evaluation_results_sonnet_sonnet.db\n",
      "\u2713 Configuration: 3 runs per sample, 4 reconstruction methods\n"
     ]
    }
   ],
   "source": [
    "from belletrist.models import (\n",
    "    StyleFlatteningConfig,\n",
    "    StyleReconstructionGenericConfig,\n",
    "    StyleReconstructionFewShotConfig,\n",
    "    StyleReconstructionAuthorConfig,\n",
    "    StyleReconstructionInstructionsConfig,\n",
    "    MethodMapping,\n",
    "    StyleJudgeComparativeConfig\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "n_runs = 3\n",
    "AUTHOR_NAME = \"Bertrand Russell\"\n",
    "\n",
    "# Reconstructor configs\n",
    "RECONSTRUCTORS_CFGS = {\n",
    "    'generic': StyleReconstructionGenericConfig,\n",
    "    'fewshot': StyleReconstructionFewShotConfig,\n",
    "    'author': StyleReconstructionAuthorConfig,\n",
    "    'instructions': StyleReconstructionInstructionsConfig\n",
    "}\n",
    "\n",
    "# Reconstructor kwargs\n",
    "RECONSTRUCTORS_KWARGS = {\n",
    "    'generic': {},\n",
    "    'fewshot': {'few_shot_examples': [seg.text for seg in few_shot_texts]},\n",
    "    'author': {'author_name': AUTHOR_NAME},\n",
    "    'instructions': {'style_instructions': style_instructions}\n",
    "}\n",
    "\n",
    "print(f\"\u2713 Store initialized at {store.filepath}\")\n",
    "print(f\"\u2713 Configuration: {n_runs} runs per sample, 4 reconstruction methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Content Flattening\n",
    "\n",
    "Extract content from each test sample, removing stylistic elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: Flattening and Saving Samples ===\n",
      "\n",
      "Flattening sample_000... \u2713 (4272 chars)\n",
      "Flattening sample_001... \u2713 (4258 chars)\n",
      "Flattening sample_002... \u2713 (3357 chars)\n",
      "Flattening sample_003... \u2713 (5134 chars)\n",
      "Flattening sample_004... \u2713 (2925 chars)\n",
      "\n",
      "\u2713 All samples flattened and saved to store\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Save samples and flatten content\n",
    "print(\"=== Step 1: Flattening and Saving Samples ===\\n\")\n",
    "\n",
    "for k_text, test_sample in enumerate(test_texts):\n",
    "    sample_id = f\"sample_{k_text:03d}\"\n",
    "    \n",
    "    # Skip if already saved\n",
    "    if store.get_sample(sample_id):\n",
    "        print(f\"\u2713 {sample_id} already flattened (skipping)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Flattening {sample_id}...\", end=\" \")\n",
    "    \n",
    "    # Flatten content\n",
    "    flatten_prompt = prompt_maker.render(\n",
    "        StyleFlatteningConfig(text=test_sample.text)\n",
    "    )\n",
    "    flattened = reconstruction_llm.complete(flatten_prompt)\n",
    "    \n",
    "    # Save to store with provenance\n",
    "    source_info = f\"File {test_sample.file_index}, para {test_sample.paragraph_start}-{test_sample.paragraph_end}\"\n",
    "    store.save_sample(\n",
    "        sample_id=sample_id,\n",
    "        original_text=test_sample.text,\n",
    "        flattened_content=flattened.content,\n",
    "        flattening_model=flattened.model,\n",
    "        source_info=source_info\n",
    "    )\n",
    "    \n",
    "    print(f\"\u2713 ({len(flattened.content)} chars)\")\n",
    "\n",
    "print(f\"\\n\u2713 All samples flattened and saved to store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====ORIGINAL===\n",
      "In regard to mines, development by the Chinese themselves is urgent,\n",
      "since undeveloped resources tempt the greed of the Great Powers, and\n",
      "development by foreigners makes it possible to keep China enslaved. It\n",
      "should therefore be enacted that, in future, no sale of mines or of any\n",
      "interest in mines to foreigners, and no loan from foreigners on the\n",
      "security of mines, will be recognized as legally valid. In view of\n",
      "extra-territoriality, it will be difficult to induce foreigners to\n",
      "accept such legislation, and Consular Courts will not readily admit its\n",
      "validity. But, as the example of extra-territoriality in Japan shows,\n",
      "such matters depend upon the national strength; if the Powers fear\n",
      "China, they will recognize the validity of Chinese legislation, but if\n",
      "not, not. In view of the need of rapid development of mining by Chinese,\n",
      "it would probably be unwise to nationalize all mines here and now. It\n",
      "would be better to provide every possible encouragement to genuinely\n",
      "Chinese private enterprise, and to offer the assistance of geological\n",
      "and mining experts, etc. The Government should, however, retain the\n",
      "right (_a_) to buy out any mining concern at a fair valuation; (_b_) to\n",
      "work minerals itself in cases where the private owners fail to do so, in\n",
      "spite of expert opinion in favour of their being worked. These powers\n",
      "should be widely exercised, and as soon as mining has reached the point\n",
      "compatible with national security, the mines should be all nationalized,\n",
      "except where, as at Tayeh, diplomatic agreements stand in the way. It is\n",
      "clear that the Tayeh mines must be recovered by China as soon as\n",
      "opportunity offers, but when or how that will be it is as yet impossible\n",
      "to say. Of course I have been assuming an orderly government established\n",
      "in China, but without that nothing vigorous can be done to repel foreign\n",
      "aggression. This is a point to which, along with other general questions\n",
      "connected with the industrializing of China, I shall return in my last\n",
      "chapter.\n",
      "\n",
      "It is said by Europeans who have business experience in China that the\n",
      "Chinese are not good at managing large joint-stock companies, such as\n",
      "modern industry requires. As everyone knows, they are proverbially\n",
      "honest in business, in spite of the corruption of their politics. But\n",
      "their successful businesses--so one gathers--do not usually extend\n",
      "beyond a single family; and even they are apt to come to grief sooner or\n",
      "later through nepotism. This is what Europeans say; I cannot speak from\n",
      "my own knowledge. But I am convinced that modern education is very\n",
      "quickly changing this state of affairs, which was connected with\n",
      "Confucianism and the family ethic. Many Chinese have been trained in\n",
      "business methods in America; there are Colleges of Commerce at Woosung\n",
      "and other places; and the patriotism of Young China has led men of the\n",
      "highest education to devote themselves to industrial development. The\n",
      "Chinese are no doubt, by temperament and tradition, more suited to\n",
      "commerce than to industry, but contact with the West is rapidly\n",
      "introducing new aptitudes and a new mentality. There is, therefore,\n",
      "every reason to expect, if political conditions are not too adverse,\n",
      "that the industrial development of China will proceed rapidly throughout\n",
      "the next few decades. It is of vital importance that that development\n",
      "should be controlled by the Chinese rather than by foreign nations. But\n",
      "that is part of the larger problem of the recovery of Chinese\n",
      "independence, with which I shall deal in my last chapter.\n",
      "\n",
      "CHAPTER XV\n",
      "\n",
      "THE OUTLOOK FOR CHINA\n",
      "\n",
      "In this chapter I propose to take, as far as I am able, the standpoint\n",
      "of a progressive and public-spirited Chinese, and consider what reforms,\n",
      "in what order, I should advocate in that case.\n",
      "\n",
      "\n",
      "====FLATTENED====\n",
      "# Content Summary\n",
      "\n",
      "## Main Topic: Chinese Mine Development and Resource Control\n",
      "\n",
      "### Central Argument\n",
      "China must develop its mines independently to prevent foreign exploitation and maintain sovereignty.\n",
      "\n",
      "### Key Claims and Supporting Logic\n",
      "\n",
      "**Problem Statement:**\n",
      "- Undeveloped resources attract predatory interest from Great Powers\n",
      "- Foreign-controlled development enables continued Chinese subjugation\n",
      "\n",
      "**Proposed Legislative Solution:**\n",
      "- Enact prohibition on future sales of mines or mining interests to foreigners\n",
      "- Prohibit loans from foreigners secured by mines\n",
      "- Declare such transactions legally invalid\n",
      "\n",
      "**Acknowledged Implementation Challenge:**\n",
      "- Extra-territoriality complicates enforcement\n",
      "- Consular Courts will resist acknowledging validity of such legislation\n",
      "- Author notes Japan's experience with extra-territoriality as precedent\n",
      "- Effectiveness depends on national strength: Powers will respect Chinese law only if they fear China\n",
      "\n",
      "**Development Strategy - Short Term:**\n",
      "The author qualifies that immediate complete nationalization would be inadvisable given the need for rapid development.\n",
      "\n",
      "Recommended approach:\n",
      "- Maximize encouragement for genuinely Chinese private enterprise\n",
      "- Provide government assistance through geological and mining experts\n",
      "\n",
      "**Government Powers to Retain:**\n",
      "a) Right to purchase any mining concern at fair valuation\n",
      "b) Right to operate minerals when private owners fail to develop them despite expert recommendation\n",
      "\n",
      "**Development Strategy - Long Term:**\n",
      "- Exercise the above powers extensively\n",
      "- Nationalize all mines once mining reaches level compatible with national security\n",
      "- Exception: cases where diplomatic agreements prevent nationalization (example provided: Tayeh)\n",
      "\n",
      "**Specific Case Noted:**\n",
      "- Tayeh mines must be recovered by China when opportunity arises\n",
      "- Timing and method currently impossible to determine\n",
      "\n",
      "**Prerequisite Condition:**\n",
      "Author emphasizes all proposals assume establishment of orderly government in China, without which vigorous resistance to foreign aggression is impossible.\n",
      "\n",
      "**Cross-reference:**\n",
      "Author indicates intention to address this point and other general questions about Chinese industrialization in final chapter.\n",
      "\n",
      "---\n",
      "\n",
      "## Secondary Topic: Chinese Business Management Capabilities\n",
      "\n",
      "### European Perspective (Reported Claims)\n",
      "Europeans with business experience in China assert:\n",
      "- Chinese lack proficiency in managing large joint-stock companies\n",
      "- Such companies are necessary for modern industry\n",
      "\n",
      "**Contrasting Point Noted:**\n",
      "- Chinese have proverbial reputation for business honesty\n",
      "- This contrasts with corruption in their politics\n",
      "\n",
      "**Limitations of Chinese Business Success (According to European Sources):**\n",
      "- Successful businesses typically confined to single family operations\n",
      "- Even family businesses vulnerable to failure through nepotism\n",
      "\n",
      "**Author's Qualification:**\n",
      "Cannot personally verify these European claims.\n",
      "\n",
      "### Author's Counter-Argument\n",
      "\n",
      "**Claim:** Modern education is rapidly changing the described situation.\n",
      "\n",
      "**Causal Connection Identified:**\n",
      "Previous business limitations connected to:\n",
      "- Confucianism\n",
      "- Family ethic system\n",
      "\n",
      "**Evidence of Change:**\n",
      "- Many Chinese trained in American business methods\n",
      "- Colleges of Commerce established (specific location mentioned: Woosung and other places)\n",
      "- Young China's patriotism motivates highly educated individuals to pursue industrial development\n",
      "\n",
      "**Concession Made:**\n",
      "Chinese temperament and tradition better suited to commerce than industry.\n",
      "\n",
      "**Qualifying Statement:**\n",
      "Western contact rapidly introducing:\n",
      "- New aptitudes\n",
      "- New mentality\n",
      "\n",
      "### Conclusion on Industrial Development\n",
      "\n",
      "**Prediction:**\n",
      "If political conditions are not excessively adverse, Chinese industrial development will proceed rapidly over next few decades.\n",
      "\n",
      "**Emphasis:**\n",
      "Vital importance that this development be controlled by Chinese rather than foreign nations.\n",
      "\n",
      "**Connection to Larger Framework:**\n",
      "Author identifies this as component of broader problem: recovery of Chinese independence, to be addressed in final chapter.\n",
      "\n",
      "---\n",
      "\n",
      "## Transitional Section\n",
      "\n",
      "### Chapter XV Introduction\n",
      "Author states intention to adopt perspective of progressive, public-spirited Chinese person and consider:\n",
      "- What reforms to advocate\n",
      "- In what order to advocate them\n"
     ]
    }
   ],
   "source": [
    "print('====ORIGINAL===')\n",
    "print(store.get_sample('sample_000')['original_text'])\n",
    "print('\\n\\n====FLATTENED====')\n",
    "print(store.get_sample('sample_000')['flattened_content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reconstruction\n",
    "\n",
    "Generate reconstructions using all 4 methods, with M stochastic runs each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 2: Generating Reconstructions ===\n",
      "\n",
      "\n",
      "sample_000:\n",
      "  Run 0:\n",
      "    \u2713 generic      (5590 chars)\n",
      "    \u2713 fewshot      (5507 chars)\n",
      "    \u2713 author       (6374 chars)\n",
      "    \u2713 instructions (9295 chars)\n",
      "  Run 1:\n",
      "    \u2713 generic      (6510 chars)\n",
      "    \u2713 fewshot      (5156 chars)\n",
      "    \u2713 author       (5315 chars)\n",
      "    \u2713 instructions (8600 chars)\n",
      "  Run 2:\n",
      "    \u2713 generic      (7144 chars)\n",
      "    \u2713 fewshot      (4860 chars)\n",
      "    \u2713 author       (5734 chars)\n",
      "    \u2713 instructions (4648 chars)\n",
      "\n",
      "sample_001:\n",
      "  Run 0:\n",
      "    \u2713 generic      (5889 chars)\n",
      "    \u2713 fewshot      (4715 chars)\n",
      "    \u2713 author       (5226 chars)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate reconstructions (with crash resume)\n",
    "print(\"=== Step 2: Generating Reconstructions ===\\n\")\n",
    "\n",
    "for sample_id in store.list_samples():\n",
    "    sample = store.get_sample(sample_id)\n",
    "    print(f\"\\n{sample_id}:\")\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        print(f\"  Run {run}:\")\n",
    "        \n",
    "        # Check which methods need reconstruction\n",
    "        for method in ['generic', 'fewshot', 'author', 'instructions']:\n",
    "            if store.has_reconstruction(sample_id, run, method):\n",
    "                print(f\"    \u2713 {method:12s} (already done)\")\n",
    "                continue\n",
    "            \n",
    "            # Generate reconstruction\n",
    "            config = RECONSTRUCTORS_CFGS[method](\n",
    "                content_summary=sample['flattened_content'],\n",
    "                **RECONSTRUCTORS_KWARGS[method]\n",
    "            )\n",
    "            prompt = prompt_maker.render(config)\n",
    "            response = reconstruction_llm.complete(prompt)\n",
    "            \n",
    "            # Save immediately (crash resilient!)\n",
    "            store.save_reconstruction(\n",
    "                sample_id=sample_id,\n",
    "                run=run,\n",
    "                method=method,\n",
    "                reconstructed_text=response.content,\n",
    "                model=response.model\n",
    "            )\n",
    "            print(f\"    \u2713 {method:12s} ({len(response.content)} chars)\")\n",
    "\n",
    "stats = store.get_stats()\n",
    "print(f\"\\n\u2713 Generated {stats['n_reconstructions']} total reconstructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = store.get_reconstructions('sample_001', 0)\n",
    "for reconstructor in reconstructions.keys():\n",
    "    print(f\"{reconstructor.upper()}\\n===================\")\n",
    "    print(f\"\\n{reconstructions.get(reconstructor)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Judging\n",
    "\n",
    "Compare each reconstruction against the original using the judge LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 3: Comparative Blind Judging ===\n",
      "\n",
      "\n",
      "sample_000:\n",
      "  Run 0: Judging... \u2713 (confidence: high)\n",
      "  Run 1: Judging... \u2713 (confidence: high)\n",
      "  Run 2: Judging... \u2713 (confidence: high)\n",
      "\n",
      "sample_001:\n",
      "  Run 0: Judging... \u2713 (confidence: high)\n",
      "  Run 1: Judging... \u2713 (confidence: high)\n",
      "  Run 2: Judging... \u2713 (confidence: high)\n",
      "\n",
      "sample_002:\n",
      "  Run 0: Judging... \u2713 (confidence: high)\n",
      "  Run 1: Judging... \u2713 (confidence: high)\n",
      "  Run 2: Judging... \u2713 (confidence: high)\n",
      "\n",
      "sample_003:\n",
      "  Run 0: Judging... \u2713 (confidence: high)\n",
      "  Run 1: Judging... \u2713 (confidence: high)\n",
      "  Run 2: Judging... \u2713 (confidence: high)\n",
      "\n",
      "sample_004:\n",
      "  Run 0: Judging... \u2713 (confidence: high)\n",
      "  Run 1: Judging... \u2713 (confidence: high)\n",
      "  Run 2: Judging... \u2713 (confidence: high)\n",
      "\n",
      "\u2713 Completed 15 judgments\n"
     ]
    }
   ],
   "source": [
    "from belletrist.models import StyleJudgeComparativeConfig, StyleJudgmentComparative\n",
    "# Step 3: Comparative blind judging (with crash resume)\n",
    "print(\"=== Step 3: Comparative Blind Judging ===\\n\")\n",
    "\n",
    "for sample_id in store.list_samples():\n",
    "    sample = store.get_sample(sample_id)\n",
    "    print(f\"\\n{sample_id}:\")\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        if store.has_judgment(sample_id, run):\n",
    "            print(f\"  Run {run}: \u2713 Already judged (skipping)\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Run {run}: Judging...\", end=\" \")\n",
    "        \n",
    "        # Get all 4 reconstructions\n",
    "        reconstructions = store.get_reconstructions(sample_id, run)\n",
    "        if len(reconstructions) != 4:\n",
    "            print(f\"\u2717 Missing reconstructions (found {len(reconstructions)}/4)\")\n",
    "            continue\n",
    "        \n",
    "        # Create randomized mapping for blind evaluation\n",
    "        # Using deterministic seed per (sample, run) for reproducibility\n",
    "        mapping = store.create_random_mapping(seed=hash(f\"{sample_id}_{run}\"))\n",
    "        \n",
    "        # Build prompt with anonymous labels (BLIND EVALUATION)\n",
    "        judge_config = StyleJudgeComparativeConfig(\n",
    "            original_text=sample['original_text'],\n",
    "            reconstruction_text_a=reconstructions[mapping.text_a],\n",
    "            reconstruction_text_b=reconstructions[mapping.text_b],\n",
    "            reconstruction_text_c=reconstructions[mapping.text_c],\n",
    "            reconstruction_text_d=reconstructions[mapping.text_d]\n",
    "        )\n",
    "        judge_prompt = prompt_maker.render(judge_config)\n",
    "        \n",
    "        # Get structured JSON judgment\n",
    "        try:\n",
    "            response = judge_llm.complete_json(judge_prompt)\n",
    "            judgment_data = json.loads(response.content)\n",
    "            judgment = StyleJudgmentComparative(**judgment_data)\n",
    "            \n",
    "            # Save judgment with mapping (crash resilient!)\n",
    "            store.save_judgment(sample_id, run, judgment, mapping, response.model)\n",
    "            print(f\"\u2713 (confidence: {judgment.confidence})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\u2717 Error: {e}\")\n",
    "\n",
    "stats = store.get_stats()\n",
    "print(f\"\\n\u2713 Completed {stats['n_judgments']} judgments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Exporting Results ===\n",
      "\n",
      "Total judgments: 15\n",
      "Samples: 5\n",
      "Runs per sample: 3.0\n",
      "\n",
      "=== Sample Results ===\n",
      "\n",
      "     sample_id  run  ranking_generic  ranking_fewshot  ranking_author  \\\n",
      "0   sample_000    0                3                2               1   \n",
      "1   sample_000    1                4                3               2   \n",
      "2   sample_000    2                4                3               2   \n",
      "3   sample_001    0                3                1               4   \n",
      "4   sample_001    1                4                1               2   \n",
      "5   sample_001    2                2                3               4   \n",
      "6   sample_002    0                3                2               4   \n",
      "7   sample_002    1                4                3               2   \n",
      "8   sample_002    2                3                1               2   \n",
      "9   sample_003    0                3                2               1   \n",
      "10  sample_003    1                4                1               2   \n",
      "11  sample_003    2                2                1               4   \n",
      "12  sample_004    0                2                1               4   \n",
      "13  sample_004    1                1                3               4   \n",
      "14  sample_004    2                3                2               1   \n",
      "\n",
      "    ranking_instructions confidence  \n",
      "0                      4       high  \n",
      "1                      1       high  \n",
      "2                      1       high  \n",
      "3                      2       high  \n",
      "4                      3       high  \n",
      "5                      1       high  \n",
      "6                      1       high  \n",
      "7                      1       high  \n",
      "8                      4       high  \n",
      "9                      4       high  \n",
      "10                     3       high  \n",
      "11                     3       high  \n",
      "12                     3       high  \n",
      "13                     2       high  \n",
      "14                     4       high  \n",
      "\n",
      "\u2713 Results saved to style_eval_20251127_092034.csv\n"
     ]
    }
   ],
   "source": [
    "# Export results to DataFrame\n",
    "print(\"=== Exporting Results ===\\n\")\n",
    "\n",
    "# Export from store (resolves anonymous rankings to methods)\n",
    "df = store.to_dataframe()\n",
    "\n",
    "print(f\"Total judgments: {len(df)}\")\n",
    "print(f\"Samples: {df['sample_id'].nunique()}\")\n",
    "print(f\"Runs per sample: {df.groupby('sample_id')['run'].nunique().mean():.1f}\")\n",
    "\n",
    "# Show first few rows\n",
    "print(f\"\\n=== Sample Results ===\\n\")\n",
    "display_cols = ['sample_id', 'run', 'ranking_generic', 'ranking_fewshot', \n",
    "                'ranking_author', 'ranking_instructions', 'confidence']\n",
    "print(df[display_cols].head(15))\n",
    "\n",
    "# Export to CSV\n",
    "output_file = f\"style_eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n\u2713 Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me work through each text systematically, focusing on the distinctive voice of the original.\n",
      "\n",
      "**The Original's Voice:**\n",
      "The original has a particular philosophical tone that balances formality with accessibility. Key features include:\n",
      "- Direct, matter-of-fact statements (\"The inductive principle, however, is equally incapable...\")\n",
      "- Concrete, vivid examples woven naturally into abstract arguments (\"to expect bread to be more nourishing than a stone\")\n",
      "- A conversational relationship with the reader, using \"we\" inclusively\n",
      "- Measured pacing with neither excessive elaboration nor stark minimalism\n",
      "- Phrases like \"begging the question,\" \"intrinsic evidence,\" \"forgo all justification\"\n",
      "- A distinctive rhythm that moves from principle to example to implication\n",
      "- The memorable image of the friend's body inhabited by an enemy's mind\n",
      "- Chapter transitions that are straightforward and organizational\n",
      "\n",
      "**TEXT A Analysis:**\n",
      "This text feels like an educational expansion or modernization. The voice is explanatory and pedagogical (\"In other words, any attempt to use past experience...\"). It uses italics for *begging the question*, which the original doesn't. The prose is more explicitly structured with transitional phrases like \"Indeed,\" \"Nor does science escape,\" \"Thus, all knowledge that ventures.\" The tone is that of a textbook or teaching document\u2014clear and systematic but somewhat impersonal. The final paragraph's metaphor about \"pillars that experience alone cannot erect\" feels more contemporary and explanatory than the original's voice. The rhythm is more uniform and less varied than the original.\n",
      "\n",
      "**TEXT B Analysis:**\n",
      "This text immediately strikes a different register: \"There is a principle, simple in its aspect yet profound in its consequences, which lies at the very foundation...\" This is more ornate, more consciously literary. The prose has a Victorian/Edwardian philosophical grandeur with phrases like \"narrow precincts of immediate experience,\" \"the edifice of science...collapses,\" \"curious and inescapable circle,\" \"psychologically impossible and practically catastrophic.\" The author uses italicized Latin (*petitio principii*), which the original doesn't. The concluding metaphor\u2014\"not a pyramid resting securely on observed facts, is rather a raft floating upon a sea of assumptions\"\u2014is strikingly poetic and memorable in a way that feels consistent with philosophical writing of the early 20th century. The voice has theatrical flair (\"And let it not be thought...\") and builds arguments with rhetorical flourish. This feels like it could be from the same era and philosophical tradition as the original.\n",
      "\n",
      "**TEXT C Analysis:**\n",
      "This text is notably spare and direct: \"The inductive principle cannot be proven by experience.\" It reads like lecture notes or a philosophical pr\u00e9cis\u2014accurate but stripped down. The sentences are shorter and more declarative. There's less imagery and fewer memorable phrases. The examples are present but feel more perfunctory (\"that bread will nourish rather than poison\"). The prose lacks the texture and rhythm of the original\u2014it's efficient rather than engaging. Phrases like \"This, though it may seem counterintuitive\" feel more contemporary and textbook-like. The voice is that of a clear expositor but lacks personality and distinctive character. It's the most utilitarian of the four texts.\n",
      "\n",
      "**TEXT D Analysis:**\n",
      "This text opens with a complex, formal construction: \"The principle of induction\u2014by which we infer, from a number of instances that have been observed, a general rule or expectation concerning cases not yet observed\u2014lies at the very foundation...\" The voice is measured and philosophical with phrases like \"transcends immediate experience,\" \"involved in a circle from which there seems no escape.\" The examples feel naturally integrated (\"fire will burn or that water will quench thirst\"). The rhythm alternates between complex and simple sentences in a way that feels authentic to early 20th-century philosophical prose. Phrases like \"to-morrow\" (with hyphen) and \"the deliverances of sense\" suggest period authenticity. The conclusion\u2014\"its foundation remains one of the deep, unsolved mysteries of the human intellect\"\u2014has appropriate gravitas without being overwrought. The voice maintains formality while remaining accessible.\n",
      "\n",
      "**Comparative Ranking:**\n",
      "\n",
      "TEXT B (Rank 1): Despite its more ornate style, this captures the philosophical voice of the era most completely. The rhetorical structures, the balance of abstraction and concrete example, the relationship with the reader, and the memorable concluding metaphor all feel authentic to early 20th-century philosophical writing. If I encountered this \"in the wild,\" I would most likely attribute it to the same author or tradition.\n",
      "\n",
      "TEXT D (Rank 2): This is very close to the original's voice\u2014formal but accessible, with good rhythm and natural integration of examples. The period touches (like \"to-morrow\") and the measured philosophical tone are convincing. It would be difficult to distinguish from the original, though it lacks some of the original's particular turns of phrase.\n",
      "\n",
      "TEXT A (Rank 3): This is competent and clear but feels more like a modern educational text. The explanatory style and contemporary framing devices make it feel less like the original author's voice and more like someone explaining that author's ideas.\n",
      "\n",
      "TEXT C (Rank 4): This is the least similar\u2014too stripped down, too utilitarian. It captures the content but misses the voice entirely. The prose lacks texture, rhythm, and personality. It reads like efficient notes rather than authored philosophical prose.\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0,'reasoning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ranking Distribution by Method ===\n",
      "\n",
      "\n",
      "GENERIC:\n",
      "  Rank 1:   1 (  6.7%)\n",
      "  Rank 2:   3 ( 20.0%)\n",
      "  Rank 3:   6 ( 40.0%)\n",
      "  Rank 4:   5 ( 33.3%)\n",
      "\n",
      "FEWSHOT:\n",
      "  Rank 1:   6 ( 40.0%)\n",
      "  Rank 2:   4 ( 26.7%)\n",
      "  Rank 3:   5 ( 33.3%)\n",
      "  Rank 4:   0 (  0.0%)\n",
      "\n",
      "AUTHOR:\n",
      "  Rank 1:   3 ( 20.0%)\n",
      "  Rank 2:   6 ( 40.0%)\n",
      "  Rank 3:   0 (  0.0%)\n",
      "  Rank 4:   6 ( 40.0%)\n",
      "\n",
      "INSTRUCTIONS:\n",
      "  Rank 1:   5 ( 33.3%)\n",
      "  Rank 2:   2 ( 13.3%)\n",
      "  Rank 3:   4 ( 26.7%)\n",
      "  Rank 4:   4 ( 26.7%)\n",
      "\n",
      "=== Confidence Distribution ===\n",
      "\n",
      "confidence\n",
      "high    15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analyze ranking distributions\n",
    "print(\"=== Ranking Distribution by Method ===\\n\")\n",
    "\n",
    "for method in ['generic', 'fewshot', 'author', 'instructions']:\n",
    "    col = f'ranking_{method}'\n",
    "    print(f\"\\n{method.upper()}:\")\n",
    "    ranking_counts = df[col].value_counts().sort_index()\n",
    "    for rank in [1, 2, 3, 4]:\n",
    "        count = ranking_counts.get(rank, 0)\n",
    "        pct = (count / len(df) * 100) if len(df) > 0 else 0\n",
    "        print(f\"  Rank {rank}: {count:3d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n=== Confidence Distribution ===\\n\")\n",
    "print(df['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Method Performance Metrics ===\n",
      "\n",
      "Average Ranking (lower is better):\n",
      "1. fewshot     : 1.93 (1st place: 6/15 = 40.0%)\n",
      "2. instructions: 2.47 (1st place: 5/15 = 33.3%)\n",
      "3. author      : 2.60 (1st place: 3/15 = 20.0%)\n",
      "4. generic     : 3.00 (1st place: 1/15 = 6.7%)\n",
      "\n",
      "Top-2 Rate (ranked 1st or 2nd):\n",
      "  generic     : 4/15 = 26.7%\n",
      "  fewshot     : 10/15 = 66.7%\n",
      "  author      : 9/15 = 60.0%\n",
      "  instructions: 7/15 = 46.7%\n"
     ]
    }
   ],
   "source": [
    "# Calculate method performance metrics\n",
    "print(\"=== Method Performance Metrics ===\\n\")\n",
    "\n",
    "# Calculate mean ranking for each method (lower is better: 1 = best, 4 = worst)\n",
    "mean_rankings = {}\n",
    "for method in ['generic', 'fewshot', 'author', 'instructions']:\n",
    "    col = f'ranking_{method}'\n",
    "    mean_rankings[method] = df[col].mean()\n",
    "\n",
    "# Sort by mean ranking (best first)\n",
    "sorted_methods = sorted(mean_rankings.items(), key=lambda x: x[1])\n",
    "\n",
    "print(\"Average Ranking (lower is better):\")\n",
    "for i, (method, mean_rank) in enumerate(sorted_methods, 1):\n",
    "    # Count how often this method ranked 1st\n",
    "    first_place = (df[f'ranking_{method}'] == 1).sum()\n",
    "    first_place_pct = (first_place / len(df) * 100) if len(df) > 0 else 0\n",
    "    \n",
    "    print(f\"{i}. {method:12s}: {mean_rank:.2f} (1st place: {first_place}/{len(df)} = {first_place_pct:.1f}%)\")\n",
    "\n",
    "# Win rate (percentage of times ranked 1st or 2nd)\n",
    "print(\"\\nTop-2 Rate (ranked 1st or 2nd):\")\n",
    "for method in ['generic', 'fewshot', 'author', 'instructions']:\n",
    "    col = f'ranking_{method}'\n",
    "    top2 = ((df[col] == 1) | (df[col] == 2)).sum()\n",
    "    top2_pct = (top2 / len(df) * 100) if len(df) > 0 else 0\n",
    "    print(f\"  {method:12s}: {top2}/{len(df)} = {top2_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u2713 Results saved to style_evaluation_results_20251127_092147.csv\n"
     ]
    }
   ],
   "source": [
    "# Export results\n",
    "output_file = f\"style_evaluation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n\u2713 Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "TODO: Add analysis cells for:\n",
    "- Statistical significance testing\n",
    "- Visualization of results\n",
    "- Sample-by-sample breakdown\n",
    "- Confidence level analysis\n",
    "- Qualitative review of reasoning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (russell_writes)",
   "language": "python",
   "name": "russell_writes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}